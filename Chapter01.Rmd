---
title: "描述性统计"
author: "梁雪枫"
documentclass: ctexart
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    template: !expr rticles::ctex_template()
    toc: yes
classoption: "hyperref`r if (.Platform$OS.type != 'windows') ',nofonts'`"
---

```{r include=FALSE}
library(epicalc)
library(mosaic)
library(showtext)
library(pander)
library(PerformanceAnalytics)
library(Hmisc)
library(pastecs)
library(psych)
library(plyr)
library(doBy)
library(vcd)
library(gmodels)
```

统计分析分为统计描述和统计推断两个部分，统计描述是通过绘制统计图、计算统计量等方法描述数据的分布特征，是数据分析的基本步骤。

## 常用统计量

###  均数(Mean)

均数是一组数据的平均值，均数（记为$\overline{x}$）定义为
$$\overline{x} = \frac{\sum_{i=1}^{n}x_{i}}{n}$$
用它来描述正态分布数据的集中趋势。

### 标准差(Standard Deviation)

标准差是方差的算术平方根，是一组数值自均数分散开来的程度的一种测量观念。定义为
$$\delta = \sqrt{\frac{1}{N}\sum_{i=1}^{n}(x_i-u)^2}$$
一个较大的标准差，代表大部分的数值和其平均值之间差异较大；一个较小的标准差，代表这些数值较接近平均值。

例 已知50名患者的收缩压（mmHg）分别为：
147 163 159 124 120  94 135 185 109 143 116 129 157 146 149 127 124 160 101 129 130 154 151
119 128 147 127 122 145 159 141 131 117 139 142 152 147 157 134 146 144 119 160 136 122 172
170 109 151 144

求血压的集中趋势和离散趋势及集中趋势的95%可信区间。

思路：先判断数据是否为正态分布，然后根据结果选择描述集中趋势的统计量。
```{r}
sbp <- c(147,163,159,124,120,94,135,185,109,143,116,129,157,146,149,127,124,160,101,129,130,154,151,119,128,147,127,122,145,159,141,131,117,139,142,152,147,157,134,146,144,119,160,136 ,122,172,170,109,151,144)
qqnorm(sbp)
qqline(sbp)
#plot(density(sbp)) 核密度
hist(sbp,freq = F) #freq=T,则绘制频数
result <- shapiro.test(sbp)
result
ks.test(sbp,"pnorm",mean(sbp),sd(sbp))
```
样本大小在3和5000之间,选择Shapiro-Wilk进行正态性检验。W值为`r result[1]`，P值为`r result[2]`大于0.05，不能拒绝其于正态分布一致的假设。如果样本数较大，可以选择Kolmogorov-Smirnov检验。对于服从正态分布的数据，选择均数和标准差描述其集中趋势和离散趋势。
```{r}
mean(sbp)
sd(sbp)
```
均值为`r mean(sbp)`,标准差为`r sd(sbp)`。对均数和标准差的计算还可以通过base包中的summary()函数，该函数提供了最小值、最大值、四分位数和数值型变量的均值，以及因子向量和逻辑型向量的频数统计。epicalc包中的summ()和mosaic包中的favstats()等函数也可获得类似结果，如favstats()一次就可以完成均数和标准差的计算。
```{r}
favstats(sbp)
```

对均数的95%可信区间的计算可通过t.test()获得，对一个给定的可信区间，它表示一个总体参数的估计范围。根据中位数和均数可以快速检查数据分布，如中位数小于均数，说明分布有可能向右倾斜。
```{r}
t.test(sbp)
```

通过设置conf.level=0.99，可以将可信区间水平提高到99%。
```{r}
t.test(sbp,conf.level=0.99)
```
###中位数(Median)
对于一组有限个数的数据来说，它们的中位数是这样的一种数：这群数据里的一半的数据比它大，而另外一半数据比它小。 计算有限个数的数据的中位数的方法是：把所有的同类数据按照大小的顺序排列。如果数据的个数是奇数，则中间那个数据就是这群数据的中位数；如果数据的个数是偶数，则中间那2个数据的算术平均值就是这群数据的中位数。通常用中位数来描述非正态分布数据的集中趋势，极值对中位数影响不大。定义为
实数$x_1$, $x_2$, $\dots$, $x_n$按大小顺序（顺序，降序皆可）排列为$x'_1$, $x'_2$, $\dots$ , $x'_n$、实数数列$x=(x_1, x_2, \dots , x_n)$的中位数$\mathrm{Q}_\frac{1}{2}(x)$为
$$\mathrm{Q}_\frac{1}{2}(x) = 
\begin{cases} 
 x'_\frac{n + 1}{2},                                  & \mbox{if } n \mbox{ is odd.} \\
 \frac{1}{2}( x'_\frac{n}{2} + x'_{\frac{n}{2} + 1}), & \mbox{if } n \mbox{ is even.} 
\end{cases}
$$
odd 为奇数，even 为偶数。

###四分位差(quartile deviation)
是上四分位数（QU，即位于75%）与下四分位数（QL，即位于25%）的差的一半。计算公式为：$Qd=QU-QL$。四分位差反映了中间50%数据的离散程度，其数值越小，说明中间的数据越集中；其数值越大，说明中间的数据越分散。四分位差不受极值的影响。
例 某地17名患者的月收入分别为：
23408 3468 1939 4360 23545 12233 4583 3546 35781 6578 8981 1345 5567 23455 23564 7623 14334
求收入的集中趋势和离散趋势及集中趋势的95%可信区间。
思路：仍然先判断数据是否为正态分布，然后根据结果选择描述集中趋势的统计量。
```{r}
income <- c(23408,3468,1939,4360,23545,12233,4583,3546,35781,6578,8981,1345,5567,23455, 23564,7623,14334)
qqnorm(income)
qqline(income)
#plot(density(income))
hist(income,freq = F)
result <- shapiro.test(income)
result
```
根据QQ图和Shapiro-Wilk进行正态性检验结果，W值为`r result[1]`，P值为`r result[2]`小于0.05，选择中位数和四分位差描述其集中趋势和离散趋势。
```{r}
quantile(income)
```
中位数为`r median(income)`，四分位差为75%的分位数减去25%的分位数。对中位数的可信区间估计，可通过wilcox.test()函数获得
```{r}
wilcox.test(income, conf.int=TRUE)
```

### 数学期望(mathematical expectation)
离散型随机变量：离散型随机变量的一切可能的取值$x_{i}$与对应的概率$P_{i}(=x_{i})$之积的和称为该离散型随机变量的数学期望，记为$E(X)$。数学期望是最基本的数学特征之一。它反映随机变量平均取值的大小。离散型随机变量的数学期望就是均数，通过mean()即可获得。
$$E(X)=\sum_{i}x_{i}p_{i}$$
连续型随机变量：若随机变量X的分布函数$F(x)$可表示成一个非负可积函数$f(x)$的积分，则称$X$为连续性随机变量，$f(x)$称为$X$的概率密度函数，积分值为X的数学期望，记为$E(X)$。
$$E(X)=\int_{-\infty }^{+\infty }xf(x)dx$$

###方差(Variance)
方差是各个数据与平均数之差的平方的平均数。在概率论和数理统计中，方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。
设$X$为随机变量，如果$E{[X-E(X)]^2}$存在，则称$E{[X-E(X)]^2}$为$X$的方差，记为$Var(X)$。
离散型随机变量方差计算公式为$$Var(X)=E(X^{2})-(E(X))^{2}$$,连续型随机变量方差计算公式为$Var(x)=\int_{-\infty}^{+\infty} (x-E(X))^{2}f(x) \text{d}x=E(X^{2})-(E(X))^{2}$
例 计算样本(2,5,78,45,89,124)的方差
```{r}
s <- c(2,5,78,45,89,124)
var(s)
```
###众数(Mode)
观察资料中出现次数最多的数值或类别，不受极值影响，由于可能有不只一个，也可能没有众数，一般不适合进行统计分析。

例 计算样本(4,22,31,33,3,27,27,27,27,569,110,8,21,31,33,33)的众数
```{r}
S <- c(4,22,31,33,3,27,27,27,27,569,110,8,21,31,33,33)
names(which.max(table(S)))
```
###协方差(Covariance)
协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。设$X$,$Y$为两个随机变量，称$E{[X-E(X)][Y-E(Y)]}$为$X$和$Y$的协方差，记录$Cov(X,Y)$。
$$Cov(X,Y)=E\left \{ [X-E(X)][Y-E(Y)] \right \}$$
例 计算X(2,5,7)和Y(6,7,9)的协方差。
```{r}
x <- c(2,5,7)
y <- c(6,7,9)
cov(x,y)
```
###相关系数(Correlation coefficient)
相关系数是用以反映变量之间相关关系密切程度的统计指标。相关系数是按积差方法计算，同样以两变量与各自平均值的离差为基础，通过两个离差相乘来反映两变量之间相关程度。当$Var(X)>0, Var(Y)>0$时，称$Cov(X,Y)/sqrt(Var(X)*Var(Y))$为$X$与$Y$的相关系统。
$$\rho (X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$
例 计算X(2,5,7)和Y(6,7,9)的相关系数
```{r}
x <- c(2,5,7)
y <- c(6,7,9)
cor(x,y)
```
### 偏度(skewness)
是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。设分布函数$F(x)$有中心矩$\mu_{2}=E(X-E(X))^2$,$\mu_{3}=E(X-E(X))^3$,则$\frac{\mu_{3}}{\mu_{2}^{\frac{3}{2}}}$为偏度系数。当$C_{s}$>0时，概率分布偏向均值右则,$C_{s}$<0时，概率分布偏向均值左则。
$$C_{s}=\frac{\mu_{3}}{\mu_{2}^{\frac{3}{2}}}$$

###峰度(kurtosis)
表征概率密度分布曲线在平均值处峰值高低的特征数。峰度刻划不同类型的分布的集中和分散程序。设分布函数$F(x)$有中心矩$\mu_{2}=E(X-E(X))^2$, $\mu_{4}=E(X-E(X))^4$，则$C_{k}=\frac{\mu_{4}}{\mu_{2}^{2}}-3$为峰度系数。
$$C_{k}=\frac{\mu_{4}}{\mu_{2}^{2}}-3$$
例 计算10000个正态分布的样本的偏度和峰度
```{r}
S<-rnorm(10000)
skewness(S)
kurtosis(S)
hist(S,breaks=100)
```

###几何平均数（Geometric mean）
是n个变量值连乘积的n次方根,是用于反映一组经对数转换后呈对称分布的变量值在数量上的平均水平即对数正态分布数据，在医学研究中常适用于免疫学的指标。对于变量值呈倍数关系或呈对数正态分布（正偏态分布），如抗体效价及抗体滴度，某些传染病的潜伏期，细菌计数等，宜用几何均数表示其平均水平。
$$H=G=\sqrt[n]{X_{1}*X_{2}*...*X_{n}}=\sum \sqrt[n]{\prod_{i=1}^{n}X_{n}}$$
例 5名学龄儿童的麻疹血凝抑制抗体滴度为1：25，1：50，1：50，1：100，1：400，求几何均数及标准差。
```{r}
geomean <- function(x, na.rm = FALSE, trim = 0, ...)
{
  exp(mean(log(x, ...), na.rm = na.rm, trim = trim, ...))
}
geosd <- function(x, na.rm = FALSE, ...)
{
  exp(sd(log(x, ...), na.rm = na.rm, ...))
}
s<-c(25,50,50,100,400)
shapiro.test(log(s))
geomean(s)
geosd(s)
```
也可以安装NCStats包，调用geomean和geosd()函数。

###变异系数（Coefficient of Variation）
是刻画数据相对分散性的一种度量，记为$c_v$,是概率分布离散程度的一个归一化量度，其定义为标准差$\ \sigma$与平均值$\ \mu$ 之比
$$c_v = {\sigma \over \mu }$$

###样本校正平方和（CSS）
样本与均值差的平方的求和$CSS=\sum_{i=1}^{n}(x_{i}-\overline{x})$

###样本未校正平方和（USS）
样本值平方的求和$USS=\sum_{i=1}^{n}x_{i}^{2}$

###标准误（Standard Deviation）
是某种统计量在抽样分布上的标准差称为该种统计量的标准误，即样本统计量的标准差，是描述对应的样本统计量抽样分布的离散程度及衡量对应样本统计量抽样误差大小的尺度。设n个测量值的误差为v1、v2……vn，则这组测量值的标准误差$\sigma$
$$\sigma =\sqrt{\frac{1}{n-1}\sum_{i=1}^{n}v_{i}^2}$$

###极差
描述样本分散性，数据越分散，其极差越大。
$$R=max(x)-min(x)$$

例 对例1求变异系数、样本校正平方和、样本未校正平方和、极差和均值的标准误。
```{r}
cv <- 100*sd(sbp)/mean(sbp)
cv
css <- sum((sbp-mean(sbp))^2)
css
uss <- sum(sbp^2)
uss
r <- max(sbp)-min(sbp)
r
```
通常由于总体的均数或总体的方差并不知道，样本均值的标准误$SD=\frac{s}{\sqrt{n}}$,s为标准差，n为样本数。
```{r}
sd <- sd(sbp)/sqrt(length(sbp))
sd
```

###数据中心化和标准化
数据中心化是将某变量中的观察值减去该变量的平均数，数据标准化将某变量中的观察值减去该变量的平均数，然后除以该变量的标准差。经标准化的数据都是没有单位的纯数量。对变量进行的标准差标准化可以消除量纲（单位）影响和变量自身变异的影响。
例 对下表中三科成绩进行标准化。
Math  Science	English
---   ---     ---
502	  95	    25
465	  67      12
621	  78      22
575	  66      18
454	  96      15
634	  89      30
576	  78      37
421	  56      12
599	  68      22
666	  100     38

R语言中scale()函数可以实现数据标准化，两个参数center和scale为True分别表示计算中心化和标准化
```{r}
Math <- c(502,465,621,575,454,634,576,421,599,666)
Science <- c(95,67,78,66,96,89,78,56,68,100)
English <- c(25,12,22,18,15,30,37,12,22,38)

Student <- as.data.frame(cbind(Math,Science,English))

options(digits=2) #限定为2位小数
scale(Student[,1:3],center = T,scale = F) #数据中心化 
scale(Student[,1:3],center = F,scale = T) #数据标准化
```

apply()函数或sapply()函数计算所选择的任意描述性统计量。对于sapply()函数，其使用格式为：sapply(x,FUN,options)其中的x是输入的数据框（或矩阵），FUN为一个任意的函数。如果指定了options，它们将被传递给FUN。你可以在这里插入的典型函数有mean、sd、var、min、max、median、length、range和quantile。可以根据需要自定义需要的统计量，如下
```{r}
mystats <- function(x, na.omit = FALSE) {
  if (na.omit) 
    x <- x[!is.na(x)]
  m <- mean(x)
  n = length(x)
  s <- sd(x)
  skew <- sum((x - m)^3/s^3)/n
  kurt <- sum((x - m)^4/s^4)/n - 3
  return(c(n = n, mean = m, stdev = s, skew = skew, kurtosis = kurt))
}

data(drugDat,package = "elrm")
sapply(drugDat,mystats)
```


Hmisc包中的describe()函数可返回变量和观测的数量、缺失值和唯一值的数目、平均值、分位数，以及五个最大的值和五个最小的值。pastecs包中有一个名为stat.desc()的函数，它可以计算种类繁多的描述性统计量。使用格式为：stat.desc(x,basic=TRUE,desc=TRUE,norm=FALSE,p=0.95)其中的x是一个数据框或时间序列。若basic=TRUE（默认值），则计算其中所有值、空值、缺失值的数量，以及最小值、最大值、值域，还有总和。若desc=TRUE（同样也是默认值），则计算中位数、平均数、平均数的标准误、平均数置信度为95%的置信区间、方差、标准差以及变异系数。最后，若norm=TRUE（不是默认的），则返回正态分布统计量，包括偏度和峰度（以及它们的统计显著程度）和Shapiro–Wilk正态检验结果。这里使用了p值来计算平均数的置信区间（默认置信度为0.95）。psych包也拥有一个名为describe()的函数，它可以计算非缺失值的数量、平均数、标准差、中位数、截尾均值、绝对中位差、最小值、最大值、值域、偏度、峰度和平均值的标准误。

##分类汇总
在比较多组个体或观测时，关注的焦点经常是各组的描述性统计信息，而不是整体的描述性统计信息时，可以使用aggregate()分组获取描述性统计量。

例 epicalc中HW93数据集是1993年泰国南部钩虫感染的调查资料，其中intense变量表示感染的严重程度为有序多分类变量，egp为感染的数量，shoes表示是否穿鞋，agegr是年龄分组,需要计算每个年龄的构虫平均感染钩虫的数量。

使用aggregate()分组获取描述性统计量
```{r}
data(HW93,package = "epicalc")
aggregate(HW93$epg,by=list(epg=HW93$agegr),mean)
```
注意list(epg=HW93$age)的使用。如果使用的是list(HW93$age)，则age列将被标注为Group.1而不是age。如果有多个分组变量，可以使用by=list(name1=groupvar1, name2=groupvar2, ... , groupvarN)这样的语句。aggregate()仅允许在每次调用中使用平均数、标准差这样的单返回值函数。
doBy包和psych包也提供了分组计算描述性统计量的函数，doBy包中summaryBy()函数的使用格式为：summaryBy(formula,data=dataframe,FUN=function) 其中的formula接受以下的格式：var1+var2+…+varN~grounpvar1+goupvar2+…+groupvarN,在~左侧的变量是需要分析的数值型变量，而右侧的变量是类别型的分组变量。function可为任何内建或用户自编的R函数。psych包中的describe.by()函数可计算和describe相同的描述性统计量，只是按照一个或多个分组变量分层，使用psych包中的describe.by()和使用doBy包中的summaryBy()分组计算概述统计量如下，describe.by()函数不允许指定任意函数，所以它的使用范围较窄。若存在一个以上的分组变量，你可以使用list(groupvar1, groupvar2, ... , groupvarN)来表示它们。但这仅在分组变量交叉后不出现空白单元时有效。

```{r}
summaryBy(epg~agegr,data=HW93,FUN=max)
describe.by(HW93$epg,HW93$agegr)
```

需要使用复杂函数则需要plyr包中的*ply族函数。该函数由Hadley Wickham创建，将这类任务以“分割-应用-结合”这种三步方式进行处理：通过一种或多种factor将数据集进行分割，而后应用某项函数，最后将结果整合回数据集当中。Plyr包中囊括了一整套“ply”函数，其第一个字母表示输入的类型，第二个字母表示输出的类型，输入:array,dataframe,list三种格式，输出: array,dataframe,list,discareded四种格式。plyr包中的ddply()可以得到相同结果。summarize不会提供来自原始数据框中其它列中的任何信息，如果大家需要列出其它column数据，则可以把“summarize”替换为“transform”，请且允许一次应用多个函数。
```{r eval=FALSE}
ddply(.data = HW93,.(agegr),summarize,mean=mean(epg),max=max(epg),min=min(epg))

rate <- function(x){
  return(sum(x,na.rm = T)/length(x))
}
ddply(.data = HW93,.(agegr),.fun = function(x){rate(x$epg)})
```

##频数表和列联表
table(var1, var2, …, varN) 使用 N 个类别型变量（因子）创建一个 N 维列联表。xtabs(formula, data) 根据一个公式和一个矩阵或数据框创建一个 N 维列联表。prop.table(table, margins) 依margins定义的边际列表将表中条目表示为分数形式。margin.table(table, margins) 依margins定义的边际列表计算表中条目的和addmargins(table, margins) 将概述边margins（默认是求和结果）放入表中。ftable(table) 创建一个紧凑的“平铺”式列联表

###一维列联表
```{r}
data(Arthritis,package = "vcd")
pander(head(Arthritis))
mytable<-with(Arthritis,table(Improved))
mytable
```
可以用prop.table()将这些频数转化为比例值
```{r}
prop.table(mytable)
```

###二维列联表
对于二维列联表，table()函数的使用格式为：table(A,B),其中的A是行变量，B是列变量。xtabs()函数还可使用公式风格的输入创建列联表，格式为：xtabs(\~A+B,data=mydata)，其中的mydata是一个矩阵或数据框，要进行交叉分类的变量应出现在公式的右侧（即\~符号的右方），以+作为分隔符。若某个变量写在公式的左侧，则其为一个频数向量（在数据已经被表格化时很有用）。

```{r}
mytable<-xtabs(~Treatment+Improved,data=Arthritis)
mytable
```

可以使用margin.table()和prop.table()函数分别生成边际频数(行和)和比例(行比)。
```{r}
margin.table(mytable,1)
prop.table(mytable,1)
```
列和与列比例可以这样计算
```{r}
margin.table(mytable,2)
prop.table(mytable,2)
```
各单元格所占比例可用如下语句获取
```{r}
prop.table(mytable)
```
可以使用addmargins()函数为这些表格添加边际和
```{r}
addmargins(mytable)
addmargins(prop.table(mytable))
```
在使用addmargins()时，默认是表中所有的变量创建边际和
```{r}
addmargins(prop.table(mytable,1),2)
```
注意 table()函数默认忽略缺失值（NA）。要在频数统计中将NA视为一个有效的类别，请设定参数useNA="ifany"。
```{r}
table(Arthritis$Treatment,Arthritis$Improved,useNA = "ifany")
```
使用gmodels包中的CrossTable()函数生成二维列联表
```{r}
CrossTable(Arthritis$Treatment,Arthritis$Improved)
```
CrossTable()函数有很多选项计算（行、列、单元格）的百分比；指定小数位数；进行卡方、Fisher和McNemar独立性检验；计算期望和（皮尔逊、标准化、调整的标准化）残差；将缺失值作为一种有效值；进行行和列标题的标注;

###多维列联表
table()和xtabs()都可以基于三个或更多的类别型变量生成多维列联margin.table()、prop.table()和addmargins()函数也可以推广到多维的情况。另外，ftable()函数可以以一种紧凑而吸引人的方式输出多维列联表

```{r}
mytable<-xtabs(~Treatment+Sex+Improved,data=Arthritis)
mytable
ftable(mytable)
margin.table(mytable,c(1,3))#治疗情况（Treatment） × 改善情况（Improved）的边际频数
```


