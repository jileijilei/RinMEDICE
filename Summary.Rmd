---
date: "2014年10月11日"
documentclass: ctexart
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    template: !expr rticles::ctex_template()
    toc: yes
classoption: "hyperref`r if (.Platform$OS.type != 'windows') ',nofonts'`"
---
#如何使用
相对于R在其他行业的流行，医学领域R应用更加少见，医学领域目前仍然以SPSS和SAS为主，本书主要目的在于介绍R在医学领域的应用。本书使用 markdown衍生版本R Markdown（Rmd）V2进行撰写，在TeXLive环境下使用xelatex编译，所有的R语言代码都基于knitr运行和生成。本书的所有代码都在R 3.2 下经过严格的测试。其中测试的操作系统为Linux Mint 17.2。

##R的安装
在Linux Mint下安装R，需要安装如下依赖库和编译库
```{r eval=FALSE}
sudo apt-get install build-essential gfortran libxml2-dev 
libcurl4-openssl-dev libfreetype6-dev libbz2-dev liblapack-dev  
libpcre++-dev liblzma-dev r-cran-rcpp r-cran-rjava openjdk-7-* 
  libgmp3-dev libmysql++-dev libmpfr-dev libgdal1-dev libproj-dev 
libglu1-mesa-dev r-cran-boot r-cran-class r-cran-cluster 
r-cran-codetools r-cran-foreign r-cran-kernsmooth r-cran-lattice 
r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme r-cran-nnet 
r-cran-rpart r-cran-spatial r-cran-survival r-cran-rodbc

#Step 1: Update Sources.List File
#- Edit the sources.list file
sudo gedit /etc/apt/sources.list
#- Add following entry
deb http://cran.rstudio.com/bin/linux/ubuntu trusty/
#Step 2: Add the Public Keys
gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9
gpg -a --export E084DAB9 | sudo apt-key add -
#Step 3: Install R-base
sudo apt-get update
sudo apt-get upgrade
sudo apt-get install r-base r-base-dev
```
安装Java的jdk时，在shell中运行 sudo R CMD javareconf命令，解决jdk安装问题。R 升级可通shell完成
```{r eval=FALSE}
sudo apt-get update
sudo apt-get upgrade
sudo apt-get install r-base
cp -r ~/R/x86_64-pc-linux-gnu-library/3.1/* 
  ~/R/x86_64-pc-linux-gnu-library/3.2 # at the shell prompt
update.packages(checkBuilt=TRUE, ask=FALSE) #at the R prompt 
```

本书涉及的R语言包较多，CRAN中包可通过下列方式一次性完成安装。
```{r eval=FALSE}
wants <- c("knitr","rmarkdown","devtools","epicalc","mosaic",
           "showtext","pander","PerformanceAnalytics","fitdistrplus",
           "CircStats","MASS","mixtools","boot","TrialSize","vcd",
           "ggplot2","pspearman","gvlma","car","lmtest","leaps",
           "plyr","bootstrap","elrm","rms","Deducer","bestglm",
           "survival","robust","mlogit","nnet","VGAM","ordinal",
           "Sample.Size","phia","mvtnorm","pscl","mosaic","XML",
           "pipeR","Rcmdr","rgl","HH","DescTools","multcomp",
           "effects","sandwich","qcc")

has   <- wants %in% rownames(installed.packages())
if(any(!has)) install.packages(wants[!has])
```
GitHub中R包通过以下方式进行安装
```{r eval=FALSE}
devtools::install_github("rstudio/rticles")
devtools::install_github("rstudio/rmarkdown")
```
bioconductor中R包通过以下方式进行安装
```{r eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite(c("GenomicFeatures", "AnnotationDbi","LBE"))
```
R-Forge等其它第三方源中的包，通过以下方式进行安装
```{r eval=FALSE}
install.packages("blotter", repos="http://R-Forge.R-project.org")
```
本书使用的R语言编译器是Rstudio，源代码托管于GitHub（https://github.com/xuefliang/RInMedicine）
。

##Rstudio安装
```{r eval=FALSE}
wget https://download1.rstudio.org/rstudio-0.99.486-amd64.deb
sudo dpkg -i /home/xuefliang/Downloads/rstudio-0.99.486-amd64.deb
```
## TexLive2014安装
```{r eval=FALSE}
mount -t iso9660 -o ro,loop,noauto texlive2014.iso /mnt 
cd /mnt ./install-tl 
umount -l /mnt
#安装完成后需要设置环境变量，即在～/profile下加入
vi ~/profile
PATH=/usr/local/texlive/2014/bin/x86_64-linux:$PATH; export PATH
MANPATH=/usr/local/texlive/2014/texmf-dist/doc/man:$MANPATH; export MANPATH
INFOPATH=/usr/local/texlive/2014/texmf-dist/doc/info:$INFOPATH; export INFOPATH
```
## Fandol 字体
```{r eval=FALSE}
wget http://mirrors.ctan.org/fonts/fandol.zip
#字体保存到 ~/.fonts 文件夹下
mkdir ~/.fonts
unzip ~/Downloads/fandol.zip
cp ~/Downloads/fandol/* ~/.fonts
cd ~/.fonts
fc-cache -fv
#测试
tex -v
#字体查看
fc-list :lang=zh-cn
```

由于水平有限，书中难免有错误和疏漏之处，诚恳地期望各位专家和读者批评指正，深表感谢。

#描述性统计
```{r include=FALSE}
library(epicalc)
library(mosaic)
library(showtext)
library(pander)
library(PerformanceAnalytics)
library(Hmisc)
library(pastecs)
library(psych)
library(plyr)
library(doBy)
library(vcd)
library(gmodels)
library(readr)
library(stringr)
library(dplyr)
library(reshape2)
```

统计分析分为统计描述和统计推断两个部分，统计描述是通过绘制统计图、计算统计量等方法描述数据的分布特征，是数据分析的基本步骤。

## 常用统计量
###矩
设X和Y是随机变量，若$$E(X^{k}),k=1,2,\cdot \cdot \cdot $$存在，则称它为X的k阶原点矩，简称k阶矩。
若$$E\left \{ [X-E(x)]^{k} \right \},k=2,3,\cdot \cdot \cdot$$存在，则称它为X的k阶中心距。
若$$E(X^{k}Y^{l}),k,l=1,2,\cdot \cdot \cdot$$存在，则称它为X和Y的k+l阶混合距。
若$$E\left \{ [X-E(X)]^{k}[Y-E(Y)]^{l} \right \},k,l=1,2,\cdot \cdot \cdot$$存在，则称它为X和Y的k+l阶混合中心距。
X的数学期望E(X)是X的一阶原点矩，方差D(X)是X的二阶中心矩，协方差Cov(X,Y)是X和Y的二阶混合中心矩。
###  均值(Mean)
一阶原点矩又称均数是一组数据的平均值,均数（记为$\bar{x}$）定义为
$$\bar{X}=\frac{1}{n}\sum _{i=1}^{n}X_{i}$$
用它来描述正态分布数据的集中趋势。
### 标准差(Standard Deviation)
样本方差定义为$$S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\bar{X})^{2}$$,标准差是方差的算术平方根，是一组数值自均数分散开来的程度的一种测量观念。定义为
$$\delta = \sqrt{\frac{1}{N}\sum_{i=1}^{n}(x_i-u)^2}$$
一个较大的标准差，代表大部分的数值和其平均值之间差异较大；一个较小的标准差，代表这些数值较接近平均值。
例 已知50名患者的收缩压（mmHg）分别为：
147 163 159 124 120  94 135 185 109 143 116 129 157 146 149 127 124 160 101 129 130 154 151
119 128 147 127 122 145 159 141 131 117 139 142 152 147 157 134 146 144 119 160 136 122 172
170 109 151 144
求血压的集中趋势和离散趋势及集中趋势的95%可信区间。
思路：先判断数据是否为正态分布，然后根据结果选择描述集中趋势的统计量。
```{r}
sbp <- c(147,163,159,124,120,94,135,185,109,143,116,129,157,146,149,
         127,124,160,101,129,130,154,151,119,128,147,127,122,145,159,
         141,131,117,139,142,152,147,157,134,146,144,119,160,136 ,
         122,172,170,109,151,144)
qqnorm(sbp)
qqline(sbp)
#plot(density(sbp)) 核密度
hist(sbp,freq = F) #freq=T,则绘制频数
result <- shapiro.test(sbp)
result
ks.test(sbp,"pnorm",mean(sbp),sd(sbp))
```
样本大小在3和5000之间,选择Shapiro-Wilk进行正态性检验。W值为`r result[1]`，P值为`r result[2]`大于0.05，不能拒绝其于正态分布一致的假设。如果样本数较大，可以选择Kolmogorov-Smirnov检验。对于服从正态分布的数据，选择均数和标准差描述其集中趋势和离散趋势。
```{r}
mean(sbp)
sd(sbp)
```
均值为`r mean(sbp)`,标准差为`r sd(sbp)`。对均数和标准差的计算还可以通过base包中的summary()函数，该函数提供了最小值、最大值、四分位数和数值型变量的均值，以及因子向量和逻辑型向量的频数统计。epicalc包中的summ()和mosaic包中的favstats()等函数也可获得类似结果，如favstats()一次就可以完成均数和标准差的计算。
```{r}
favstats(sbp)
```
对均数的95%可信区间的计算可通过t.test()获得，对一个给定的可信区间，它表示一个总体参数的估计范围。根据中位数和均数可以快速检查数据分布，如中位数小于均数，说明分布有可能向右倾斜。
```{r}
t.test(sbp)
```
通过设置conf.level=0.99，可以将可信区间水平提高到99%。
```{r}
t.test(sbp,conf.level=0.99)
```
###中位数(Median)
对于一组有限个数的数据来说，它们的中位数是这样的一种数：这群数据里的一半的数据比它大，而另外一半数据比它小。 计算有限个数的数据的中位数的方法是：把所有的同类数据按照大小的顺序排列。如果数据的个数是奇数，则中间那个数据就是这群数据的中位数；如果数据的个数是偶数，则中间那2个数据的算术平均值就是这群数据的中位数。通常用中位数来描述非正态分布数据的集中趋势，极值对中位数影响不大。定义为
实数$x_1$, $x_2$, $\dots$, $x_n$按大小顺序（顺序，降序皆可）排列为$x'_1$, $x'_2$, $\dots$ , $x'_n$、实数数列$x=(x_1, x_2, \dots , x_n)$的中位数$\mathrm{Q}_\frac{1}{2}(x)$为
$$\mathrm{Q}_\frac{1}{2}(x) = 
\begin{cases} 
 x'_\frac{n + 1}{2},                                  & \mbox{if } n \mbox{ is odd.} \\
 \frac{1}{2}( x'_\frac{n}{2} + x'_{\frac{n}{2} + 1}), & \mbox{if } n \mbox{ is even.} 
\end{cases}
$$
odd 为奇数，even 为偶数。
###四分位差(quartile deviation)
是上四分位数（QU，即位于75%）与下四分位数（QL，即位于25%）的差的一半。计算公式为：$Qd=QU-QL$。四分位差反映了中间50%数据的离散程度，其数值越小，说明中间的数据越集中；其数值越大，说明中间的数据越分散。四分位差不受极值的影响。
例 某地17名患者的月收入分别为：
23408 3468 1939 4360 23545 12233 4583 3546 35781 6578 8981 1345 5567 23455 23564 7623 14334
求收入的集中趋势和离散趋势及集中趋势的95%可信区间。
思路：仍然先判断数据是否为正态分布，然后根据结果选择描述集中趋势的统计量。
```{r}
income <- c(23408,3468,1939,4360,23545,12233,4583,3546,35781,6578,
            8981,1345,5567,23455, 23564,7623,14334)
qqnorm(income)
qqline(income)
#plot(density(income))
hist(income,freq = F)
result <- shapiro.test(income)
result
```
根据QQ图和Shapiro-Wilk进行正态性检验结果，W值为`r result[1]`，P值为`r result[2]`小于0.05，选择中位数和四分位差描述其集中趋势和离散趋势。
```{r}
quantile(income)
```
中位数为`r median(income)`，四分位差为75%的分位数减去25%的分位数。对中位数的可信区间估计，可通过wilcox.test()函数获得
```{r}
wilcox.test(income, conf.int=TRUE)
```
### 数学期望(mathematical expectation)
离散型随机变量：离散型随机变量的一切可能的取值$x_{i}$与对应的概率$P_{i}(=x_{i})$之积的和称为该离散型随机变量的数学期望，记为$E(X)$。数学期望是最基本的数学特征之一。它反映随机变量平均取值的大小
$$E(X)=\sum_{i}x_{i}p_{i}$$
连续型随机变量：若随机变量X的分布函数$F(x)$可表示成一个非负可积函数$f(x)$的积分，则称$X$为连续性随机变量，$f(x)$称为$X$的概率密度函数，积分值为X的数学期望，记为$E(X)$。
$$E(X)=\int_{-\infty }^{+\infty }xf(x)dx$$
###方差(Variance)
方差是各个数据与平均数之差的平方的平均数。在概率论和数理统计中，方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。
设$X$为随机变量，如果$E{[X-E(X)]^2}$存在，则称$E{[X-E(X)]^2}$为$X$的方差，记为$Var(X)$。
离散型随机变量方差计算公式为$$Var(X)=E(X^{2})-(E(X))^{2}$$,连续型随机变量方差计算公式为$Var(x)=\int_{-\infty}^{+\infty} (x-E(X))^{2}f(x) \text{d}x=E(X^{2})-(E(X))^{2}$
例 计算样本(2,5,78,45,89,124)的方差
```{r}
s <- c(2,5,78,45,89,124)
var(s)
```
###众数(Mode)
观察资料中出现次数最多的数值或类别，不受极值影响，由于可能有不只一个，也可能没有众数，一般不适合进行统计分析。
例 计算样本(4,22,31,33,3,27,27,27,27,569,110,8,21,31,33,33)的众数
```{r}
S <- c(4,22,31,33,3,27,27,27,27,569,110,8,21,31,33,33)
names(which.max(table(S)))
```
###协方差(Covariance)
协方差用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。设$X$,$Y$为两个随机变量，称$E{[X-E(X)][Y-E(Y)]}$为$X$和$Y$的协方差，记录$Cov(X,Y)$。方差是协方差的一种特殊情况，即当两个变量是相同的情况。
$$Cov(X,Y)=E\left \{ [X-E(X)][Y-E(Y)] \right \}=E(XY)-E(X)E(Y)$$
例 计算X(2,5,7)和Y(6,7,9)的协方差。
```{r}
x <- c(2,5,7)
y <- c(6,7,9)
cov(x,y)
```
###相关系数(Correlation coefficient)
相关系数是用以反映变量之间相关关系密切程度的统计指标。相关系数是按积差方法计算，同样以两变量与各自平均值的离差为基础，通过两个离差相乘来反映两变量之间相关程度。当$Var(X)>0, Var(Y)>0$时，称$Cov(X,Y)/sqrt(Var(X)*Var(Y))$为$X$与$Y$的相关系统。
$$\rho (X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$
例 计算X(2,5,7)和Y(6,7,9)的相关系数
```{r}
x <- c(2,5,7)
y <- c(6,7,9)
cor(x,y)
```
### 偏度(skewness)
是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。设分布函数$F(x)$有中心矩$\mu_{2}=E(X-E(X))^2$,$\mu_{3}=E(X-E(X))^3$,则$\frac{\mu_{3}}{\mu_{2}^{\frac{3}{2}}}$为偏度系数。当$C_{s}$>0时，概率分布偏向均值右则,$C_{s}$<0时，概率分布偏向均值左则。
$$C_{s}=\frac{\mu_{3}}{\mu_{2}^{\frac{3}{2}}}$$
###峰度(kurtosis)
表征概率密度分布曲线在平均值处峰值高低的特征数。峰度刻划不同类型的分布的集中和分散程序。设分布函数$F(x)$有中心矩$\mu_{2}=E(X-E(X))^2$, $\mu_{4}=E(X-E(X))^4$，则$C_{k}=\frac{\mu_{4}}{\mu_{2}^{2}}-3$为峰度系数。
$$C_{k}=\frac{\mu_{4}}{\mu_{2}^{2}}-3$$
例 计算10000个正态分布的样本的偏度和峰度
```{r}
S<-rnorm(10000)
skewness(S)
kurtosis(S)
hist(S,breaks=100)
```
###几何平均数（Geometric mean）
是n个变量值连乘积的n次方根,是用于反映一组经对数转换后呈对称分布的变量值在数量上的平均水平即对数正态分布数据，在医学研究中常适用于免疫学的指标。对于变量值呈倍数关系或呈对数正态分布（正偏态分布），如抗体效价及抗体滴度，某些传染病的潜伏期，细菌计数等，宜用几何均数表示其平均水平。
$$H=G=\sqrt[n]{X_{1}*X_{2}*...*X_{n}}=\sum \sqrt[n]{\prod_{i=1}^{n}X_{n}}$$
例 5名学龄儿童的麻疹血凝抑制抗体滴度为1：25，1：50，1：50，1：100，1：400，求几何均数及标准差。
```{r}
geomean <- function(x, na.rm = FALSE, trim = 0, ...)
{
  exp(mean(log(x, ...), na.rm = na.rm, trim = trim, ...))
}
geosd <- function(x, na.rm = FALSE, ...)
{
  exp(sd(log(x, ...), na.rm = na.rm, ...))
}
s<-c(25,50,50,100,400)
shapiro.test(log(s))
geomean(s)
geosd(s)
```
也可以安装NCStats包，调用geomean和geosd()函数。
###变异系数（Coefficient of Variation）
是刻画数据相对分散性的一种度量，记为$c_v$,是概率分布离散程度的一个归一化量度，其定义为标准差$\ \sigma$与平均值$\ \mu$ 之比
$$c_v = {\sigma \over \mu }$$
###样本校正平方和（CSS）
样本与均值差的平方的求和$CSS=\sum_{i=1}^{n}(x_{i}-\overline{x})$
###样本未校正平方和（USS）
样本值平方的求和$USS=\sum_{i=1}^{n}x_{i}^{2}$
###标准误（Standard Deviation）
是某种统计量在抽样分布上的标准差称为该种统计量的标准误，即样本统计量的标准差，是描述对应的样本统计量抽样分布的离散程度及衡量对应样本统计量抽样误差大小的尺度。设n个测量值的误差为v1、v2……vn，则这组测量值的标准误差$\sigma$
$$\sigma =\sqrt{\frac{1}{n-1}\sum_{i=1}^{n}v_{i}^2}$$
###极差
描述样本分散性，数据越分散，其极差越大。
$$R=max(x)-min(x)$$
例 对例1求变异系数、样本校正平方和、样本未校正平方和、极差和均值的标准误。
```{r}
cv <- 100*sd(sbp)/mean(sbp)
cv
css <- sum((sbp-mean(sbp))^2)
css
uss <- sum(sbp^2)
uss
r <- max(sbp)-min(sbp)
r
```
通常由于总体的均数或总体的方差并不知道，样本均值的标准误$SD=\frac{s}{\sqrt{n}}$,s为标准差，n为样本数。
```{r}
sd <- sd(sbp)/sqrt(length(sbp))
sd
```
###数据中心化和标准化
数据中心化是将某变量中的观察值减去该变量的平均数，数据标准化将某变量中的观察值减去该变量的平均数，然后除以该变量的标准差。经标准化的数据都是没有单位的纯数量。对变量进行的标准差标准化可以消除量纲（单位）影响和变量自身变异的影响。
例 对下表中三科成绩进行标准化。
Math  Science	English
---   ---     ---
502	  95	    25
465	  67      12
621	  78      22
575	  66      18
454	  96      15
634	  89      30
576	  78      37
421	  56      12
599	  68      22
666	  100     38

R语言中scale()函数可以实现数据标准化，两个参数center和scale为True分别表示计算中心化和标准化
```{r}
Math <- c(502,465,621,575,454,634,576,421,599,666)
Science <- c(95,67,78,66,96,89,78,56,68,100)
English <- c(25,12,22,18,15,30,37,12,22,38)

Student <- as.data.frame(cbind(Math,Science,English))

options(digits=2) #限定为2位小数
scale(Student[,1:3],center = T,scale = F) #数据中心化 
scale(Student[,1:3],center = F,scale = T) #数据标准化
```
apply()函数或sapply()函数计算所选择的任意描述性统计量。对于sapply()函数，其使用格式为：sapply(x,FUN,options)其中的x是输入的数据框（或矩阵），FUN为一个任意的函数。如果指定了options，它们将被传递给FUN。你可以在这里插入的典型函数有mean、sd、var、min、max、median、length、range和quantile。可以根据需要自定义需要的统计量，如下
```{r}
mystats <- function(x, na.omit = FALSE) {
  if (na.omit) 
    x <- x[!is.na(x)]
  m <- mean(x)
  n = length(x)
  s <- sd(x)
  skew <- sum((x - m)^3/s^3)/n
  kurt <- sum((x - m)^4/s^4)/n - 3
  return(c(n = n, mean = m, stdev = s, skew = skew, kurtosis = kurt))
}

data(drugDat,package = "elrm")
sapply(drugDat,mystats)
```
Hmisc包中的describe()函数可返回变量和观测的数量、缺失值和唯一值的数目、平均值、分位数，以及五个最大的值和五个最小的值。pastecs包中有一个名为stat.desc()的函数，它可以计算种类繁多的描述性统计量。使用格式为：stat.desc(x,basic=TRUE,desc=TRUE,norm=FALSE,p=0.95)其中的x是一个数据框或时间序列。若basic=TRUE（默认值），则计算其中所有值、空值、缺失值的数量，以及最小值、最大值、值域，还有总和。若desc=TRUE（同样也是默认值），则计算中位数、平均数、平均数的标准误、平均数置信度为95%的置信区间、方差、标准差以及变异系数。最后，若norm=TRUE（不是默认的），则返回正态分布统计量，包括偏度和峰度（以及它们的统计显著程度）和Shapiro–Wilk正态检验结果。这里使用了p值来计算平均数的置信区间（默认置信度为0.95）。psych包也拥有一个名为describe()的函数，它可以计算非缺失值的数量、平均数、标准差、中位数、截尾均值、绝对中位差、最小值、最大值、值域、偏度、峰度和平均值的标准误。

##数据操作
###数据输入
readr包中的函数使数据读入的速度更快，相对于基础包中的函数，对字符类型并不需要指定stringsAsFactors = FALSE防止字符类型自动转为因子，对列名限制更少。固定分割的数据使用read_delim(), read_csv(), read_tsv()和read_csv2()函数，固定宽度的数据使用read_fwf()和 read_table()。
```{r warning=F}
WHO<- read_csv("WHO.csv",col_names=T) #col_names相当于header=T，默认为True
#可以从压缩包或网站上直接输入
mtcars <- read_csv(system.file("extdata/mtcars.csv.bz2", package = "readr"))
#mtcars <- read_csv("https://github.com/hadley/readr/raw/master/inst/extdata/mtcars.csv")
```
###数据输出
用readr包读入的数据，变量的引用使用如下格式WHO$`Adolescent fertility rate (%)`，不同于通常的引用。write_csv()将数据框快速的输出为csv文件。
```{r}
who <- read_csv("WHO.csv", col_types = list(
  CountryID = col_integer(),
  Continent=col_double(),
  Country=col_factor(c("Country")) 
  #col_date() 使用Y-m-d格式，col_datetime()使用 ISO8601日期时间格式
))
class(who) #tbl_df、tbl和data.frame类型
```
###字符串操作
####合并字符串
```{r}
IT <- c("google","baidu","bing")
res <- str_c(1:3,IT,sep=' ',collapse=' ')
str_c('My work place is ',res,collapse=' ')
```
####计算字符串长度
```{r}
str_length(c("programming R and Python", 123,res))
```
####按位置取子字符串
```{r}
str_sub(IT, 1, 3)
```
####子字符串重新赋值
```{r}
capital <-toupper(str_sub(IT,1,1))
str_sub(IT, rep(1,3),rep(1,3)) <- capital 
```
####重复字符串
```{r}
str_dup(IT, c(2,3,4))
```
####加空白和去除空白
```{r}
str_pad(IT, 10, "both")
str_trim(IT)
```
####根据正则表达式检验是否匹配
```{r}
str_detect(IT, "g$")  #查找以g结尾
str_detect(IT, "[aiu]") #查找是否包含a、i、u
```
####查找匹配的字符串位置
```{r}
str_locate(IT, "a")  #返回起始和结束的位置
```
####提取匹配的部分
```{r}
str_extract(IT, "[a-z]+")
str_extract(IT, "[a-z]{1,3}")
str_match(IT, "[a-z]+")
```
####替换匹配的部分
```{r}
str_replace(IT, "[aeiou]", "-")
```
####分割
```{r}
str_split(res, " ")
```
###数据操作
dplyr包将plyr包中的ddply()等函数进一步分离强化,专注接受dataframe对象,大幅提高了运算速度,并且提供了更稳健的与其它数据库对象间的接口。

####数据集类型
将过长过大的数据集转换为显示更友好的tbl_df类型
```{r}
iris_df<- tbl_df(iris)
iris_df
```
####筛选
filter 用于选择满足条件的观测（行），第一个参数是 data frame 名字，第二个参数是条件。
```{r}
#选取 Species == versicolor的观测
filter(iris_df, Species == "versicolor") 
#选取Sepal.Length为7.0，5.2，6.6的观测
filter(iris_df, Sepal.Length %in% c(7.0, 5.2,6.6)) 
```
对于多条件的选择，需要完整条件的，然后使用集合运算符将条件拼接起来。集合运算符有 !、|、&、xor(交补)。条件的判断符有>(=)、<(=)、==、!=、%in% (判断元素是否在集合或者列表内，返回逻辑值)。
```{r}
filter(iris_df, Sepal.Length>=6.3 & Species=="versicolor")
```
####排列
arrange 用于根据变量排序，如果排序依据（列）是字符，按照字母表的顺序，如果是数字，默认按照从小到大的顺序排序，如果需要使用逆序排，可以使用desc(var) 或者 -var。
```{r}
arrange(iris_df, Petal.Length)
arrange(iris_df, desc(Petal.Length))
```
####选择
select 用于选择列,类似于R自带的 subset() 函数,select中负号表示不选择。其中变量的声明还有其他形式，比如B:F表示从 B 列到 F 列所有列；ends_with("string") 表示选取列名以 string 结尾的全部列；contains("string") 表示选取列名中含有 string 的所有列。
```{r}
select(iris_df, Petal.Length)
```
####变形
mutate用于添加新的变量，直接使用列名进行计算得到新变量即可。可使用刚添加的变量，也就是在一个语句中可以多个变量，而且变量可以来源于刚新建的变量。
```{r}
mutate(iris_df, double=Petal.Length*2,quadruple=double*2)
```
####分类汇总
summarise可以用于分类汇总,实际上它是把 data frame 依据分组依据拆分成多个data frame，然后对每data frame 分别计算，类似于ddply。summarise 可以使用的函数有：min(x), median(x), max(x), quantile(x, p)，计算个数n(), 计算 x 中唯一值的个数n_distinct(), sum(x), mean(x),sum(x > 10), mean(x > 10),sd(x), var(x), iqr(x), mad(x)
```{r}
group <- group_by(iris_df, Species)  # 分组依据
summarise(group, Speciessum = sum(Sepal.Length), 
          Speciesmean=mean(Petal.Length, na.rm = TRUE)) #分组求和
```
####管道操作
%>%与pipeR和magrittr包中%>%操作符一样，用来将上一步产生的对象管道输出为下一步调用的函数的第一个参数。
```{r}
iris_df %>% group_by(Species) %>% 
  summarise(total = sum(Sepal.Length)) %>%
  arrange(desc(total)) %>%head(5)
```
####变量查重
通常用select指定需要查重的变量，distinct返回没有重复的数据。
```{r}
#Sepal.Length,Species这两列中没有重复的数据
distinct(select(iris_df, Sepal.Length,Species)) 
```
####随机抽样
使用sample_n和sample_frac从数据框中随机的返回一些行，sample_n按指定的行数返回，sample_frac按指定的比例返回。
```{r}
sample_n(iris, 10)  #返回10行
sample_frac(iris, 0.01) #返回总行数的0.01倍
```
###长宽格式数据转换
在wide format中，每一个样本点(subject)自成一行，这一行内记录了这个样本点的所有信息。典型的宽格式数据如下：
```{r}
data_wide <- read.table(header=TRUE, text='
 subject sex control cond1 cond2
       1   M     7.9  12.3  10.7
       2   F     6.3  10.6  11.1
       3   F     9.5  13.1  13.8
       4   M    11.5  13.4  12.9
')
data_wide
```
long format把wide format中的某几个numerical variables变成了一个factor variable之下的levels，而这几个numerical variables的取值都被集中在了一个变量之下。reshape2包中melt函数把wide format变成long format。
```{r}
data_long <- melt(data_wide,
     id.vars = c('subject', 'sex'),
          #ID variables 是指将被保存在long format中的变量,它起到指示样本点的作用
     variable.name = 'condition', 
     value.name = 'measurement')
data_long
```
在long format中，每个样本点被拆成了三个行，两个新的变量出现。第一个新变量是一个factor variable，fator levels是wide format中的三个变量。第二个新变量是一个numeric variable，记录的数值对应于wide format中该样本点在control, cond1, cond2三列的取值。除了id.variable之外，其他变量都被变成了long format的形式,数据的长短是相对的，如果把没有转换的sex变量转换掉，数据将变得更长。
```{r}
melt(data_wide, id.vars = 'subject')
```
Wide format转换为long format时，最极端的情况是所有变量都转换掉
```{r}
melt(data_wide, id.vars = NULL)
```
reshape2包中Cast函数把long format变成wide format的函数，dcast针对data.frame，acast针对的是array或matrices。dcast中需要一个formular来说明转换的形式，formular的左边是id variables，右边是一个factor variables，它的factor levels将会在wide format中成为新的variables，这些variables的取值用value.var来指定，最后得到的wide format如下：
```{r}
data.wide <- dcast(data_long, subject + sex ~ condition, value.var = "measurement")
data.wide
```
###分类汇总
在比较多组个体或观测时，关注的焦点经常是各组的描述性统计信息，而不是整体的描述性统计信息时，可以使用aggregate()分组获取描述性统计量。
例 epicalc中HW93数据集是1993年泰国南部钩虫感染的调查资料，其中intense变量表示感染的严重程度为有序多分类变量，egp为感染的数量，shoes表示是否穿鞋，agegr是年龄分组,需要计算每个年龄的构虫平均感染钩虫的数量。
使用aggregate()分组获取描述性统计量
```{r}
data(HW93,package = "epicalc")
aggregate(HW93$epg,by=list(epg=HW93$agegr),mean)
```
注意list(epg=HW93$age)的使用。如果使用的是list(HW93$age)，则age列将被标注为Group.1而不是age。如果有多个分组变量，可以使用by=list(name1=groupvar1, name2=groupvar2, ... , groupvarN)这样的语句。aggregate()仅允许在每次调用中使用平均数、标准差这样的单返回值函数。
doBy包和psych包也提供了分组计算描述性统计量的函数，doBy包中summaryBy()函数的使用格式为：summaryBy(formula,data=dataframe,FUN=function) 其中的formula接受以下的格式：var1+var2+…+varN~grounpvar1+goupvar2+…+groupvarN,在~左侧的变量是需要分析的数值型变量，而右侧的变量是类别型的分组变量。function可为任何内建或用户自编的R函数。psych包中的describe.by()函数可计算和describe相同的描述性统计量，只是按照一个或多个分组变量分层，使用psych包中的describe.by()和使用doBy包中的summaryBy()分组计算概述统计量如下，describe.by()函数不允许指定任意函数，所以它的使用范围较窄。若存在一个以上的分组变量，你可以使用list(groupvar1, groupvar2, ... , groupvarN)来表示它们。但这仅在分组变量交叉后不出现空白单元时有效。
```{r}
summaryBy(epg~agegr,data=HW93,FUN=max)
describe.by(HW93$epg,HW93$agegr)
```
需要使用复杂函数则需要plyr包中的*ply族函数。该函数将这类任务以“分割-应用-结合”这种三步方式进行处理：通过一种或多种factor将数据集进行分割，而后应用某项函数，最后将结果整合回数据集当中。Plyr包中囊括了一整套“ply”函数，其第一个字母表示输入的类型，第二个字母表示输出的类型，输入:array,dataframe,list三种格式，输出: array,dataframe,list,discareded四种格式。plyr包中的ddply()可以得到相同结果。summarize不会提供来自原始数据框中其它列中的任何信息，如果需要列出其它column数据，则可以把“summarize”替换为“transform”，且允许一次应用多个函数。
```{r eval=FALSE}
ddply(.data = HW93,.(agegr),summarize,mean=mean(epg),max=max(epg),min=min(epg))

rate <- function(x){
  return(sum(x,na.rm = T)/length(x))
}
ddply(.data = HW93,.(agegr),.fun = function(x){rate(x$epg)})
```
##频数表和列联表
table(var1, var2, …, varN) 使用 N 个类别型变量（因子）创建一个 N 维列联表。xtabs(formula, data) 根据一个公式和一个矩阵或数据框创建一个 N 维列联表。prop.table(table, margins) 依margins定义的边际列表将表中条目表示为分数形式。margin.table(table, margins) 依margins定义的边际列表计算表中条目的和addmargins(table, margins) 将概述边margins（默认是求和结果）放入表中。ftable(table) 创建一个紧凑的“平铺”式列联表
###一维列联表
```{r}
data(Arthritis,package = "vcd")
pander(head(Arthritis))
mytable<-with(Arthritis,table(Improved))
mytable
```
可以用prop.table()将这些频数转化为比例值
```{r}
prop.table(mytable)
```
###二维列联表
对于二维列联表，table()函数的使用格式为：table(A,B),其中的A是行变量，B是列变量。xtabs()函数还可使用公式风格的输入创建列联表，格式为：xtabs(\~A+B,data=mydata)，其中的mydata是一个矩阵或数据框，要进行交叉分类的变量应出现在公式的右侧（即\~符号的右方），以+作为分隔符。若某个变量写在公式的左侧，则其为一个频数向量（在数据已经被表格化时很有用）。
```{r}
mytable<-xtabs(~Treatment+Improved,data=Arthritis)
mytable
```
可以使用margin.table()和prop.table()函数分别生成边际频数(行和)和比例(行比)。
```{r}
margin.table(mytable,1)
prop.table(mytable,1)
```
列和与列比例可以这样计算
```{r}
margin.table(mytable,2)
prop.table(mytable,2)
```
各单元格所占比例可用如下语句获取
```{r}
prop.table(mytable)
```
可以使用addmargins()函数为这些表格添加边际和
```{r}
addmargins(mytable)
addmargins(prop.table(mytable))
```
在使用addmargins()时，默认是表中所有的变量创建边际和
```{r}
addmargins(prop.table(mytable,1),2)
```
注意 table()函数默认忽略缺失值（NA）。要在频数统计中将NA视为一个有效的类别，请设定参数useNA="ifany"。
```{r}
table(Arthritis$Treatment,Arthritis$Improved,useNA = "ifany")
```
使用gmodels包中的CrossTable()函数生成二维列联表
```{r}
CrossTable(Arthritis$Treatment,Arthritis$Improved)
```
CrossTable()函数有很多选项计算（行、列、单元格）的百分比；指定小数位数；进行卡方、Fisher和McNemar独立性检验；计算期望和（皮尔逊、标准化、调整的标准化）残差；将缺失值作为一种有效值；进行行和列标题的标注;

###多维列联表
table()和xtabs()都可以基于三个或更多的类别型变量生成多维列联margin.table()、prop.table()和addmargins()函数也可以推广到多维的情况。另外，ftable()函数可以以一种紧凑而吸引人的方式输出多维列联表
```{r}
mytable<-xtabs(~Treatment+Sex+Improved,data=Arthritis)
mytable
ftable(mytable)
margin.table(mytable,c(1,3))#治疗情况（Treatment） × 改善情况（Improved）的边际频数
```

```{r,echo=FALSE}
try(detach(package:epicalc))
try(detach(package:mosaic))
try(detach(package:showtext))
try(detach(package:pander))
try(detach(package:PerformanceAnalytics))
try(detach(package:Hmisc))
try(detach(package:pastecs))
try(detach(package:psych))
try(detach(package:plyr))
try(detach(package:doBy))
try(detach(package:vcd))
try(detach(package:gmodels))
try(detach(package:readr))
try(detach(package:stringr))
try(detach(package:dplyr))
try(detach(package:reshape2))
```

#常用数据分布
```{r include=FALSE}
library(fitdistrplus)
library(CircStats)
library(ggplot2)
```

如果给定一种概率分布，通常会有四类计算问题：计算其概率密度density(d);计算其概率分布probability(p);计算其百分位数quantile(q);随机数模拟random(r),R中常见的函数、分布和参数如下

R funciton    Distribution	       Parameters
----          ----                 ----
beta	        beta	               shape1,shape2
binom	        binomial	           sample,size,probability
cauchy	      Cauchy	             location,scale
exp	          exponential	         rate(optional)
chisq	        Chi-squared	         degrees of freedom
f	            Fisher's F	         df1,df2
gamma	        gamma	               shape
geom	        geometric	           probability
hyper	        hypergeometric	     m,n,k
lnorm	        lognormal	           mean,standard deviation
logis	        logistic	           location,scale
nbinom	      negative binomial    size,probability
norm	        normal	             mean,standard deviation
pois	        Poisson	             mean
signrank    	Wilcoxon signed rank sample size n
t	            Student's t	         degree of freedom
unif	        uniform	             minimum,maximum(opt.)
weibull	      Weibull	             shape
wilcox	      Wilcoxon rank sum    m,n

##正态分布(Normal distribution)
又名高斯分布(Gaussian distribution)，是一个在数学、物理及工程等领域都非常重要的概率分布，在统计学的许多方面有着重大的影响力。若随机变量X服从一个数学期望为$μ$、方差为$\sigma^2$的正态分布，记为$N(u，\sigma^2)$。其概率密度函数为正态分布的期望值$u$决定了其位置，其标准差$\sigma^2$决定了分布的幅度。因其曲线呈钟形，因此人们又经常称之为钟形曲线。我们通常所说的标准正态分布是$u$ = 0,$\sigma$ = 1的正态分布。
概率密度函数
$$f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma ^2}}$$
```{r}
fun1 <- function(x){
  y <- dnorm(x,mean = 0,sd = 1)
  return(y)
}
  
fun2 <- function(x){
  y <- dnorm(x,mean = 0,sd = 0.5)
  return(y)
} 

fun3 <- function(x){
  y <- dnorm(x,mean = 0,sd = 2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x = -5:5, g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x = -5:5, g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x = -5:5, g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red","green","blue"))+ylab(label = "density")+
  labs(title="The Normal Density Distribution")
```

累积分布函数
$$F(x;u,\sigma )=\frac{1}{\sqrt{2\pi}\sigma} \int_{-\infty }^{x}exp(-\frac{(t-u)^2}{2\sigma ^2})dt$$
```{r}
fun1 <- function(x){
  y <- pnorm(x,mean = 0,sd = 1)
  return(y)
}
  
fun2 <- function(x){
  y <- pnorm(x,mean = 0,sd = 0.5)
  return(y)
} 

fun3 <- function(x){
  y <- pnorm(x,mean = 0,sd = 2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x = -5:5, g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x = -5:5, g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x = -5:5, g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Normal Cumulative Distribution")
```
分布检验
Shapiro-Wilk正态分布检验: 用来检验是否数据符合正态分布，类似于线性回归的方法一样，是检验其于回归曲线的残差。该方法推荐在样本量很小的时候使用，样本在3到5000之间。该检验原假设为$H_{0}$:数据集符合正态分布，统计量W为：
$$W=\frac{(\sum_{i=1}^{n}a_{i}x_{(i)})^2}{\sum_{i=1}^{n}(x_{i}-\bar{x})^2}$$
统计量W 最大值是1，越接近1，表示样本与正态分布匹配,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rnorm(1000)
shapiro.test(S)
```
结论: W接近1，p-value>0.05，不能拒绝原假设，所以数据集S符合正态分布！

Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合正态分布，$H_{1}$:样本所来自的总体分布不符合正态分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近正态分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝H_{0}
```{r}
set.seed(1)
S<-rnorm(1000)
ks.test(S, "pnorm")
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合正态分布！

## 指数分布
指数分布(Exponential distribution)用来表示独立随机事件发生的时间间隔，比如旅客进机场的时间间隔、中文维基百科新条目出现的时间间隔等等。许多电子产品的寿命分布一般服从指数分布。有的系统的寿命分布也可用指数分布来近似。它在可靠性研究中是最常用的一种分布形式。指数分布是伽玛分布和weibull分布的特殊情况，产品的失效是偶然失效时，其寿命服从指数分布。指数分布可以看作当weibull分布中的形状系数等于1的特殊分布，指数分布的失效率是与时间t无关的常数，所以分布函数简单。
概率密度函数
$$f(x;\lambda)=\left\{\begin{matrix} \lambda e^{-\lambda x},x>=0
 &  & \\ 0,x<0
\end{matrix}\right.$$
其中$\lambda$> 0是分布的一个参数，常被称为率参数（rate parameter）。即每单位时间发生该事件的次数。指数分布的区间是$[0,\infty)$。 如果一个随机变量X 呈指数分布，则可以写作：$X$ ~ Exponential（$\lambda$）。
```{r}
fun1 <- function(x){
  y <- dexp(x,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <- dexp(x,1)
  return(y)
} 

fun3 <- function(x){
  y <- dexp(x,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Exponential Density Distribution")
```
累积分布函数
$$F(x;\lambda)=\left\{\begin{matrix} 1-e^{\lambda x},x>=0
 &  & \\ 0,x<0
\end{matrix}\right.$$
```{r}
fun1 <- function(x){
  y <- pexp(x,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <- pexp(x,1)
  return(y)
} 

fun3 <- function(x){
  y <- pexp(x,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,3,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Exponential Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近指数分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rexp(1000)
ks.test(S, "pexp")
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合指数分布！

##γ(伽玛)分布
伽玛分布(Gamma)是著名的皮尔逊概率分布函数簇中的重要一员，称为皮尔逊Ⅲ型分布。它的曲线有一个峰，但左右不对称。伽玛分布中的参数α，称为形状参数，β称为尺度参数。
$$Ga(x)=\frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}e^{-\frac{x}{\beta}},x>0$$
伽玛函数为：
$$\Gamma(x)=\int_{0}^{\infty }t^{x-1}e^{-t}dt$$
伽玛函数是阶乘在实数上的泛化。
概率密度函数
$$f(x)=x^{k-1}\frac{exp(-x/\theta )}{\Gamma (k)\theta^{k}}$$
```{r}
fun1 <- function(x){
  y <- dgamma(x,1,2)
  return(y)
}
  
fun2 <- function(x){
  y <- dgamma(x,2,2)
  return(y)
} 

fun3 <- function(x){
  y <- dgamma(x,5,1)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Gamma Density Distribution")
```
累积分布函数
$$f(x)=\frac{\gamma (k,x/\theta )}{\Gamma (k)}$$
```{r}
fun1 <- function(x){
  y <- pgamma(x,1,2)
  return(y)
}
  
fun2 <- function(x){
  y <- pgamma(x,2,2)
  return(y)
} 

fun3 <- function(x){
  y <- pgamma(x,5,1)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Gamma Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近γ(伽玛)分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rgamma(1000,1)
ks.test(S, "pgamma", 1)
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合shape=1伽玛分布！
```{r}
ks.test(S, "pgamma", 2)
```
结论:D值不够小, p-value<0.05，拒绝原假设，所以数据集S符合shape=2伽玛分布！

##weibull分布
weibull(韦伯)分布，又称韦氏分布或威布尔分布，是可靠性分析和寿命检验的理论基础。Weibull分布能被应用于很多形式，分布由形状、尺度（范围）和位置三个参数决定。其中形状参数是最重要的参数，决定分布密度曲线的基本形状，尺度参数起放大或缩小曲线的作用，但不影响分布的形状。Weibull分布通常用在故障分析领域( field of failure analysis)中；尤其是它可以模拟(mimic) 故障率(failture rate)持续( over time)变化的分布。故障率为：
一直为常量(constant over time)， 那么 $\alpha$ = 1， 暗示在随机事件中发生
一直减少(decreases over time)，那么$\alpha$ < 1， 暗示"早期失效(infant mortality)"
一直增加(increases over time)，那么$\alpha$ > 1， 暗示"耗尽(wear out)" 随着时间的推进，失败的可能性变大
概率密度函数
$$f(x;\lambda,k)=\left\{\begin{matrix}
{k/\lambda (x/\lambda)^{k-1}e^{-(x/\lambda)^{k}}}, \quad x\geq 0
 & \\ 0,\quad x<0
 & 
\end{matrix}\right.$$
```{r}
fun1 <- function(x){
  y <- dweibull(x,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <- dweibull(x,1)
  return(y)
} 

fun3 <- function(x){
  y <- dweibull(x,5)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Weibull Density Distribution")
```
累积分布函数
$$ F(x)=1-e^{-(x/\lambda)^{k}}$$
```{r}
fun1 <- function(x){
  y <- pweibull(x,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <- pweibull(x,1)
  return(y)
} 

fun3 <- function(x){
  y <- pweibull(x,5)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,2.5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Weibull Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近weibull分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rweibull(1000,1)
ks.test(S, "pweibull",1)
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合shape=1的weibull分布！

## F分布
F-分布（F-distribution）是一种连续概率分布，被广泛应用于似然比率检验，特别是ANOVA中。F分布定义为：设X、Y为两个独立的随机变量，X服从自由度为k1的卡方分布，Y服从自由度为k2的卡方分布，这2 个独立的卡方分布被各自的自由度除以后的比率这一统计量的分布。即： 上式F服从第一自由度为k1，第二自由度为k2的F分布。
F分布是一种非对称分布它有两个自由度，即n1 -1和n2-1，相应的分布记为F（ n1 –1， n2-1）， n1 –1通常称为分子自由度， n2-1通常称为分母自由度
F分布是一个以自由度n1 –1和n2-1为参数的分布族，不同的自由度决定了F 分布的形状
F分布的倒数性质：$F\alpha,df1,df2=1/F1-\alpha,df1,df2[1]$
概率密度函数
$$f(x)=\frac{\sqrt{\frac{d1x^{d1}d2^{d2}}{(d1x+d2)^{d1+d2}}}}{xB(\frac{d1}{2},\frac{d2}{2})}$$
B是Beta函数(beta function)
```{r}
fun1 <- function(x){
  y <- -df(x,1,1,0)
  return(y)
}
  
fun2 <- function(x){
  y <- -df(x,1,1,2)
  return(y)
} 

fun3 <- function(x){
  y <- -df(x,2,2,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The F Density Distribution")
```
累积分布函数
$$F(x)=I\frac{d1x}{d1x+d2}(d1/2,d2/2)$$
I是不完全Beta函数
```{r}
fun1 <- function(x){
  y <- -pf(x,1,1,0)
  return(y)
}
  
fun2 <- function(x){
  y <- -pf(x,1,1,2)
  return(y)
} 

fun3 <- function(x){
  y <- -pf(x,2,2,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The F Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近F分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rf(1000,1,1,2)
ks.test(S, "pf", 1,1,2)
```

## T分布
学生t-分布（Student's t-distribution），可简称为t分布。应用在估计呈正态分布的总体的平均数。它是对两个样本均值差异进行显著性测试的学生t检定的基础。学生t检定改进了Z检定（Z-test），因为Z检定以总体标准差已知为前提。虽然在样本数量大（超过30个）时，可以应用Z检定来求得近似值，但Z检定用在小样本会产生很大的误差，因此必须改用学生t检定以求准确。在总体标准差未知的情况下，不论样本数量大或小皆可应用学生t检定。在待比较的数据有三组以上时，因为误差无法压低，此时可以用变异数分析（ANOVA）代替学生t检定。
概率密度函数
$$f(x)=\frac{\Gamma ((\nu+1)/2)}{\sqrt{\nu \pi }\Gamma (\nu/2)(1+x^{2}/\nu)^{(v1+1)/2}}$$
$v$ 等于n − 1。 T的分布称为t-分布。参数$\nu$ 一般被称为自由度。
$\gamma$是伽玛函数。
```{r}
fun1 <- function(x){
  y <-dt(x,1,0)
  return(y)
}
  
fun2 <- function(x){
  y <-dt(x,5,0)
  return(y)
} 

fun3 <- function(x){
  y <-dt(x,5,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The T Density Distribution")
```
累积分布函数
$$f(x)=\frac{1}{2}+\frac{x\Gamma((\nu+1)/2)_{2}F_{1}(\frac{1}{2},(\nu+1)/2;\frac{3}{2};-\frac{x^{2}}{v})}{\sqrt{\nu \pi }\Gamma (\nu/2)}$$
$\nu$等于n − 1。 T的分布称为t-分布。参数$\nu$一般被称为自由度。
$\gamma$是伽玛函数。
```{r}
fun1 <- function(x){
  y <-pt(x,1,0)
  return(y)
}
  
fun2 <- function(x){
  y <-pt(x,5,0)
  return(y)
} 

fun3 <- function(x){
  y <-pt(x,5,2)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(-5,5,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The T Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近T分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rt(1000, 1,2)
ks.test(S, "pt", 1, 2)
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合df1=1, ncp=2的T分布！

##β(贝塔Beta)分布
贝塔分布(Beta Distribution)是指一组定义在(0,1)区间的连续概率分布，Beta分布有α和β两个参数$\alpha$,$\beta$>0，其中$\alpha$为成功次数加1，$\beta$为失败次数加1。Beta分布的一个重要应该是作为伯努利分布和二项式分布的共轭先验分布出现，在机器学习和数理统计学中有重要应用。贝塔分布中的参数可以理解为伪计数，伯努利分布的似然函数可以表示为，表示一次事件发生的概率，它为贝塔有相同的形式，因此可以用贝塔分布作为其先验分布。
概率密度函数
$$f(x)=\frac{1}{B(\alpha,\beta )}(x^{\alpha-1})(1-x)^{\beta-1}$$
随机变量X服从参数为$\alpha,\beta$，服从Beta分布
$\gamma$是伽玛函数
```{r}
fun1 <- function(x){
  y <-dbeta(x,0.5,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <-dbeta(x,5,1)
  return(y)
} 

fun3 <- function(x){
  y <-dbeta(x,1,3)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Beta Density Distribution")
```
累积分布函数
$$F(x;\alpha,\beta )=\frac{B_{x}(\alpha,\beta)}{B(\alpha,\beta)}=I_{x}(\alpha,\beta)$$
I是正则不完全Beta函数
```{r}
fun1 <- function(x){
  y <-pbeta(x,0.5,0.5)
  return(y)
}
  
fun2 <- function(x){
  y <-pbeta(x,5,1)
  return(y)
} 

fun3 <- function(x){
  y <-pbeta(x,1,3)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,1,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Beta Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近β(贝塔Beta)分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rbeta(1000,1,2)
ks.test(S, "pbeta",1,2)
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合shape1=1, shape2=2的Beta分布！

## $\chi^2$(卡方)分布
总体$X\sim N(\mu,\sigma^{2})$,则样本的统计量$\frac{1}{\sigma ^{2}}\sum_{i=1}^{n}(X_{i}-\mu)$,服从自由度为n的$\chi^2$分布。样本统计量$\frac{1}{\sigma ^{2}}\sum_{i=1}^{n}(X_{i}-\bar{X})$,服从自由度为n-1的$\chi^2$分布。
若n个相互独立的随机变量$\varepsilon _{1},\varepsilon _{2},...,\varepsilon _{n}$ ，均服从标准正态分布（也称独立同分布于标准正态分布），则这n个服从标准正态分布的随机变量的平方和构成一新的随机变量，其分布规律称为$\chi^2$分布（chi-square distribution）。其中参数n称为自由度，自由度不同就是另一个$\chi^2$分布，正如正态分布中均值或方差不同就是另一个正态分布一样。
概率密度函数
$$f_{k}(x)=\frac{(1/2)^{k/2}}{\Gamma (k/2)}x^{k/2-1}e^{-x/2}$$
$\gamma$是伽玛函数
```{r}
fun1 <- function(x){
  y <-dchisq(x,1)
  return(y)
}
  
fun2 <- function(x){
  y <-dchisq(x,2)
  return(y)
} 

fun3 <- function(x){
  y <-dchisq(x,3)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Chisq Density Distribution")
```
累积分布函数
$$f_{k}(x)=\frac{\gamma (k/2,x/2)}{\Gamma (k/2)}$$
$\gamma$是伽玛函数
```{r}
fun1 <- function(x){
  y <-pchisq(x,1)
  return(y)
}
  
fun2 <- function(x){
  y <-pchisq(x,2)
  return(y)
} 

fun3 <- function(x){
  y <-pchisq(x,3)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Chisq Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近$\chi^2$(卡方)分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-rchisq(1000,1)
ks.test(S, "pchisq",1)
```

##均匀分布
均匀分布(Uniform distribution)是均匀的，不偏差的一种简单的概率分布，分为：离散型均匀分布与连续型均匀分布。
 概率密度函数
 $$f(x)=\left\{\begin{matrix}\frac{1}{b-a} \quad for \quad a\leq x\leq b
 & \\ 0 \quad elsewhere
 & 
\end{matrix}\right.$$
```{r}
fun1 <- function(x){
  y <-dunif(x,0,1)
  return(y)
}
  
fun2 <- function(x){
  y <-dunif(x,0,0.5)
  return(y)
} 

fun3 <- function(x){
  y <-dunif(x,-3,1)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Uniform Density Distribution")
```
累积分布函数
$$F(x)\left\{\begin{matrix} 0 \quad for \quad x< a
 & \\ \quad \frac{x-a}{b-a} \quad for \quad a\leq x < b
 & \\ 1 \quad for \quad x\geq b
 & 
\end{matrix}\right.$$
```{r}
fun1 <- function(x){
  y <-punif(x,0,1)
  return(y)
}
  
fun2 <- function(x){
  y <-punif(x,0,0.5)
  return(y)
} 

fun3 <- function(x){
  y <-punif(x,-3,1)
  return(y)
} 

ggplot(NULL, aes(x=x, colour = g)) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(1)), fun = fun1) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(2)), fun = fun2) +
  stat_function(data = data.frame(x=seq(0,10,length.out=100), 
                                  g = factor(3)), fun = fun3) +
  scale_colour_manual(values = c("red", "green","blue"), 
                      labels = c("red", "green","blue"))+
  ylab(label = "density")+
  labs(title="The Uniform Cumulative Distribution Function")
```
分布检验
Kolmogorov-Smirnov连续分布检验:检验单一样本是不是服从某一预先假设的特定分布的方法。以样本数据的累计频数分布与特定理论分布比较，若两者间的差距很小，则推论该样本取自某特定分布族。该检验原假设为$H_{0}$:数据集符合指数分布，$H_{1}$:样本所来自的总体分布不符合指数分布。令$F0(x)$表示预先假设的理论分布，$Fn(x)$表示随机样本的累计概率(频率)函数.
统计量D为: $D=max|F0(x) - Fn(x)|$
D值越小，越接近0，表示样本数据越接近均匀分布,p值，如果p-value小于显著性水平$\alpha$(0.05)，则拒绝$H_{0}$
```{r}
set.seed(1)
S<-runif(1000)
ks.test(S, "punif")
```
结论: D值很小, p-value>0.05，不能拒绝原假设，所以数据集S符合均匀分布！

例 某年级医学生解剖学考试成绩X(分)近似服从$N(65,10^{2})$，问解剖学成绩在85分以上的考生的概率是多少？
```{r}
pnorm(85,65,10,lower.tail = F) 
#pnorm()函数是正态分布的分布函数，用来计算对应分布下的概率
#lower.tail = F默认为T计算小于x的概率，F表示计算大于x的概率
```
解剖学成绩在85分以上的考生概率为`r round(pnorm(85,65,10,lower.tail = F) ,2)`

##Poisson分布
Poisson分布常用于描述单位时间、单位平面或单位空间中罕见事件的随机分布规律，Poisson分布的均数和方差相等。概率密度函数为
$$f(x)=\frac{e^{-\lambda}\lambda^x}{x!},x\in {0,1,2,3,...}$$

```{r warning=F}
ggplot(data.frame(x=c(0:10)),aes(x=x))+
  stat_function(fun=dpois,colour="red",args = list(lambda=1))+
  stat_function(fun=dpois,colour="green",args = list(lambda=2))+
  stat_function(fun=dpois,colour="blue",args = list(lambda=3))+
  ylab(label = "density")+
  labs(title="The Poisson Density Distribution")
```

累积分布函数
$$f(x)=e^{-\lambda}\sum_{i=0}^{|x|}\frac{\lambda^{i}}{i!},x\in {0,1,2,3,...}$$
```{r warning=F}
ggplot(data.frame(x= seq(-0.01, 5, 0.01)),aes(x=x))+
  stat_function(fun=ppois,colour="red",args = list(lambda=1))+
  stat_function(fun=ppois,colour="green",args = list(lambda=2))+
  stat_function(fun=ppois,colour="blue",args = list(lambda=3))+
  ylab(label = "density")+
  labs(title="The Poisson Cumulative Distribution Function")
```

例 随机变量X服从参数为3的Poisson分布，求概率P{x=6}.
```{r}
dpois(6,3)
```
参数为3的Poisson分布在X=6时的概率为`r dpois(6,3)`。

##数据分布直接的关系

![常见数据分布之间的关系](./distribution_chart.jpg)

##探索数据分布
要了解样本数据的总体分布情况，仅有特征统计量是不够的，还需要研究数据的分布状况。经验分布函数是指根据样本构造的概率分布函数，设$x_{1},x_{2},...,x_{n}$为一组样本，定义函数$m(x)$表示样本中小于或者等于$x$的样本个数，则称函数
$$F_{n}^{x}=\frac{m(x)}{n}$$
为样本$x_{1},x_{2},...,x_{n}$的经验分布函数。由Glivenko-Cantelli定理，当样本数组数足够大时，经验分布函数是总体分布函数的一个良好的近似。对数据分布的探索可参考下图中的决策树

![数据分布探索决策树](./distribution.jpg)

例 探索fitdistrplus中groundbeef的数据分布。
思路：首先判断数据的特点选择较为可能的分布，然后利用fitdist()获得可能分布的参数估计，再利用gofstat()选择较优的分布，最后可用ks.test()进行验证。
```{r}
data(groundbeef)
serving <- groundbeef$serving

fitW <- fitdist(serving, "weibull")
fitg <- fitdist(serving, "gamma")
fitln <- fitdist(serving, "lnorm")
summary(fitW)
summary(fitg)
summary(fitln)
#plot(fitg, demp = TRUE)
#plot(fitg, histo = FALSE, demp = TRUE)
cdfcomp(list(fitW, fitg, fitln), legendtext=c("Weibull", "gamma", "lognormal"))
denscomp(list(fitW, fitg, fitln), legendtext=c("Weibull", "gamma", "lognormal"))
qqcomp(list(fitW, fitg, fitln), legendtext=c("Weibull", "gamma", "lognormal"))
ppcomp(list(fitW, fitg, fitln), legendtext=c("Weibull", "gamma", "lognormal"))
gofstat(list(fitW, fitg, fitln), fitnames=c("Weibull", "gamma", "lognormal"))
```
选择AIC和BIC值较小的gamma分布

```{r echo=F}
try(detach(package:fitdistrplus))
try(detach(package:CircStats))
try(detach(package:ggplot2))
```

#参数估计
```{r include=FALSE}
library(MASS)
library(pander)
library(mixtools)
library(boot)
```

参数估计(Parameter Estimation)是指用样本指标(称为统计量)估计总体指标(称为参数)。参数估计有点估计(point estimation)和区间估计(interval estimation)两种。 

##点估计
设总体$X$的分布函数$F(x;\theta)$形式已知，其中$\theta$是待估计的参数，点估计就是利用样本($x_{1},x_{2},...,x_{n}$)，构造一个统计量$\hat{\theta }=\hat{\theta}(x_{1},x_{2},...,x_{n})$来估计$\theta$，称$\hat{\theta}(x_{1},x_{2},...,x_{n})$为$\theta$的点估计量，它是一个随机变量。将样本观测值($x_{1},x_{2},...,x_{n}$)代入估计量$\hat{\theta}(x_{1},x_{2},...,x_{n})$，就得到它的一个具体数值$\hat{\theta}(x_{1},x_{2},...,x_{n})$，这个数值成为$\theta$的点估计值。
点估计是依据样本估计总体分布中所含的未知参数或未知参数的函数。通常它是总体的某个特征值，如数学期望、方差和相关系数等。点估计问题就是要构造一个只依赖于样本的量，作为未知参数或未知参数的函数的估计值。
构造点估计常用的方法是：

###矩估计法  
设$(x_{1},x_{2},...,x_{n})$是来自总体$X$的一个样本，根据大数定律，对任意$\varepsilon >0$,有
$$\lim_{n\rightarrow \infty}P\left \{\right |\bar{X}-E(X)|\geq \varepsilon\}=0$$
并且对于任何$k$，只要$E(X^{k})$存在，同样有
$$\lim_{n\rightarrow \infty}P\left \{  \right|\frac{1}{n}\sum_{i=1}^{n}X_{i}^{k}-E(X^{k})|\geq \varepsilon \}=0,k=1,2,...$$
因此用样本矩估计总体矩，从而得到总体分布中参数的一种估计。如用样本均值估计总体均值。矩法的优点是简单易行，并不需要事先知道总体是什么分布，缺点是当总体类型已知时，没有充分利用分布提供的信息，且矩估计量不具有唯一性。

例1 设某药厂一天中发生着火现象的次数X服从参数为$\lambda$的Poisson分布，$\lambda$未知，有以下样本值，试用矩法估计参数$\lambda$。

着火的次数                 0  1  2  3  4  5  6
----                      -- -- -- -- -- -- --
发生k次着火的天数$n_{k}$  75 90 54  22  6  2  1

解 $EX=\lambda,A_{1}=\frac{1}{n}\sum_{i=1}^{n}X_{i}=\bar{X}$,

令$\bar{X}=\lambda$则$\bar{\lambda }=\bar{x}=\frac{1}{250}(0\times 57+1\times 90+...+6\times 1)=1.22$，

所以$\bar{X}=\lambda$,估计值$\hat{\lambda }=1.22$

例2 正态分布N（0,1）的矩估计
```{r}
x<-rnorm(100) #产生N（0,1）的100个随机数
mu<-mean(x)   #对N(mu,sigma)中的mu做矩估计
sigma<-var(x) #这里的var并不是样本方差的计算函数，而是修正的样本方差，其实也就是x的总体方差
mu
sigma
```

### 极大似然估计法（MLE）  
它是建立在极大似然原理的基础上的一个统计方法，极大似然原理的直观想法是：一个随机试验如有若干个可能的结果A，B，C，…。若在一次试验中，结果A出现，则一般认为试验条件对A出现有利，也即A出现的概率很大。当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该是使得从模型中抽取该n组样本观测值的概率最大。在任一次随机抽取中，样本观测值都以一定的概率出现。如果已经知道总体的参数，当然由变量的频率函数可以计算其概率。如果只知道总体服从某种分布，但不知道其分布参数，通过随机样本可以求出总体的参数估计。

例3 对MASS包中的geyser数据，该数据采集自美国黄石公园内的一个名叫Old Faithful 的喷泉。“waiting”就是喷泉两次喷发的间隔时间，“duration”当然就是指每次喷发的持续时间。在这里，我们只用到“waiting”数据
```{r}
panderOptions('table.split.table', Inf)
pander(head(geyser))
```
```{r}
hist(geyser$waiting,freq = F) #从图中可以看出，其分布是两个正态分布的混合。
```
用如下的分布函数来描述该数据
$$f(x)=pN(x_i;\mu_1,\sigma_1)+(1-p)N(x_i;\mu_2,\sigma_2)$$
该函数中有5个参数$p、\mu_1、\sigma_1、\mu_2、\sigma_2$需要确定。上述分布函数的对数极大似然函数为：
$$l=\sum_{i=1}^n\log \{pN(x_i;\mu_1,\sigma_1)+(1-p)N(x_i;\mu_2,\sigma_2)\}$$
在R中定义对数似然函数
```{r}
LL<-function(params,data) #定义log-likelihood函数,参数"params"是一个向量，依次包含了五个参数：p,mu1,sigma1,#mu2,sigma2.#参数"data"，是观测数据。
{
t1<-dnorm(data,params[2],params[3])  #这里的dnorm()函数是用来生成正态密度函数的。
t2<-dnorm(data,params[4],params[5])
f<-params[1]*t1+(1-params[1])*t2
ll<-sum(log(f))  #混合密度函数,log-likelihood函数
return(-ll) #nlminb()函数是最小化一个函数的值，但我们是要最大化log-likeilhood函数，所以需要在“ll”前加个“-”号。
}
#参数估计
hist(geyser$waiting,freq = F)
lines(density(geyser$waiting)) #初始值为p=0.5,mu1=50,sigma1=10,mu2=80,sigma2=10
geyser.res<-nlminb(c(0.5,50,10,80,10),LL,data=geyser$waiting,lower=c(0.0001,-Inf,0.0001,-Inf,-Inf,0.0001),upper=c(0.9999,Inf,Inf,Inf,Inf))
```
估计结果
```{r}
geyser.res$par #查看拟合的参数
X<-seq(40,120,length=100)
p<-geyser.res$par[1]
mu1<-geyser.res$par[2]
sig1<-geyser.res$par[3]
mu2<-geyser.res$par[4]
sig2<-geyser.res$par[5]
f<-p*dnorm(X,mu1,sig1)+(1-p)*dnorm(X,mu2,sig2) #将估计的参数函数代入原密度函数。
hist(geyser$waiting,probability=T,col=0,ylab="Density", #作出数据的直方图
     ylim=c(0,0.04),xlab="Eruption waiting times")
lines(X,f) #画出拟合的曲线
```

###最小二乘法
当从模型总体随机抽取n组样本观测值后，最合理的参数估计量应该使得模型能最好地拟合样本数据，即实际值与估计值的距离最小，主要用于线性统计模型中的参数估计问题。

例4 用最小二乘法估计线性回归模型
```{r}
x <- c(5.05, 6.75, 3.21, 2.66)
y <- c(1.65, 26.5, -5.93, 7.96)
lsfit(x, y)$coefficients #或者lm(y ~ x)$coefficients
plot(x, y)
abline(lsfit(x, y)$coefficients, col="red")
```

###EM算法
EM算法是一种在观测到数据后，用迭代法估计未知参数的方法。可以证明EM算法得到的序列是稳定单调递增的。这种算法对于截尾数据或参数中有一些不感兴趣的参数时特别有效。EM算法的步骤为：E-step（求期望）：利用对隐藏变量的现有估计值，计算其最大似然估计值。M-step（求极值）：最大化在 E 步上求得的最大似然值来计算参数的值，重复以上两步，直至收敛即可得到theta的MLE。可以看到对于一个参数的情况，EM仅仅只是求解MLE的一个迭代算法。
```{r}
sim.x <- c()  
sim.y <- c()  

# 用循环产生2000个点
for (i in 1:2000) {
    # first draw to determine which normal distribution is used
  first.draw = rmultinom(1, 1, c(0.1, 0.2, 0.7))[, 1]
  y = which(first.draw == 1)
  sim.y[i] = y
  
  # second draw to generate X from corresponding distribution
  if (y == 1) {
    x = rnorm(1, mean = 0, sd = 1)
    sim.x[i] = x
  }
  if (y == 2) {
    x = rnorm(1, mean = 10, sd = 5)
    sim.x[i] = x
  }
  if (y == 3) {
    x = rnorm(1, mean = -10, sd = 1)
    sim.x[i] = x
  }
}
plot(density(sim.x), main = "Density plot of sim.x")

mix.model <- normalmixEM(sim.x, lambda = c(0.3, 0.3, 0.4), mu = c(-20, 0, 20), sigma = c(1, 1, 1), k = 3)
summary(mix.model)
plot(mix.model, which = 2, density = TRUE)
```

###Bootstrap法 
以原始数据为基础的模拟抽样统计推断法,可用于研究一组数据的某统计量的分布特征,特别适用于那些难以用常规方法导出对参数的区间估计、假设检验等问题。“Bootstrap”的基本思想是:在原始数据的围内作有放回的再抽样,样本容量仍为n,原始数据中每个观察单位每次被抽到的概率相等,为1，…,n,所得样本称为bootstrap样本。于是可得到参数Η的一个估计值Η(b),这样重复若干次,记为B。设B=1000,就得到该参数的1000个估计值,则参数Η的标准误的bootstrap估计。简而言之就是：就是从样本中重复抽样。
```{r}
gauss<-rnorm(1000,4,10)
boot<-0
for(i in 1:1000){boot[i]=mean(sample(gauss,replace=T))}
summary(boot)
summary(gauss)
sd(boot)
```


##区间估计
由于点估计不能说明估计值与真实值的偏差到底有多大，也不能说明这个估计有多大的可行度，这些问题需要区间估计予以解决。区间估计是依据抽取的样本，根据一定的正确度与精确度的要求，构造出适当的区间，作为总体分布的未知参数或参数的函数的真值所在范围的估计。求置信区间常用的三种方法：1.利用已知的抽样分布.利用区间估计与假设检验的联系。3.利用大样本理论。 

设总体X的分布中含有未知参数$\theta,\alpha$是任意给定的正数$(0< \alpha < 1)$，如果能从样本除服确定出两个统计量$\hat{\theta }_{1}(x_{1},x_{2},...,x_{n}),\hat{\theta }_{2}(x_{1},x_{2},...,x_{n})$，使得
$$P\left \{ \hat{\theta }_{1}<\theta <\hat{\theta }_{2}  \right \}=1-\alpha $$
成立，我们称$1-\alpha$为置信度或置信概率，区间$\hat{\theta }_{1},\hat{\theta }_{2}$为参数$\theta$的置信度为$1-\alpha$的置信区间。分别称$\hat{\theta }_{1},\hat{\theta }_{2}$为置信上线和置信下线。
置信度为0.95是指100组样本值所得置信区间的实现中，约有95个能覆盖$\theta$，而不是说一个实现以0.95的概率覆盖了$\theta$。区间的宽度反应了估计的精度，区间越小，精度越高。区间估计中精确性和可靠性是相互矛盾的。当样本容量一定时，提供估计的可靠性，将降低估计的精度，相反，提高估计的精确性，将降低估计的可靠性。实际使用中，总是在保证一定的可靠度的情况下尽可能地提高其精度。
区间估计的基本步骤
1.选取一个合适的随机变量T,这个随机变量一方面包括了待估参数$\theta$，另一方面，它的分布是已知的；
2.根据实际需要，选取合适的置信度$1-\alpha$；
3.根据相应分布的分位数的概念，写出如下形式的概率表达式
$P\left \{ T_{1}<T <T_{2}  \right \}=1-\alpha$
4.将上式表达形式变为
$P\left \{ \hat{\theta }_{1}<\theta <\hat{\theta }_{2}  \right \}=1-\alpha$
5.写出参数$\theta$的置信区间$\hat{\theta }_{1},\hat{\theta }_{2}$

### 单正态总体参数的区间估计

#### 方差已知时的均值的区间估计
总体方差已知，均值的置信度为$1-\alpha$的单侧置信上限$\bar{X}+\frac{\sigma }{\sqrt{n}}z_{1-\alpha }$,单侧置信下线$\bar{X}-\frac{\sigma }{\sqrt{n}}z_{1-\alpha }$。

例5 某单位随机抽样的15位员工的身高分别为: 159 158 164 169 161 161 160 157 158 163 161 154 166 168 159,  假设身高服从方差为4的正态分布, 要求估计该单位员工身高均值的置信区间，置信水平为95%。

```{r}
z.test<-function(x,sigma,conf.level=0.95,u0=0,alt="two.sided"){
  result<-list()
  mean<-mean(x)
  a=1-conf.level
  n <- length(x)
  z<-(mean-u0)/(sigma/sqrt(n))
  p<-pnorm(z,lower.tail=F)
  result$z<-z
  result$p.value<-p
  if(alt=="two.sided"){
    result$p.value<-2*p
  }
  else if (alt == "greater"|alt =="less" ){
    result$p.value<p
  }
  result$interval<-c(mean-sigma*qnorm(1-a/2,0,1)/sqrt(n),mean+sigma*qnorm(1-a/2,0,1)/sqrt(n))
  result
}

x<-c(159,158,164,169,161,161,160,157,158,163,161,154,166,168,159)
result<-z.test(x,4) #默认95%的置信区间
result
```

#### 方差未知时的均值的区间估计
总体方差未知，均值的置信度为$1-\alpha$的置信区间为$\bar{X}+\frac{\sigma }{\sqrt{n}}t_{1-\alpha },\bar{X}-\frac{\sigma }{\sqrt{n}}t_{1-\alpha }$。
方差未知时我们直接利用R语言的t.test( )来求置信区间。
例6 假设不知道例5中总体的方差，要求估计该单位员工身高均值的置信区间，置信水平为95%。
```{r}
t.test(x)
```

#### 方差的区间估计
方差置信水平$1-\alpha$的置信区间为$\left ( \frac{(n-1)S^{2}}{\chi_{1-\alpha /2}^{2}(n-1)},\frac{(n-1)S^{2}}{\chi_{\alpha/2}^{2}(n-1)} \right )$
例7 假设不知道例5中总体的方差，要求估计该单位员工身高方差的置信区间，置信水平为95%。
```{r}
chisq.var.test<-function(x,conf.level=0.95,alt="two.sided",sigma0=1)   #默认95%的置信区间 双侧检验
{
  result<-list()
  n <- length(x)
  a=1-conf.level
  v<-var(x)
  result$interval<-c((n-1)*v/qchisq(1-a/2,n-1,lower.tail=T),(n-1)*v/qchisq(a/2,n-1,lower.tail=T))
  chi2<-(n-1)*v/sigma0
  result$chi2<-chi2
  p<-pchisq(chi2,n-1)
  if(alt=="two.sided")
    result$p.value<-2*min(pchisq(chi2,n-1),pchisq(chi2,n-1,lower.tail=F))
  else
    result$p.value<-pchisq(chi2,n-1,lower.tail=F)
  result
}

chisq.var.test(x)
```

### 两正态总体参数的区间估计
####均值差$\mu _{1}-\mu_{2}$的置信区间
##### 两方差都已知时两均值差的置信区间
两方差已知$\mu _{1}-\mu_{2}$的置信水平$1-\alpha$的置信区间为
$(\bar{X}-\bar{Y}-z_{1-\alpha /2}\sqrt{\frac{\sigma_{1}^{2} }{n_{1}}+\frac{\sigma_{2}^{2} }{n_{2}}},\bar{X}-\bar{Y}+z_{1-\alpha /2}\sqrt{\frac{\sigma_{1}^{2} }{n_{1}}+\frac{\sigma_{2}^{2} }{n_{2}}})$

例8 为比较两种药品的降糖效果, 选择20名条件相似的受试者, 分别服用甲、乙两种药品后，测得甲组的血糖为6.48 4.00 5.54 6.89 5.14 4.60 3.67 4.32 4.80 7.50,乙组的血糖为4.16 10.77  9.08  5.95  6.36  3.77  5.18  6.76  3.86  3.63。假定甲乙两组血糖均服从正态分布，甲组的方差为5.0，乙组的方差为5.2，试求这两组平均血糖差的置信区间(取$\alpha=0.05$)
```{r}
two.sample.ci<-function(x,y,sigma1,sigma2,conf.level=0.95){
  m= length(x)
  n = length(y)
  xbar=mean(x)-mean(y) 
  alpha = 1 - conf.level
  zstar= qnorm(1-alpha/2)* (sigma1/m+sigma2/n)^(1/2)
  xbar +c(-zstar, +zstar)
}

x <- c(6.48,4.00,5.54,6.89,5.14,4.60,3.67,4.32,4.80,7.50)
y <- c(4.16,10.77,9.08,5.95,6.36,3.77,5.18,6.76,3.86,3.63)
sigma1<-5.0
sigma2<-5.2

two.sample.ci(x,y,sigma1,sigma2)
```
##### 两方差都未知但相等时两均值差的置信区间
两方差未知$\mu _{1}-\mu_{2}$的置信水平$1-\alpha$的置信区间为
$(\bar{X}-\bar{Y}-t_{1-\alpha /2}\sqrt{\frac{\sigma_{1}^{2} }{n_{1}}+\frac{\sigma_{2}^{2} }{n_{2}}},\bar{X}-\bar{Y}+t_{1-\alpha /2}\sqrt{\frac{\sigma_{1}^{2} }{n_{1}}+\frac{\sigma_{2}^{2} }{n_{2}}})$

例9 假设例8中两组的方差未知，试求这两组平均血糖差的置信区间(取$\alpha=0.05$)
```{r}
t.test(x,y,var.equal=TRUE) #两方差都未知但相等时两均值差的置信区间
```
#### 两方差比的置信区间
$\sigma _{1}^{2}/\sigma _{1}^{2}$的置信水平$1-\alpha$的置信区间为$\begin{pmatrix}
 \frac{S_{1}^{2}}{S_{2}^{2}}\frac{1}{F_{1-\alpha/2}(n_{1}-1,n_{2}-1)},\frac{S_{1}^{2}}{S_{2}^{2}}\frac{1}{F_{\alpha/2}(n_{1}-1,n_{2}-1)}
\end{pmatrix}$

例10 假设例9中两组的方差未知，试求这两组平均血糖方差比的置信区间(取$\alpha=0.05$)
```{r}
var.test(x,y)
```

##单总体比率$p$的区间估计
$x$为容量为n的样本中具有某种特征的个体数量，则样本比例为$x/n$。当总体中的样品数足够多时，$x$近似服从二项分布$b(n,p)$ (实际上它是超几何分布),这时总体比例可用样本比例来估计,总体比例为$p$的置信水平$1-\alpha$的置信区间为$\left ( \hat{p}-z_{1-\alpha/2}\sqrt{\hat{p}(1-\hat{p})/n},\hat{p}+z_{1-\alpha/2}\sqrt{\hat{p}(1-\hat{p})/n} \right )$

例10 在某小学随机抽取了120人，发现其中34人有不同程度的视力下降，假定样本的数量服从正态分布，以95%的置信度, 估计这个小学视力下降比例。

```{r}
prop.test(34,120,correct=TRUE) #correct选项为是否做连续性校正
binom.test(34,120)
```

##两总体比率差$p_{1}-p{2}$的区间估计
在近似正态性下$p_{1}-p{2}$置信水平为$1-\alpha$的区间估计$(\hat{p_{1}}-\hat{p_{2}})\pm z_{1-\alpha/2}\sqrt{\frac{\hat{p_{1}}(1-\hat{p_{1}})}{n_{1}}+\frac{\hat{p_{2}}(1-\hat{p_{2}})}{n_{2}}}$

例11 对某疾病进行调查。在甲地区调查了160人，有98人符合诊断标准，在乙地区调查了206人，有132人符合诊断标准。试以95%的可靠性对该病在两地差别作出区间估计。
```{r}
s <- c(98,132)
t <- c(160,206)
prop.test(s,t)
```

## 基于Bootstrap的区间估计
对于大多数的统计量而言，计算置信区间的数学公式太过复制或者根本没有数学公式，因而没有计算置信区间的已知的解析形式的公式。采用Bootstrap方法，解析形式的数据公式是不必知道的。当样本不符合理论分布假设时，求样本统计量的置信区间就成为一个难题。而自助法(Bootstrap)的思路是对原始样本重复抽样产生多个新样本，针对每个样本求取统计量，然后得到它的经验分布，再通过求经验分布的分位数来得到统计量的置信区间，这种方法不需要对统计量有任何理论分布的假设。一般认为，只要样本具有代表性，采用自助法需要的原始样本只要20-30个,重复抽样1000次就能达到满意的结果。在R中进行自助法是利用boot扩展包，其流程如下：1.编写一个求取统计量的自定义函数 2.将上面的函数放入boot（）函数中进行运算，得到自助法的结果 3.用boot.ci()函数求取置信区间

例12 对mtcars数据集中的mpg变量估算其中位数的置信区间，将wt和disp作为自变量，mpg 作为因变量，进行回归后对判定系数R-square，用自助法求它的95%置信区间。
```{r}
myfun <- function(data,indices){
  d <- data[indices,]
  rs <- median(d$mpg)
  return (rs)
}

results=boot(data=mtcars,statistic=myfun ,R=1000) #results这个数据结构中包括了原始样本的统计(results$t0)和再抽样样本的统计量(results$t0)，
boot.ci(results,conf=0.95,type=c('perc','bca')) 
#其中conf表示置信水平，type表示了用何种算法来求区间，perc即使用百分位方法，bca表示adjusted bootstrap percentile，即对偏差进行了调整

rsq=function(data,indices){
d=data[indices,]
fit=lm(formula=mpg~wt+disp,data=d)
return(summary(fit)$r.square)
}
results=boot(data=mtcars,statistic=rsq,R=1000)
print(results)
plot(results) 
#左侧的直方图表示了再抽样样本的统计量的经验分布，其中的虚线表示了原始样本的统计量，从中可以观察到偏差。右侧QQ图有助于判断经验分布是否正态。
boot.ci(results,conf=0.95,type=c('perc','bca'))

```

例12 假定例10的样本数量的分布状况未知，以95%的置信度, 估计这个小学视力下降比例。

```{r}
p.test <- function(x,n)
{
  n <- rep(0,each=n)
  n[seq(1,x)] <- 1
  data <- as.data.frame(n)
  
  p <- function(data,indices)
  {
    d <- data[indices,]
    ratio<- sum(d)/length(d)
    return (ratio)
  }
  results=boot(data=data,statistic=p,R=1000)
  boot.ci(results,conf=0.95,type=c('perc','bca'))
}
  
p.test(34,120)
```
```{r echo=F}
try(detach(package:MASS))
try(detach(package:pander))
try(detach(package:mixtools))
try(detach(package:boot))
```

#样本容量估计
```{r include=FALSE}
library(TrialSize)
library(pipeR)
library(pander)
library(expm)
library(koRpus)
library(ldbounds)
```

样本容量过小，信息不充分，所得指标不够稳定，抽样误差较大，结论的可靠性差，用于推断总体的精度差，检验效能低，会导致总体中存在的差异未能检验出来，出现假阴性的结果。样本容量过大，花费的人力、物力、财力和时间较大，还会增加工作中质量控制的难度，样本量过大还可能引入更多的混杂因素，对研究结果产生不良影响。常见样本容量的影响因素如下1.第一类错误的大小$\alpha$(或置信度为$1-\alpha$)，$\alpha$越小所需的样本容量越大。2.第二类错误的大小$\beta$，$\beta$越小，检验效能$1-\beta$越大，所需的样本量也越大，一般要求检验效能不低于0.8。在参数估计的样本容量估计中不设计$\beta$。3.容许误差d，是指研究者要求的或者客观存在的样本统计量和总体参数间或样本统计量间的差值，或专业上认为有意义的最小差值，容许误差越小，所需样本两越大。4.总体标准差s或者总体率p，常根据预实验以及既往资料进行估计，其值越大或远离0.5时，所需样本量越大。通常在抽样调查和临床试验的设计中，需要估算样本含量以保证结果的可靠。

临床研究的目的不同 ,所采用的样本含量估算方法也不同。 在临床试验过程 ,需要区分是做显著性检验(significance test), 还是区间假设检验(interval hypotheses test)。显著性检验 (significance test)用于推断两个样本是否来自同一总体, 它的检验假设为两组相等的零假设 ,即样本来自同一总体。 其无效假设为$H_{0}\  \mu _{T}= \mu _{P}$,备择假设为$H_{1}\  \mu _{T}\neq \mu _{P}$ ,T(test)为试验组，P(placebo)为安慰剂组。临床试验中，对于两组疗效的评价 ,显著性检验结果不能评价差别的实际大小,更不能说明差别是否有临床实际意义 ,只能说明两组的疗效是否来自不同的总体。在临床中往往是要确认新药是否不差于或相当于甚至优于标准的有效药物 ,所以通常采用非劣效/等效/优效检验。它们的检验假设不再是一个点，而是一个区间，所以又可称之为“区间假设”(interval hypothesis)或“区间检验” (interval test) 。区间假设检验包括了等效性检验(equiv alencetest)、非劣效性检验(noninferiority test)与优效性检验(superiority test)。 非劣效性试验指主要研究目的是显示对试验药的反应在临床意义上不差于（非劣于）对照药的试验,如果治疗差异（试验药的疗效-对照药的疗效）>0，则试验药的疗效较好；治疗差异<0，则对照药疗效较好；如果允许试验药疗效比对照药疗效低一定范围，仍然认为两药疗效相当，即确定$\Delta$表示临床意义上判断疗效不差所允许的最大差异值，则如果治疗差异>-$\Delta$，便是试验药非劣效于对照药，此处的$\Delta$称为非劣效试验的判断界值（margin）。非劣效试验的原假设为$H_{0}\  \mu _{T}- \mu _{S}\geqslant -\delta$,备择假设为$H_{1}\  \mu _{T}- \mu _{S}< -\delta$，S(standard)为标准组，T(test)为试验组，通常用于与已上市的有效药物或标准治疗方案进行比较以求能提供一个新的治疗选择。等效性检验指主要研究目的是要显示两种或多种处理的反应间差异的大小在临床上并无重要性的试验，通常通过显示真正的差异在临床上可以接受的等效的上下界值之间来证实其原假设为$H_{0}\  |\mu _{T}- \mu _{S}|\geqslant \delta$，备择假设为$H_{0}\  |\mu _{T}- \mu _{S}|<  \delta$为等效标准，也称界值 ) ,只有两组假设同时成立 ,才认为等效，多见于对同一活性成分的生物等效性以及血浆无法测定时的临床等效验证。优效性试验指主要研究目的是显示所研究的药物的反应优于对比制剂（阳性或安慰剂对照），优效性试验的原假设为$H_{0}\  \mu _{T}- \mu _{S}\leqslant   \delta$,备择假设为$H_{1}\  \mu _{T}- \mu _{S}>  \delta$,通常用于具有某方面优势的在新研发的试验药，一般需要与安慰剂进行优效性试验以比较其真正的疗效和安全性，来判断其上市的利益风险。如果当前已有曾经优效性试验证实的有效药物的话，还常常与其进行比较，并判定待验证药物的疗效至少不差于（非劣于）已有有效药物作为其上市的最低标准。临床试验中，(临床)界值的选择，应由研究者与统计学家共同商定，是基于统计推理及临床判断的双重考虑；若无公认界值，可参考EMEA《Guideline on the choice of the non-inferiority margin》及《Issues on the selection of non-inferiority margin in clinical trials》等文献.

随机对照临床试验（randomized clinical trial，RCT）是临床试验中比较重要的试验，根据设计方案，常分为平行设计、交叉设计、析因设计和序贯设计。除序贯设计不需事先估计样本含量外，其余设计均需要估计样本含量。(1) 平行设计(parallel design)：将研究对象随机分配到两组（或多组），分别接受不同的处理，两组同时开始进行研究，同时分析和比较研究结果。平行设计的双盲随机对照试验是临床试验的金标准。(2) 交叉设计（cross-over design）四队两组受试者使用两种不同的处理措施，然后将处理措施相互交换，最后将结果进行对比分析的方法。这种设计比平行设计检验效率更高，所需样本量也少。但第一阶段干预效应可能会对第二阶段有影响，产生遗留效应或其他交互效应，设计和分析比较复杂。还存在试验周期较长等不足。(3)析因设计（factorial design）是将两个或多个以上的处理因素的各水平进行组合，对各种可能的组合都进行实验，用以评价不同处理的单独作用和联合应用的交互效应。析因设计可以分析处理交互因素，但设计和分析也比较复杂。(4)序贯设计(sequential design)在试验前不规定样本，按照先后顺序用随机化方法分配进入实验组或对照组，每试验一个或一对受试者后，及时进行分析，一旦可以判定结果，即可停止试验。序贯设计符合临床患者陆续就医的实际，比较适合以单一指标做为结论依据的新药和老药或新药和安慰剂的配对比较，节省人力物力，但不适用于慢性病、多变量、长期随访等研究设计。在本章中，对微阵列数据基于族错误率(FWER)样本量计算和基于贝叶斯统计的样本量计算未能用R语言实现。

##均数比较的样本量估计(Comparing Means)
###单组设计(One-Sample Design)
没有对照组的开放设计为单组设计，常用于治疗组数据与标准公认值比较或基线数据与治疗后数据的分析比较。
####显著性性检验
当标准差为$\sigma^{2}$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值（样本均值与某参考值的差值,或者，在配对设计中，配对个体观察值之差的均数，或试验组终点与基线之差的均数）为$\epsilon$,样本容量为$n= \frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma ^{2}}{\epsilon ^{2}}$

例 已知某社区50~70岁男性的平均收缩压为158mmHg，标准差为18mmHg。用某新型药品治疗后，差值为10mmHg，在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？
```{r}
OneSampleMean.Equality(0.05,0.1,18,10)
```
当标准差未知检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$,样本容量为$n= \frac{(t_{\alpha/2}+t_{\beta})^{2}\sigma ^{2}}{\epsilon ^{2}}$

例 已知某社区50~70岁男性的平均收缩压总体方差未知，样本标准差为18mmHg，用某新型药品治疗后，差值为10mmHg，在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？
总体方差未知的情况下，一般采用t分布代替z分布。使用t分布时，假设了初始值，采用迭代算法。
```{r}
OneSampleMean.Equality2 <- function(alpha, beta, sigma, margin,m=1000)
{
  t0<-qt(alpha/2,m,lower.tail=FALSE)+qt(beta,m,lower.tail=FALSE)
  n0 <- (t0*sigma/margin)^2
  t1 <- qt(alpha/2,n0,lower.tail=FALSE)+qt(beta,n0,lower.tail=FALSE)
  n1<-(t1*sigma/margin)^2
  while(abs(n1-n0)>0.5){
    n0<-((qt(alpha/2,n1,lower.tail=FALSE)+qt(beta,n1,lower.tail=FALSE))*sigma/margin)^2
    n1<-((qt(alpha/2,n0,lower.tail=FALSE)+qt(beta,n0,lower.tail=FALSE))*sigma/margin)^2
  }
  n1
}

OneSampleMean.Equality2(0.05,0.1,18,10)
```

####非劣效/优效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$，$\delta$具有临床意义的界值,进行非劣效性检验，界值应为负值，若进行优效性检验，界值为正值。样本容量为$n= \frac{(z_{\alpha}+z_{\beta})^{2}\sigma ^{2}}{(\epsilon -\delta ) ^{2}}$

例 一项临床试验研究新型降压药治疗高血压的作用，对某社区50~70岁平均收缩压为158mmHg，标准差为18mmHg的男性进行治疗，进行非劣性设计。如果认为有临床价值界值为10mmHg，差值为8mmHg,在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？
```{r}
OneSampleMean.NIS(0.05,0.1,18,8,-10)
```
####等效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$，$\delta$具有临床意义的界值,样本容量为$n= \frac{(z_{\alpha}+z_{\beta/2})^{2}\sigma ^{2}}{(\delta -|\epsilon|) ^{2}}$

例 一项临床试验研究新型降压药治疗高血压的作用，对北京某社区50~70岁平均收缩压为158mmHg，标准差为18mmHg的男性进行治疗，进行等效性检验。如果认为有临床价值界值为10mmHg，差值为8mmHg,在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？
```{r}
OneSampleMean.Equivalence(0.05,0.1,18,8,10)
```

###两组平行设计(Two-Sample Parallel Design)
####显著性性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n_{c}= \frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma ^{2}(1+1/k)}{\epsilon ^{2}}$，$n_{t}=kn_{2}$，k为实验组/对照组即$k=\frac{n_{t}}{n_{c}}$。

例 为研究某地正常成年男、女末稍血液的红细胞的差别，据文献报道，男性红细胞均数为465万/mm3 ，女性红细胞均数为422万/mm3，标准差为52万/mm3，1:1平行对照设计，取双侧$\alpha=0.05$,$\beta=0.1$，问要抽查多少人才能发现男女间红细胞的差别？ 

```{r}
n <- TwoSampleMean.Equality(0.05,0.1,52,1,43) #465-422=43
n
```
每组样本量为31人。若实验组和对照组方差齐性采用Pooled合并方差(Pooled varance)计算样本量；若两组方差不齐，则使用Welch–Satterthwaite方程对自由度进行近似的方法计算样本量。

####非劣效/优效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n_{c}= \frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma ^{2}(1+1/k)}{(\epsilon-\delta)^{2}}$，$n_{t}=kn_{2}$,k为实验组/对照组即$k=\frac{n_{t}}{n_{c}}$。

例 为研究某地正常成年男、女末稍血液的红细胞的差别，据文献报道，男性红细胞均数为465万/mm3 ，女性红细胞均数为422万/mm3，标准差为52万/mm3，1:1平行对照设计，取双侧$\alpha=0.05$,$\beta=0.1$，界值为10mmHg，进行非劣性设计，要抽查多少人才能发现男女间红细胞的差别？ 

```{r}
n <- TwoSampleMean.NIS(0.05,0.1,52,1,-10,43)
n
```
每组样本量为17人。若实验组和对照组方差齐性采用Pooled合并方差(Pooled varance)计算样本量；若两组方差不齐，则使用Welch–Satterthwaite方程对自由度进行近似的方法计算样本量。

####等效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n_{c}= \frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma ^{2}(1+1/k)}{(\epsilon-|\delta|)^{2}}$，$n_{t}=kn_{2}$，k为实验组/对照组即$k=\frac{n_{t}}{n_{c}}$。

例 为研究某地正常成年男、女末稍血液的红细胞的差别，据文献报道，男性红细胞均数为465万/mm3 ，女性红细胞均数为422万/mm3，标准差为52万/mm3，1:1平行对照设计，取双侧$\alpha=0.05$,$\beta=0.1$，界值为10mmHg，进行等效性设计，要抽查多少人才能发现男女间红细胞的差别？ 

```{r}
n <- TwoSampleMean.Equivalence(0.05,0.1,52,1,10,43)
n
```
每组样本量为53人。若实验组和对照组方差齐性采用Pooled合并方差(Pooled varance)计算样本量；若两组方差不齐，则使用Welch–Satterthwaite方程对自由度进行近似的方法计算样本量。

###两组交叉设计（Two-Sample Crossover Design）
两组交叉设计的样本量估计公式也适用配对设计、交叉配对设计和随机区组配对设计。
####显著性性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n=\frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma ^{2}_{m}}{2\epsilon ^{2}}$。

例 AAA 药品和对照药品治疗高血压，患者先服用对照药品 1 个月，洗脱2 周，再服用 AAA 1 个月，另一组反之。如果 AAA 能够比对照药品平均多降低收缩压 5mmHg（差值），则认为有推广价值。预试验差值标准差为 10。选用 α=0.05,Power=90%, 双侧显著性检验，需要多少样本含量? 

```{r}
TwoSampleCrossOver.Equality(0.05,0.1,10,5)
```

####非劣效/优效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n=\frac{(z_{\alpha}+z_{\beta})^{2}\sigma ^{2}_{m}}{2(\epsilon -\delta )^{2}}$。

例 AAA 药品和对照药品治疗高血压，患者先服用对照药品 1 个月，洗脱2 周，再服用 AAA 1 个月，另一组反之。如果 AAA 能够比对照药品平均多降低收缩压 5mmHg（差值），则认为有推广价值。预试验差值标准差为 10。选用 α=0.05,Power=90%, 界值为1,双侧非劣效检验，需要多少样本含量? 

```{r}
TwoSampleCrossOver.NIS(0.05,0.1,10,-1,5)
```

####等效性检验
当差值的标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon=\mu _{test}-\mu_{reference}$,样本容量为$n=n=\frac{(z_{\alpha}+z_{\beta/2})^{2}\sigma ^{2}_{m}}{2(\epsilon -|\delta|)^{2}}$。

例 AAA 药品和对照药品治疗高血压，患者先服用对照药品 1 个月，洗脱2 周，再服用 AAA 1 个月，另一组反之。如果 AAA 能够比对照药品平均多降低收缩压 5mmHg（差值），则认为有推广价值。预试验差值标准差为 10。选用 α=0.05,Power=90%, 界值为1,双侧等效性检验，需要多少样本含量? 

```{r}
TwoSampleCrossOver.Equivalence(0.05,0.1,10,1,5)
```

###多组设计(Multiple-Sample One-Way ANOVA)
####平行设计 
该设计考察的试验因素只有一个，并且该因素的水平(组数)$k\geqslant 3$,用来考察各组观察指标总体均数之间的差别是否有统计学意义。$\Delta =\frac{1}{\sigma ^{2}}\sum_{i=1}^{k}(\mu _{i}-\bar{\mu})^{2},\bar{\mu}=\frac{1}{k}\sum_{j=1}^{k}\mu_{j}$,样本量$n=\lambda/\Delta$,其中$\sigma$为标准差，k为组数，$\mu_{1}$为各组的平均数，$\bar{\mu}$为各组平均数的平均数。$\lambda$需要查询下表。

$k$  $\alpha=0.01$  $\alpha=0.05$  $\alpha=0.01$  $\alpha=0.05$     
---  ---            ---            ---            ---
     $1-\beta=0.80$                $1-\beta=0.90$
2    11.68          7.85           14.88	        10.51
3    13.89	        9.64           17.43          12.66
4    15.46	        10.91	         19.25	        14.18
5    16.75	        11.94	         20.74	        15.41
6    17.87	        12.83	         22.03	        16.47
7    18.88	        13.63	         23.19	        17.42
8    19.79	        14.36          24.24	        18.29
9    20.64	        15.03	         25.22	        19.09
10   21.43	        15.65	         26.13	        19.83
11	 22.18	        16.25	         26.99	        20.54
12	 22.89	        16.81	         27.8	          21.20
13	 23.57	        17.34	         28.58	        21.84
14	 24.22	        17.85	         29.32	        22.44
15	 24.84	        18.34	         30.04	        23.03
16	 25.44	        18.82	         30.73	        23.59
17	 26.02	        19.27	         31.39	        24.13
18	 26.58	        19.71	         32.04	        24.65
19	 27.12          20.14	         32.66	        25.16
20	 27.65          20.56	         33.27	        25.66

例 用四种药品治疗高血压，已知四种药品降低收缩压的平均数分别是8.25,11.75,12和13。各药品降低收缩压的标准差都是3.5.在$\sigma=0.05,\beta=0.1$,双侧检验，需要多少样本？
查表$\lambda=14.18$
```{r}
k <- c(2:20)
dim <- c("alpha0.01beta0.2","alpha0.05beta0.2","alpha0.01beta0.1","alpha0.05beta0.1")
data <- c(11.68,13.89,15.46,16.75,17.87,18.88,19.79,20.64,21.43,22.18,22.89,23.57,
          24.22,24.84,25.44,26.02,26.58,27.12,27.65,7.85,9.64,10.91,11.94,12.83,13.63,
          14.36,15.03,15.65,16.25,16.81,17.34,17.85,18.34,18.82,19.27,19.71,20.14,
          20.56, 14.88,17.43,19.25,20.74,22.03,23.19,24.24,25.22,26.13,26.99,27.80,
          28.58,29.32,30.04,30.73,31.39,32.04,32.66,33.27,10.51,12.66,14.18,15.41,
          16.47,17.42,18.29,19.09,19.83,20.54,21.20,21.84,22.44,23.03,23.59,24.13,
          24.65,25.16,25.66 )
z <- array(data,c(19,4),dimnames<-list(k,dim))

delta<- function(mu,sigma){
  mu0 <- mean(mu)
  return(sum((mu-mu0)^2)/sigma^2)
}

MutiSampleMean <- function(alpha, beta, sigma, k, mu){
  lambda <- z[k-1,paste(paste("alpha",alpha,sep = ""),paste("beta",beta,sep = ""),
                        sep = "")]
  n <- lambda/delta(mu,sigma)
}

(MutiSampleMean(0.05,0.1,3.5,4,c(8.25,11.75,12,13)))
```
每组研究至少需要14名。

####两两比较设计
试验组为2个或以上，且设有对照的试验设计，主要观察指标为计量资料。当标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon = \mu_{i} − \mu_{j}$取最小值,$\tau$ 的配对对比，样本量为$n_{ij}=\frac{2(z_{\alpha/(2\tau))}+z_{\beta})^2\sigma^{2}}{\epsilon ^{2}_{ij}}$。使用TrialSize包中的OneWayANOVA.pairwise()进行计算。

例 试验药两剂量的降低收缩压的平均数分别30和35，对照的降低收缩压的平均数为20，两剂量降低收缩压的标准差分别是5.3和4.2,进行1：1：1的平行对照实验，在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量?
```{r}
n1 <- OneWayANOVA.pairwise(0.05, 0.1, 2, 5.3, (30-20))
n2 <- OneWayANOVA.pairwise(0.05, 0.1, 2, 4.2, (35-20))
n <- max(n1,n2)
n
```
每组需要7个例。

####Williams设计(Multiple-Sample Williams Design)
当交叉试验可使用的时期数与处理数相同时，采用广义拉丁方以尽量少的受试者来均衡一阶延滞作用的交叉设计为Williams设计。常见的Williams设计有三组设计（一个6×3的交叉设计）和四组设计（一个4*4的交叉设计）。当试验组是奇数，设计结果是$2k×k$交叉设计，当试验组是偶数，设计结果$k×k$交叉设计。

#####显著性检验
标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,$k$为组数，$\epsilon$为两组的差值，样本量$n=\frac{(z_{\alpha/2}+z_{\beta})\sigma^2_{d}}{k\epsilon^{2}}$

例 用三种药品治疗高血压，预实验已知三种药品（A、B、C）降低收缩压分别为8.25,11.75,12,各药品降低收缩压的标准差均为3.5。williams设计为三交叉对照实验，三交叉的处理顺序排列组合为ABC,ACB,BAC,BCA,CAB,CBA共6个序列，$\alpha=0.05$，$\beta=0.1$,双侧显著性检验，需要多少样本？

```{r}
n1 <- MeanWilliamsDesign.Equality(0.05,0.1,3.5,6,(8.25-11.25))
n2 <- MeanWilliamsDesign.Equality(0.05,0.1,3.5,6,(8.25-12))
n3 <- MeanWilliamsDesign.Equality(0.05,0.1,3.5,6,(11.75-12))

n  <- max(n1,n2,n3)
n
```
研究的每个序列至少需要343例。

#####非劣效/优效性检验
标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,$k$为组数，$\epsilon$为两组的差值，$\delta$为界值，样本量$n=\frac{(z_{\alpha}+z_{\beta})\sigma^2_{d}}{k(\epsilon-\delta)^{2}}$

例 用三种药品治疗高血压，预实验已知三种药品（A、B、C）降低收缩压分别为8.25,11.75,12,各药品降低收缩压的标准差均为3.5。williams设计为三交叉对照实验，三交叉的处理顺序排列组合为ABC,ACB,BAC,BCA,CAB,CBA共6个序列，界值为5，$\alpha=0.05$，$\beta=0.1$,双侧显著性检验，需要多少样本？

```{r}
n1 <- MeanWilliamsDesign.NIS(0.05,0.1,3.5,6,-5,(8.25-11.25))
n2 <- MeanWilliamsDesign.NIS(0.05,0.1,3.5,6,-5,(8.25-12))
n3 <- MeanWilliamsDesign.NIS(0.05,0.1,3.5,6,-5,(11.75-12))

n  <- max(n1,n2,n3)
n
```
研究的每个序列至少需要12例。

#####等效性检验
标准差为$\sigma$,检验功效为$1-\beta$，置信度为$1-\alpha$,$k$为组数，$\epsilon$为两组的差值，$\delta$为界值，样本量$n=\frac{(z_{\alpha}+z_{\beta/2})\sigma^2_{d}}{k(\delta-|\epsilon|)^{2}}$

例 用三种药品治疗高血压，预实验已知三种药品（A、B、C）降低收缩压分别为8.25,11.75,12,各药品降低收缩压的标准差均为3.5。williams设计为三交叉对照实验，三交叉的处理顺序排列组合为ABC,ACB,BAC,BCA,CAB,CBA共6个序列，界值为5，$\alpha=0.05$，$\beta=0.1$,双侧等效性检验，需要多少样本？

```{r}
n1 <- MeanWilliamsDesign.Equivalence(0.05,0.1,3.5,6,5,(8.25-11.25))
n2 <- MeanWilliamsDesign.Equivalence(0.05,0.1,3.5,6,5,(8.25-12))
n3 <- MeanWilliamsDesign.Equivalence(0.05,0.1,3.5,6,5,(11.75-12))

n  <- max(n1,n2,n3)
n
```
研究的每个序列至少需要14例。

##率比较的样本量估计(Large Sample Tests for Proportions)
###单组设计(One-Sample Design)
####显著性检验
当总体率为$p$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$,样本容量为$n=\frac{(z_{\alpha /2}+z_{\beta })^{2}p(1-p)}{\epsilon ^{2}}$。

例 用传统的方法治疗运动负胫骨结节股骺损伤的有效率约为85%，现采用小刚针做胫骨结节股骺穿刺，估计有效率为95%，在$\alpha=0.05$,$\beta=0.1$，双侧显著性检验，问需要多大的样本容量？
```{r}
OneSampleProportion.Equality(0.05,0.1,0.95,(0.95-0.85))  
```
研究需要50例。OneSampleProportion.Equality()函数中的delta相当于样本计算公式的$\epsilon$。

####非劣效/优效性检验
当总体率为$p$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$，界值$\delta$,样本容量为$n=\frac{(z_{\alpha}+z_{\beta })^{2}p(1-p)}{(\epsilon-\delta ) ^{2}}$。

例 用传统的方法治疗运动负胫骨结节股骺损伤的有效率约为85%，现采用小刚针做胫骨结节股骺穿刺，估计有效率为95%,界值为5%，在$\alpha=0.05$,$\beta=0.1$，双侧非劣效检验，问需要多大的样本容量？

```{r}
OneSampleProportion.NIS2 <- function (alpha, beta, p, delta, margin) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta))^2 * p * (1 - p)/(margin-delta)^2
    n
}
OneSampleProportion.NIS2(0.05,0.1,0.95,-0.05,(0.95-0.85)) 
```
研究需要19例。TrialSize的作者在OneSampleProportion.NIS()函数中delta和margin代表的意义，与样本量计算公式有不相符之处，但可以得到正确结果OneSampleProportion.NIS2(0.05,0.1,0.95,(0.95-0.85),-0.05) 。

#### 等效性检验
当总体率为$p$,检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon$，界值$\delta$,样本容量为$n=\frac{(z_{\alpha}+z_{\beta/2})^{2}p(1-p)}{(\epsilon-|\delta|)^{2}}$。

例 用传统的方法治疗运动负胫骨结节股骺损伤的有效率约为85%，现采用小刚针做胫骨结节股骺穿刺，估计有效率为95%,界值为5%，在$\alpha=0.05$,$\beta=0.1$，双侧等效性检验，问需要多大的样本容量？

```{r}
OneSampleProportion.Equivalence2 <- function(alpha, beta, p, delta, margin) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta/2))^2 * p * (1 - 
        p)/(delta - abs(margin))^2
    n
}
OneSampleProportion.Equivalence2(0.05,0.1,0.95,0.05,(0.95-0.85))

```
研究需要206例。TrialSize的作者在OneSampleProportion.NIS()函数中delta和margin代表的意义，与样本量计算公式有不相符之处，但可以得到正确结果OneSampleProportion.Equivalence(0.05,0.1,0.95,(0.95-0.85),0.05) 

###两组平行设计(Two-Sample Parallel Design)
####显著性检验
$p_{1}$为第一组(试验组)的率，$p_{2}$为第二组（对照组）的率，差值为$\epsilon$，样本容量为$n_{2}=\frac{(z_{\alpha /2}+z_{\beta })^{2}}{\epsilon ^{2}}[\frac{p_{1}(1-p_{1})}{k}+p_{2}(1-p_{2})]$,$n_{1}= kn_{2}$

例 用两种药物对糖尿病患者进行康复治疗，经初步观察发现甲药的有效率为70%，乙药(对照)的有效率为90%，现进行进一步1:1显著行性设计在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？
```{r}
TwoSampleProportion.Equality(0.05,0.1,0.7,0.9,1,(0.7-0.9))
```
每组需要78例，TwoSampleProportion.Equality()函数中的delta相当于样本计算公式的$\epsilon$。

####非劣效/优效性检验
$p_{1}$为第一组(试验组)的率，$p_{2}$为第二组（对照组）的率，差值为$\epsilon$，$\delta$为界值，样本容量为$n_{2}=\frac{(z_{\alpha}+z_{\beta })^{2}}{(\epsilon-\delta ) ^{2}}[\frac{p_{1}(1-p_{1})}{k}+p_{2}(1-p_{2})]$,$n_{1}= kn_{2}$

例 用两种药物对糖尿病患者进行康复治疗，经初步观察发现甲药的有效率为70%，乙药(对照)的有效率为90%，现进行进一步1:1非劣效设计，界值为5%，在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量？

```{r}
TwoSampleProportion.NIS2 <- function (alpha, beta, p1, p2, k, delta, margin) 
{
    n2 <- (qnorm(1 - alpha) + qnorm(1 - beta))^2 * (p1 * (1 - p1)/k + p2 * (1 - p2))/(margin-delta)^2
    n1 <- k * n2
    n1
}

TwoSampleProportion.NIS2(0.05,0.1,0.7,0.9,1,-0.05,(0.7-0.9))
```
每组需要114例,TrialSize的作者在TwoSampleProportion.NIS()函数中delta和margin代表的意义，与样本量计算公式有不相符之处，但可以得到正确结果TwoSampleProportion.NIS2(0.05,0.1,0.7,0.9,1,(0.7-0.9),-0.05).


####等效性检验
$p_{1}$为第一组(试验组)的率，$p_{2}$为第二组（对照组）的率，差值为$\epsilon$，$\delta$为界值，样本容量为$n_{2}=\frac{(z_{\alpha}+z_{\beta/2})^{2}}{(\delta- |\epsilon|) ^{2}}[\frac{p_{1}(1-p_{1})}{k}+p_{2}(1-p_{2})]$,$n_{1}= kn_{2}$
例 用两种药物对糖尿病患者进行康复治疗，经初步观察发现甲药的有效率为70%，乙药(对照)的有效率为90%，现进行进一步1:1等效性设计，界值为5%，在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量?

```{r}
TwoSampleProportion.Equivalence2 <- function (alpha, beta, p1, p2, k, delta, margin) 
{
    n2 <- (qnorm(1 - alpha) + qnorm(1 - beta/2))^2 * (p1 * (1 - 
        p1)/k + p2 * (1 - p2))/(delta- abs(margin))^2
    n1 <- k * n2
    n1
}

TwoSampleProportion.Equivalence2(0.05,0.1,0.7,0.9,1,0.05,(0.7-0.9))
```
每组需要144例,TrialSize的作者在TwoSampleProportion.Equivalence()函数中delta和margin代表的意义，与样本量计算公式有不相符之处，beta也未除以2.

###两组交叉设计(Two-Sample Crossover Design)

####显著性检验
$\sigma$为两组率的差的标准差,$\epsilon$为试验组率-对照组率，样本容量为$n=\frac{(z_{\alpha /2}+z_{\beta })^{2}\sigma^2_{d}}{2\epsilon ^{2}}$

例 实验药和对照药品治疗中风，患者先服用对照药品 1 个月，洗脱2 周，再服用试验药1 个月，另一组反之。如果试验药能够比对照药品的有效率高 20%（差值），则认为有推广价值。预试验差值标准差为10。选用 $\alpha=0.05$,Power=90%, 双侧显著性检验，需要多少样本含量? 

```{r}
TwoSamplePropCrossOver.Equality <- function (alpha, beta, sigma, margin) 
{
    n <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * sigma^2/2*(margin^2)
    n
}

TwoSamplePropCrossOver.Equality(0.05,0.1,10,0.2)
```
每组需要21例.

####非劣效/优效性检验
$\sigma$为率的标准差，样本容量为$n=\frac{(z_{\alpha}+z_{\beta })^{2}\sigma^2_{d}}{2(\epsilon-\delta)^{2}}$

例 实验药和对照药品治疗中风，患者先服用对照药品 1 个月，洗脱2 周，再服用试验药1 个月，另一组反之。如果试验药能够比对照药品的有效率高 20%（差值），则认为有推广价值。预试验差值标准差为10。选用 $\alpha=0.05$,Power=90%,界值为10%，双侧非劣效检验，需要多少样本含量? 

```{r}
TwoSamplePropCrossOver.NIS <- function (alpha, beta, sigma, delta,margin) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta))^2 * sigma^2/2*(margin-delta)^2
    n
}

TwoSamplePropCrossOver.NIS(0.05,0.1,10,-0.1,0.2)
```
每组需要38例。

####等效性检验
$\sigma$为率的标准差，样本容量为$n=\frac{(z_{\alpha}+z_{\beta/2 })^{2}\sigma^2_{d}}{2(\delta-|\epsilon|)^{2}}$

例 实验药和对照药品治疗中风，患者先服用对照药品 1 个月，洗脱2 周，再服用试验药1 个月，另一组反之。如果试验药能够比对照药品的有效率高 20%（差值），则认为有推广价值。预试验差值标准差为10。选用 $\alpha=0.05$,Power=90%,界值为10%，双侧等效性检验，需要多少样本含量? 

```{r}
TwoSamplePropCrossOver.Equivalence <- function (alpha, beta, sigma, delta,margin) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta/2))^2 * sigma^2/2*(delta-abs(margin))^2
    n
}

TwoSamplePropCrossOver.Equivalence(0.05,0.1,10,-0.1,0.2)
```
每组需要49例。

###多组设计(One-Way Analysis of Variance)

在试验因素只有一个，且该因素的水平$k\geqslant 3$时，为多组平行对照设计，又称单因素多水平设计（ANOVA）。

####两两比较
试验组为2个或以上，且设有对照的试验设计，主要观察指标为计数资料。检验功效为$1-\beta$，置信度为$1-\alpha$,差值为$\epsilon = \mu_{i} − \mu_{j}$取最小值，样本量为$n_{ij}=\frac{(z_{\alpha/(2\tau))}+z_{\beta})^2[p_{1}(1-p_{1})+p_{2}(1-p_{2})]}{\epsilon ^{2}_{ij}}$，$n=max{n_{ij}}$。上述公式适用了多组平行对照设计。

例 试验药两剂量的有效率分别30%和35%，对照的有效率为20%，进行1：1：1的平行对照实验，在
在$\alpha=0.05$,$\beta=0.1$，问需要多大的样本容量?

```{r}
n1 <- OneWayANOVA.PairwiseComparison(0.05,0.1,2,0.3,0.2,(0.3-0.2))
n2 <- OneWayANOVA.PairwiseComparison(0.05,0.1,2,0.35,0.2,(0.35-0.2))
n <- max(n1,n2)
n
```
每组需要459例。

#### Williams设计(Williams Design)

####显著性检验
$\sigma$为标准差，$a$为组数，$\epsilon$为率差，样本容量为$n=\frac{(z_{\alpha/2}+z_{\beta })^{2}\sigma^2_{d}}{a\epsilon^{2}}$。

例 一个新型药品的两个剂量组与安慰剂进行临床试验，预计两个剂量组的有效率分别为60%和65%，安慰剂的有效率为20%，研究者感兴趣是第一剂量组与安慰剂的差别，其率差的标准差为50%，Williams三交叉设计，在$\alpha=0.05$,$\beta=0.1$，双侧差异性检验，需要多少样本？

```{r}
PorpWilliamsDesign.Equality <- function (alpha, beta, sigma, a, margin) 
{
    n <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * sigma^2/(a * 
        margin^2)
    n
}

PorpWilliamsDesign.Equality(0.05,0.1,0.5,6,(0.6-0.2))
```
每个研究需要至少3个病例。

####非劣效/优效性检验
$\sigma$为标准差，$a$为组数，$\epsilon$为率差，a为组数,样本容量为$n=\frac{(z_{\alpha}+z_{\beta })^{2}\sigma^2_{d}}{a(\epsilon-\delta)^{2}}$。

例 一个新型药品的两个剂量组与安慰剂进行临床试验，预计两个剂量组的有效率分别为60%和65%，安慰剂的有效率为20%，研究者感兴趣是第一剂量组与安慰剂的差别，其率差的标准差为50%，Williams三交叉设计，在$\alpha=0.05$,$\beta=0.1$，界值为5%，双侧非劣效检验，需要多少样本？

```{r}
PropWilliamsDesign.NIS <- function (alpha, beta, sigma, a, delta, margin) 
{
  n <- (qnorm(1 - alpha) + qnorm(1 - beta))^2 * sigma^2/(a * (margin - delta)^2)
  n
}

PropWilliamsDesign.NIS (0.05,0.1,0.5,6,-0.05,(0.6-0.2))
```
每个研究需要至少2个病例。

####等效性检验
$\sigma$为标准差，$a$为组数，$\epsilon$为率差，a为组数,样本容量为$n=\frac{(z_{\alpha}+z_{\beta/2 })^{2}\sigma^2_{d}}{a(\delta-|\epsilon|)^{2}}$。

例 一个新型药品的两个剂量组与安慰剂进行临床试验，预计两个剂量组的有效率分别为60%和65%，安慰剂的有效率为20%，研究者感兴趣是第一剂量组与安慰剂的差别，其率差的标准差为50%，Williams三交叉设计，在$\alpha=0.05$,$\beta=0.1$，界值为5%，双侧等效性检验，需要多少样本？

```{r}
PropWilliamsDesign.Equivalence <- function (alpha, beta, sigma, a, delta, margin) 
{
  n <- (qnorm(1 - alpha) + qnorm(1 - beta/2))^2 * sigma^2/(a * (delta-abs(margin ))^2)
  n
}

PropWilliamsDesign.Equivalence (0.05,0.1,0.5,6,0.05,(0.6-0.2))
```
每个研究需要至少4个病例。

### 相对危险度平行设计(Relative Risk—Parallel Design)
两样本(两组)平行对照设计，基于相对危险度，通常用比值比或优势比（odds radtio，OR）表示$OR=\frac{p_{t}/(1-p_{t})}{p_{c}/(1-p_{c})}$，t为试验组，c为对照组。比值比大于1说明对结局有影响，比值比等于1说明对结局的影响没有区别。

#### 显著性检验
OR为比值比，$p_{T}$试验组率,$p_{C}$为对照粗率，样本量$n_{C}=\frac{(z_{\alpha/2}+z_{\beta})^{2}}{log^{2}(OR)}\begin{pmatrix}
\frac{1}{\kappa p_{T}(1-p_{T})}+\frac{1}{\kappa p_{C}(1-p_{C})}
\end{pmatrix}$,$\kappa=n_{T}/n_{C}$
例 研究新型抗血小板药预防脑梗死再发的作用，和阿司匹林进行对照,以相对危险度为主要评价指标。预实验显示，新药能够预防20%的脑梗死再发，阿司匹林能够预防10%的脑梗死再发。在$\alpha=0.05$,$\beta=0.1$，1：1双侧显著性检验，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRisk.Equality(0.05,0.1,OR,1,0.2,0.1)
```
试验组和对照组均需要277例。

#### 非劣效/优效性检验
OR为比值比，$p_{T}$试验组率,$p_{C}$为对照粗率，$\delta$为界值，样本量$n_{C}=\frac{(z_{\alpha}+z_{\beta})^{2}}{(log(OR)-\delta)^2}\begin{pmatrix}
\frac{1}{\kappa p_{T}(1-p_{T})}+\frac{1}{p_{C}(1-p_{C})}
\end{pmatrix}$
例 研究新型抗血小板药预防脑梗死再发的作用，和阿司匹林进行对照，以相对危险度为主要评价指标。预实验显示，新药能够预防20%的脑梗死再发，阿司匹林能够预防10%的脑梗死再发。在$\alpha=0.05$,$\beta=0.1$，1：1双侧非劣效检验，界值为10%，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRisk.NIS(0.05,0.1,OR,1,0.2,0.1,-0.1)
```
试验组和对照组均需要179例。


#### 等效性检验
OR为比值比，$p_{T}$试验组率,$p_{C}$为对照粗率，$\delta$为界值,样本量$n_{C}=\frac{(z_{\alpha}+z_{\beta/2})^{2}}{(\delta-log(OR))^2}\begin{pmatrix}
\frac{1}{\kappa p_{T}(1-p_{T})}+\frac{1}{p_{C}(1-p_{C})}
\end{pmatrix}^{-1}$

例 研究新型抗血小板药预防脑梗死再发的作用，和阿司匹林进行对照，以相对危险度为主要评价指标。预实验显示，新药能够预防20%的脑梗死再发，阿司匹林能够预防10%的脑梗死再发。在$\alpha=0.05$,$\beta=0.1$，1：1双侧等效性检验，界值为10%，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRisk.Equivalence(0.05,0.1,OR,1,0.2,0.1,0.1)
```
试验组和对照组均需要372例。

### 相对危险度交叉设计(Relative Risk—Crossover Design)
交叉设计与随机平行对照设计相比，需要的样本量较少，但该设计的前提是所治疗疾病在停药后基本会回复到用药前的状态，中间停药时间（洗脱期）的长度基本清楚。

####显著性检验
OR为比值比，$\sigma^{2}_{d}$为差值的标准差。样本量为$n=\frac{(z_{\alpha/2}+z_{\beta})^{2}\sigma^{2}_{d}}{log^{2}(OR)}$

例 某新型药品治疗头痛后7日再发率为20%，标准治疗头痛后7日再发率为10%，以相对为危险度为主要评价指标,标准差为50%，两组交叉对照1：1设计，在在$\alpha=0.05$,$\beta=0.1$，1：1双侧显著性检验，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRiskCrossOver.Equality <- function (alpha, beta, sigma, or) 
{
    n <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * sigma^2/(log(or))^2
    n
}
RelativeRiskCrossOver.Equality(0.05,0.1,0.5,OR)
```
每组至少需要4例，TrialSize包中RelativeRiskCrossOver.Equality()函数在sigma处有误，没有取平方。

####非劣效/优效性检验
OR为比值比，$\sigma^{2}_{d}$为差值的标准差，$\delta$为界值。样本量为$n=\frac{(z_{\alpha}+z_{\beta})^{2}\sigma^{2}_{d}}{[log^{2}(OR)-\delta]^{2}}$

例 某新型药品治疗头痛后7日再发率为20%，标准治疗头痛后7日再发率为10%，以相对为危险度为主要评价指标，两组交叉对照1：1设计，在在$\alpha=0.05$,$\beta=0.1$，1：1双侧非劣效性检验，界值为10%，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRiskCrossOver.NIS <- function (alpha, beta, sigma, or,delta) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta))^2 * sigma^2/(log(or) - delta)^2
    n
}
RelativeRiskCrossOver.NIS(0.05,0.1,0.5,OR,-0.1)
```
每组至少需要3例，TrialSize包中RelativeRiskCrossOver.NIS()函数在sigma处有误，没有取平方。

####等效性检验
OR为比值比，$\sigma^{2}_{d}$为差值的标准差,$\delta$为界值。样本量为$n=\frac{(z_{\alpha}+z_{\beta/2})^{2}\sigma^{2}_{d}}{(\delta-|log^{2}(OR)|)^{2}}$

例 某新型药品治疗头痛后7日再发率为20%，标准治疗头痛后7日再发率为10%，以相对为危险度为主要评价指标，两组交叉对照1：1设计，在$\alpha=0.05$,$\beta=0.1$，1：1双侧等效性检验，界值为10%，需要多少病例？

```{r}
OR <- (0.2/(1-0.2))/(0.1/(1-0.1))
RelativeRiskCrossOver.Equivalence <- function (alpha, beta, sigma, or, delta) 
{
    n <- (qnorm(1 - alpha) + qnorm(1 - beta/2))^2 * sigma^2/(delta- abs(log(or)))^2
    n
}
RelativeRiskCrossOver.Equivalence(0.05,0.1,0.5,OR,0.1)
```
每组至少需要3例，TrialSize包中RelativeRiskCrossOver.Equivalence()函数在sigma处有误，没有取平方。

##计数资料的精确检验(Exact Tests for Proportions)

###二项分布（Binomial Test）
二项分布检验常用于但组设计情况，其样本量估计方法适合较小样本计数资料的精确检验。二项分布检验样本量和临界值（Critical Value r）的估算表如下，在$\alpha=0.05$,$P_{1}-P_{0}=0.15$时，查下表，$1-\beta=0.80$为第三和第四列，$1-\beta=0.90$为第五和第六列。

$P_{0}$ $P_{1}$ r    n     r     n
---     ---     ---  ---   ---   ---
0.05    0.20    3	   27    4     38
0.10    0.25	  7	   40    9     55
0.15	  0.30    11	 48    14    64
0.20    0.35	  16	 56    21    77
0.25	  0.40    21	 62    27    83
0.30    0.45  	26	 67    35    93
0.35	  0.50    30	 68    41    96
0.40    0.55	  35	 71    45    94
0.45	  0.60	  38	 70    52    98
0.50    0.65	  41	 69    54    93
0.55	  0.70	  45	 70    58    92
0.60	  0.75	  43	 62    58    85
0.65	  0.80	  41	 55    55    75
0.70    0.85	  39	 49    54    69
0.75	  0.90	  38	 45    46    55
0.80    0.95	  27	 30    39    44

在$\alpha=0.10$,$P_{1}-P_{0}=0.15$时，查下表，$1-\beta=0.80$为第三和第四列，$1-\beta=0.90$为第五和第六列。

$P_{0}$ $P_{1}$ r    n     r     n
---     ---     ---  ---   ---   ---
0.05    0.20    2    21	   3	   32
0.10	  0.25    5    31	   6	   40
0.15    0.30    8	   37	   11	   53
0.20	  0.35    12   44	   16	   61
0.25    0.40    15	 46	   20	   64
0.30	  0.45    19	 50	   26	   71
0.35    0.50    21	 49	   30	   72
0.40	  0.55    24	 50    35	   75
0.45    0.60    28	 53	   39	   75
0.50	  0.65    31	 53	   41	   72
0.55    0.70    31	 49	   44	   71
0.60	  0.75    32	 47	   43	   64
0.65    0.80    33	 45    44	   61
0.70	  0.85    29	 37	   41	   53
0.75    0.90    25	 30	   33	   40
0.80	  0.95    22	 25	   28	   32

在$\alpha=0.05$,$P_{1}-P_{0}=0.20$时，查下表，$1-\beta=0.80$为第三和第四列，$1-\beta=0.90$为第五和第六列。

$P_{0}$ $P_{1}$ r    n     r     n
---     ---     ---  ---   ---   ---
0.05    0.25	  2	   16	   3	   25
0.10	  0.30	  5	   25	   6	   33
0.15	  0.35	  7	   28	   9	   38
0.20	  0.40	  11	 35	   14	   47
0.25	  0.45	  13	 36	   17	   49
0.30	  0.50	  16	 39	   21	   53
0.35	  0.55	  19	 41	   24	   53
0.40	  0.60	  22	 42	   28	   56
0.45	  0.65	  24	 42	   30	   54
0.50	  0.70	  23	 37	   32	   53
0.55	  0.75	  25	 37	   33	   50
0.60	  0.80	  26	 36	   32	   45
0.65	  0.85	  24	 31	   32	   42
0.70	  0.90	  23	 28	   30	   37
0.75	  0.95	  20	 23	   25	   29
0.80	  1.00	  13	 14	   13	   14

在$\alpha=0.10$,$P_{1}-P_{0}=0.20$时，查下表，$1-\beta=0.80$为第三和第四列，$1-\beta=0.90$为第五和第六列。

$P_{0}$ $P_{1}$ r    n     r     n
---     ---     ---  ---   ---   ---
0.05    0.25	  2    16	   2	   20
0.10	  0.30	  3	   18	   4	   25
0.15	  0.35	  5	   22	   7	   32
0.20	  0.40	  7	   24	   10	   36
0.25	  0.45	  9	   26	   13	   39
0.30	  0.50	  12	 30	   15	   39
0.35	  0.55  	13	 29	   19	   44
0.40	  0.60	  15	 30	   20	   41
0.45	  0.65  	16	 29	   24	   44
0.50	  0.70	  17	 28	   23	   39
0.55	  0.75	  19	 29	   25	   39
0.60	  0.80	  17	 24	   25	   36
0.65	  0.85	  16	 21	   24	   32
0.70	  0.90	  17	 21	   20	   25
0.75	  0.95	  13	 15	   17	   20
0.80	  1.00	  10	 11	   10	   11

例 预试验中某新型抗肿瘤药品治疗某癌症的治愈率为30%，标准治疗的治愈率为10%，单组设计，二项分布检验，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？
```{r}
p <- seq(0.05,0.80,by=0.05)
dim <- c("beta0.2r","beta0.2n","beta0.1r","beta0.1n")
dim3 <- c("p0.15alpha0.05","p0.15alpha0.10","p0.20alpha0.05","p0.20alpha0.10")
data<- c(3,7,11,16,21,26,30,35,38,41,45,43,41,39,38,27,27,40,48,56,62,67,68,71,70,69,
         70,62,55,49,45,30,4,9,14,21,27,35,41,45,52,54,58,58,55,54,46,39,38,55,64,77,
         83,93,96,94,98,93,92,85,75,69,55,44,2,5,8,12,15,19,21,24,28,31,31,32,33,29,
         25,22,21,31,37,44,46,50,49,50,53,53,49,47,45,37,30,25,3,6,11,16,20,26,30,35,
         39,41,44,43,44,41,33,28,32,40,53,61,64,71,72,75,75,72,71,64,61,53,40,32,2,5,
         7,11,13,16,19,22,24,23,25,26,24,23,20,13,16,25,28,35,36,39,41,42,42,37,37,
         36,31,28,23,14,3,6,9,14,17,21,24,28,30,32,33,32,32,30,25,13,25,33,38,47,49,
         53,53,56,54,53,50,45,42,37,29,14,2,3,5,7,9,12,13,15,16,17,19,17,16,17,13,
         10,16,18,22,24,26,30,29,30,29,28,29,24,21,21,15,11,2,4,7,10,13,15,19,20,24,
         23,25,25,24,20,17,10,20,25,32,36,39,39,44,41,44,39,39,36,32,25,20,11)

z <- array(data,c(16,4,4),dimnames<-list(p,dim,dim3))

BinProp <- function(alpha, beta,p0,p1){
  col1<- paste(paste("beta",beta,sep=""),"n",sep="")
  col2 <- paste(paste("beta",beta,sep=""),"r",sep="")
  row <- paste(paste("p",format(p1-p0,digits = 2,nsmall = 2),sep = ""),
               paste("alpha",alpha,sep = ""),sep="")
  c(n=z[which(p==p0),col1,row],r=z[which(p==p0),col2,row])
}

BinProp(0.05,0.1,0.1,0.3)
```
需要33个病例，临界值为6。

###Fisher’s精确检验(Fisher’s Exact Test)
在两组平行对照设计中，当四格表中有理论数小于5,或者总观察数小于40时，需要Fisher‘s精确检验。样本含量的精确估计需要查询下表获得检验水平为0.05或为0.1,把握度为0.8或0.9时，不同率差的样本量。
率差为0.25时，查询下表

$p_{1}$    $p_{2}$    $alpha0.10beta0.20$    $alpha0.10beta0.10$    $alpha0.05beta0.20$   $alpha0.05beta0.10$
---        ---        ---                    ---                    ---                   ---
0.05       0.30       25                     33                     34                    42
0.10       0.35       31                     41                     39                    52
0.15       0.40       34                     48                     46                    60
0.20       0.45       39                     52                     49                    65
0.25       0.50       40                     56                     54                    71
0.30       0.55       41                     57                     55                    72
0.35       0.60       41                     57                     56                    77
0.40       0.65       41                     57                     56                    77
0.45       0.70       41                     57                     55                    72
0.50       0.75       40                     56                     54                    71
0.55       0.80       39                     52                     49                    65
0.60       0.85       34                     48                     46                    60
0.65       0.90       31                     41                     39                    52
0.70       0.95       25                     33                     34                    42

率差为0.30时，查询下表

$p_{1}$    $p_{2}$    $alpha0.10beta0.20$    $alpha0.10beta0.10$    $alpha0.05beta0.20$   $alpha0.05beta0.10$
---        ---        ---                    ---                    ---                   ---
0.05       0.35       20                     26                     25                    33
0.10       0.40       23                     32                     30                    39
0.15       0.45       26                     35                     34                    45
0.20       0.50       28                     39                     36                    47
0.25       0.55       29                     40                     37                    51
0.30       0.60       29                     40                     41                    53
0.35       0.65       33                     40                     41                    53
0.40       0.70       29                     40                     41                    53
0.45       0.75       29                     40                     37                    51
0.50       0.80       28                     39                     36                    47
0.55       0.85       26                     35                     34                    45
0.60       0.90       23                     32                     30                    39

率差为0.35时，查询下表

$p_{1}$    $p_{2}$    $alpha0.10beta0.20$    $alpha0.10beta0.10$    $alpha0.05beta0.20$   $alpha0.05beta0.10$
---        ---        ---                    ---                    ---                   ---
0.05       0.40       16                     21                     20                    25
0.10       0.45       19                     24                     24                    31
0.15       0.50       20                     28                     26                    34
0.20       0.55       23                     29                     27                    36
0.25       0.60       24                     29                     30                    36
0.30       0.65       24                     33                     31                    40
0.35       0.70       24                     33                     31                    40
0.40       0.75       24                     29                     30                    36
0.45       0.80       23                     29                     27                    36
0.50       0.85       20                     28                     26                    34
0.55       0.90       19                     24                     24                    31
0.60       0.95       16                     21                     20                    25

例 预试验中某新型抗肿瘤药品治疗某癌症的治愈率为35%，标准治疗的治愈率为10%，两组平行对照1：1设计，双侧差异性检验，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
dim1 <- c("p1","p2","alpha0.10beta0.20","alpha0.10beta0.10","alpha0.05beta0.20"
          ,"alpha0.05beta0.10")
p <- seq(1:14)
data1 <-c(0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,
          0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,
          25,31,34,39,40,41,41,41,41,40,39,34,31,25,33,41,48,52,56,57,57,57,57,
          56,52,48,41,33,34,39,46,49,54,55,56,56,55,54,49,46,39,34,42,52,60,65,
          71,72,77,77,72,71,65,60,52,42)
p0.25 <- array(data1,c(14,6),dimnames<-list(p,dim1))

p <- seq(1:12)
data2 <- c(0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.35,0.40,
           0.45,0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,20,23,26,28,29,29,
           33,29,29,28,26,23,26,32,35,39,40,40,40,40,40,39,35,32,25,30,34,36,
           37,41,41,41,37,36,34,30,33,39,45,47,51,53,53,53,51,47,45,39)
p0.30 <- array(data2,c(12,6),dimnames<-list(p,dim1))

p <- seq(1:12)
data3 <- c(0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50,0.55,0.60,0.40,0.45,
           0.50,0.55,0.60,0.65,0.70,0.75,0.80,0.85,0.90,0.95,16,19,20,23,24,24,24,
           24,23,20,19,16,21,24,28,29,29,33,33,29,29,28,24,21,20,24,26,27,30,31,
           31,30,27,26,24,20,25,31,34,36,36,40,40,36,36,34,31,25)
p0.35 <- array(data3,c(12,6),dimnames<-list(p,dim1))
z <- list(p0.25=p0.25,p0.30=p0.30,p0.35=p0.35)

FisherTest <- function(alpha,beta,p1,p2){
  table <- paste("p",format(p2-p1,digits = 2,nsmall = 2),sep="")
  row <- as.numeric(which(z[[table]][,1]==p1))
  col <- paste(paste("alpha",alpha,sep=""),paste("beta",format(beta,nsmall=2),
                                                 sep=""),sep="")
  z[[table]][row,col]
}

FisherTest(0.05,0.1,0.10,0.35)
```
每组是少需要52例。

###单组优化多阶段设计(Optimal Multiple-Stage Designs for Single Arm Trials)

####最优化两阶段设计（Optimal Two-Stage Designs）
该设计中，当出现了一定数量的失败后，容许实验结束。该设计的的样本量可以通过查询下表获得。

```{r}
data <- read.table("OptimalTwoStageDesigns",header = T)
panderOptions('table.split.table',140)  #改变默认80的宽度
panderOptions('digits', 2)
pander(data)
```

例 一新型抗肿瘤药品进行二期临床试验，标准治疗的有效率为20%，如果新型药品的有效率达40%，则认为有临床价值。最优化两阶段设计，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
OptimalTwoStageDesigns <- function(alphap,betap,p0p,p1p){
  data <- read.table("OptimalTwoStageDesigns",header = T)
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}

OptimalTwoStageDesigns(0.05,0.1,0.20,0.40)
```
第一阶段供需19例，其中4例有效，则可以进行第二阶段的试验。第二阶段需继续做5例，达到24例，如果至少5例有效，则可进行进一步的研究。

####灵活两阶段设计（Flexible Two-Stage Designs）
该设计对两个阶段的病例数给出多个选择，优化灵活两阶段设计样本量和界值可查询下表。

```{r}
data <- read.csv("OptimalFlexibleTwoStage.csv",header=T)
for(i in 1:length(data$p0)){
  if(is.na(data$p0[i])==T){
    data$p0[i]  <- data$p0[i-1] 
    data$p1[i]  <- data$p1[i-1] 
  }
}
panderOptions('digits', 2)
panderOptions('table.split.table',500)  
#panderOptions('table.alignment.default','left')
#panderOptions('table.split.cells',40)
pander(data,justify = c('center','center','center','center', 'center', 'center')) #调整对齐方式
```

例 一新型抗肿瘤药品进行二期临床试验，标准治疗的有效率为20%，如果新型药品的有效率达40%，则认为有临床价值。优化灵活两阶段设计，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
OptimalFlexibleTwoStageDesigns <- function(alphap,betap,p0p,p1p){
  data <- read.csv("OptimalFlexibleTwoStage.csv",header=T)
for(i in 1:length(data$p0)){
  if(is.na(data$p0[i])==T){
    data$p0[i]  <- data$p0[i-1] 
    data$p1[i]  <- data$p1[i-1] 
  }
}
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}

OptimalFlexibleTwoStageDesigns(0.05,0.1,0.20,0.40)
```
该研究第一阶段需要18-20个病例，如果至少4例有效，则可进行第二阶段试验。第二阶段继续做28～30个病例，总数达到48例。如果13例有效，则可进行进一步研究。

极小灵活两阶段设计样本量和界值可查询下表。

```{r}
data <- read.csv("MinimaxFlexibleTwoStage.csv",header=T)
for(i in 1:length(data$p0)){
  if(is.na(data$p0[i])==T){
    data$p0[i]  <- data$p0[i-1] 
    data$p1[i]  <- data$p1[i-1] 
  }
}
panderOptions('digits', 2)
panderOptions('table.split.table',500)  
pander(data,justify = c('center','center','center',
                        'center', 'center', 'center'))
```

例 一新型抗肿瘤药品进行二期临床试验，标准治疗的有效率为20%，如果新型药品的有效率达40%，则认为有临床价值。优化灵活两阶段设计，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
MinimaxFlexibleTwoStageDesigns <- function(alphap,betap,p0p,p1p){
  data <- read.csv("MinimaxFlexibleTwoStage.csv",header=T)
for(i in 1:length(data$p0)){
  if(is.na(data$p0[i])==T){
    data$p0[i]  <- data$p0[i-1] 
    data$p1[i]  <- data$p1[i-1] 
  }
}
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}

MinimaxFlexibleTwoStageDesigns(0.05,0.1,0.20,0.40)
```
该研究第一阶段需要27-29个病例，如果至少5例有效，则可进行第二阶段试验。第二阶段继续做16个病例，总数达到43-45例。如果13例有效，则可进行进一步研究。

####优化三阶段设计（Optimal Three-Stage Designs）
该设计的基本模式和两阶段相同。其样本含量和临界值，Ensign等可查询下表

```{r}
data <- read.csv("OptimalThreeStageDesignsEnsign.csv",header=T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
panderOptions('digits', 2)
panderOptions('table.split.table',500)  
pander(data)
```
Chen扩展的样本量和临床界值可查询下表

```{r}
data <- read.csv("OptimalThreeStageDesignsChen.csv",header = T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
panderOptions('digits', 2)
panderOptions('table.split.table',500)  
pander(data)
```

例 一新型抗肿瘤药品进行二期临床试验，标准治疗的有效率为20%，如果新型药品的有效率达40%，则认为有临床价值。优化三阶段设计，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
OptimalThreeStageDesignsEnsign<- function(alphap,betap,p0p,p1p){
  data <- read.csv("OptimalThreeStageDesignsEnsign.csv",header = T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
  
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}


OptimalThreeStageDesignsChen <- function(alphap,betap,p0p,p1p){
  data <- read.csv("OptimalThreeStageDesignsChen.csv",header = T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
  
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}

OptimalThreeStageDesignsEnsign(0.05,0.1,0.20,0.40)
OptimalThreeStageDesignsChen(0.05,0.1,0.20,0.40)
```
依据Ensign法，该研究第一阶段需要9名病例，如果是少有1例有效，则可以进行第二阶段研究。第二阶段继续做14例，达到23例，如果至少4例有效，则可以进行第三阶段的研究。第三阶段继续做31例，达到54例，如果至少有15例有效，则可进行进一步研究。Chen法的结果解释类似。

极小三阶段设计需要的样本两最小，其样本含量和临界值可查询下表
```{r}
data <- read.csv("MinimaxThreeStageDesignsChen.csv",header = T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
panderOptions('digits', 2)
panderOptions('table.split.table',500)  
pander(data)
```

例 一新型抗肿瘤药品进行二期临床试验，标准治疗的有效率为20%，如果新型药品的有效率达40%，则认为有临床价值。极小三阶段设计，在$\alpha=0.05$,$\beta=0.1$，需要多少病例？

```{r}
MinimaxThreeStageDesignsChen <- function(alphap,betap,p0p,p1p){
  data <- read.csv("MinimaxThreeStageDesignsChen.csv",header = T)
  
  for(i in 1:length(data$p0)){
    if(is.na(data$p0[i])==T){
      data$p0[i]  <- data$p0[i-1] 
      data$p1[i]  <- data$p1[i-1] 
    }
  }
  
  data%>>%
    subset(p0==p0p)%>>%
    subset(p1==p1p)%>>%
    subset(alpha==alphap)%>>%
    subset(beta==betap)%>>%
    return()
}

MinimaxThreeStageDesignsChen(0.05,0.1,0.20,0.40)
```
该研究第一阶段需要16名病例，如果是少有2例有效，则可以进行第二阶段研究。第二阶段继续做12例，达到28例，如果至少6例有效，则可以进行第三阶段的研究。第三阶段继续做17例，达到45例，如果至少有13例有效，则可进行进一步研究。

####多组灵活设计（Flexible Designs for Multiple-Arm Trials）
该设计需要事先规定一个有临床意义的界值$[-\delta,\delta]$，如果率的差值大于$\delta$
，那么，率大的组被选择，如果率的差值小于或者等于$\delta$，在选择过长中就需要考虑其他因素。此种设计，不是比较各组之间和好坏，而是尽可能正确的选择出优势治疗的存在，以便进一步研究。两组灵活设计的样本量，在$\delta= 0.05\,  \rho= 0 \, or\,  \rho = 0.5$可查询下表，$\lambda$为预先指定的阈值。
```{r}
data <- read.csv("FlexibleDesignsforTwoArm.csv",header = T)
pander(data)
```

例 一新型抗肿瘤药品与现有标准治疗对照进行二期临床试验，如果新型药品的有效率达35%，标准治疗有效率为20%，两组灵活设计，在$\delta=0.05$,$\rho=0$，$\lambda=0.90$需要多少病例？

```{r}
FlexibleDesignsforTwoArm <- function(p1p,p2p){
  data <- read.csv("FlexibleDesignsforTwoArm.csv",header = T)
  data%>>%
    subset(p1==p1p)%>>%
    subset(p2==p2p)%>>%
    return()
}

FlexibleDesignsforTwoArm(0.20,0.35)
```
每组至少需要57例。

多组灵活设计，在$\delta= 0.05\,  \lambda= 0.8 \, or\,  \lambda = 0.9$可查询下表，$\lambda$为预先指定的阈值
```{r}
data <- read.csv("FlexibleDesignsforMultipleArm.csv",header = T)
pander(data)
```
例 一新型抗肿瘤药品与两个标准治疗对照进行二期临床试验，预计新型药品比对照的有效率高30%（$\epsilon=0.3$），三组灵活设计，在$\delta=0.05$,$\rho=0$，$\lambda=0.90$需要多少病例？

```{r}
FlexibleDesignsforMultipleArm<- function(lambdap,epsilonp){
  data <- read.csv("FlexibleDesignsforMultipleArm.csv",header = T)
  data%>>%
    subset(lambda==lambdap)%>>%
    subset(epsilon==epsilonp)%>>%
    return()
}

FlexibleDesignsforMultipleArm(0.9,0.3)
```
每组至少需要77例。

##拟合优度和列联表检验的样本量估计（Tests for Goodness-of-Fit and Contingency Tables）
临床试验中，当计数资料的指标有多个类别，而不是二分类时，适合的检验方法通常为拟合优度检验、独立性检验（也称列联表检验）和categorical shift检验。

###拟合优度检验 (Tests for Goodness-of-Fit)，样本含量估算公式
$$n=\delta _{\alpha ,\beta }  \begin{bmatrix}
 \sum_{k=1}^{r}\frac{(p_{k}-p_{k,0})^{2}}{p_{k,0}}
\end{bmatrix}^{-1}$$,$p_{k}$为实验组每个分类的率，$p_{k,0}$为文献中每个分类的的率，$\delta_{\alpha ,\beta }$通过$F_{r-1}(\chi_{\alpha ,r-1}^{2}|\delta )=\beta$计算,$\delta =\underset{n \to \infty }{lim}\sum_{k=1}^{r}\frac{n(p_{k}-p_{k,0})^{2}}{p_{k,0}}$，r为分类的个数。

例 一探索性临床试验（pilot study），研究一降压药的临床疗效。预试验表明该药治疗高血压的显效率、进步率和无效率分别玩儿20%，60%和20%。文献报道，现有降压药的显效率、进步率和无效率分别为25%，45%和30%。单组设计，在$\alpha=0.05,\beta=0.2$时，双侧差异性检验，需要多少样本量？

```{r}
gof.Pearson(0.05,0.2,c(0.2,0.6,0.2),c(0.25,0.45,0.30),3)
```
该研究需要104例。

###单层独立性检验(Test for Independence—Single Stratum)
对于没有分层的r×c列联表数据（two-way），即单程列连数据，在进行样本量估计常用以下两种方法。

####Pearson’s Test
Pearson检验的样本量计算公式如下，
$$n=\delta _{\alpha ,\beta }\begin{bmatrix}
\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(p_{ij}-p_{i}p_{j})^{2}}{p_{i}p_{j}}
\end{bmatrix}^{-1}$$，$\delta _{\alpha ,\beta }$ 通过$$ F_{(r-1)(c-1)}(\chi _{\alpha,(r-1)(c-1))}^{2}|\delta)=\beta $$计算,$\delta =\underset{n \to \infty }{lim}\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{n(p_{ij}-p_{i.}p_{.j})^{2}}{p_{i.}p_{j.}}$，r代表横向分类数据的个数，c代表纵向分类数据的个数。

例 一新型降压要与对照药进行探索行临床试验，其结果如下

分组    无效    有效    显效  
---     ---      ---     ---
试验组  2        7       1
对照组  2        5       3

为验证差别的存在，设计较大规模的临床实验，两组平行1：1对照，在$\alpha=0.05,\beta=0.2$时，双侧差异性检验，需要多少样本量？

```{r error=FALSE}
gof.Pearson.twoway <- function (alpha, beta, trt, ctl, r, c) 
{
  p.ij <- rbind(trt, ctl)/(sum(trt) + sum(ctl))
  b = 0
  noncen = 0
  for (i in 1:1000) {
    b[i + 1] <- pchisq(qchisq(alpha, df = (r-1)*(c-1), ncp = 0, 
                              lower.tail = FALSE), df = (r-1)*(c-1), ncp = i/100)
    noncen = rbind(noncen, c(i, b[i], b[i + 1]))
  }
  delta = noncen[which(noncen[, 2] > beta & noncen[, 3] < 
                         beta)]/100
  n <- delta * (as.numeric(chisq.test(p.ij)$statistic))^-1
  return(n)
}

gof.Pearson.twoway(0.05, 0.2, c(0.2,0.7,0.1), c(0.2,0.5,0.3), 2, 3)
```
该研究每组需要`r round(gof.Pearson.twoway(0.05, 0.2, c(0.2,0.7,0.1), c(0.2,0.5,0.3), 2, 3),0)`例。TrialSize包中gof.Pearson.twoway()方法对自由度计算有误。

####似然比检验(Likelihood Ratio Test)
似然比检验的样本量计算公式等价于Pearson检验样本量计算公式。

###多层独立性检验(Test for Independence—Multiple Strata)
多中心临床实验不仅可以保障实验结果的可重复性和代表性，而且也有利于受试着在期望时间内入选。多中心临床实验属于多层列联表数据，当反映率是二分类资料时，CMH检验（Cochran-Mantel-Haenszel Test）是常用的检验方法。

分组    0            1            合计
---     ---          ---          ---
处理1   $n_{h,10}$   $n_{h,11}$   $n_{h,1.}$
处理2   $n_{h,20}$   $n_{h,21}$   $n_{h,2.}$
合计    $n_{h,.0}$   $n_{h,.1}$   $n_{h,..}$

其样本含量估计公式：$$\delta=lim\begin{vmatrix}
\frac{\sum _{h=1}^{H}\pi_{h} (p_{h,11}-p_{h,1.}p_{h,.1})}{\sqrt{\sum _{h=1}^{H}\pi_{h}p_{h,1.}p_{h,2.}p_{h,.0}p_{h,.1}}}
\end{vmatrix}$$,$$n=\frac{(z_{\alpha /2}+z_{\beta })^{2}}{\delta ^{2}}$$，$n_{h,ij}$是在第h层（中心），经i处理后，出现j反应的个数，$p_{h,ij}$是在h层（中心），经i处理后，出现j反应的率，$\pi_{h}=n_{h}/n$。此方法只使用于多中心临床实验中治疗反应数据是二分类的情况，对于多分类的数据，其样本量估算公式目前还没有可靠的方法。现在主要把p×r×c表合并成r*c表，用单层列联表样本量公式进行估算。

例 一新型抗肿瘤药与安慰剂对照进行小规模多中心探索性临床试验，主要目标是观察不良时间的发生率，其结果如下

分层    分组    反应无     反应有    合计
---     ---     ---        ---      ---
1       试验组  0.35       0.15     0.50
        对照组  0.25       0.25     0.50
2       试验组  0.30       0.20     0.50
        对照组  0.20       0.30     0.50
3       试验组  0.40       0.10     0.50
        对照组  0.20       0.30     0.50
4       试验组  0.35       0.15     0.50
        对照组  0.15       0.35     0.50
        
基于以上数据，研究者希望设计一个较大规模的临床实验，两组平行1：1对照设计，每个分层的样本数量相同，即$\pi=1/4$，在$\alpha=0.05,\beta=0.2$时，双侧差异性检验，需要多少样本量？

```{r}
CMH.Equality <- function(alpha,beta,p,h){
  pi <- 1/h
  numerator <- function(p){
    sum <- pi*(p[1,2]-rowSums(p)[1]*colSums(p)[2])
  }
  
  denominator <- function(p){
    sum <- pi*rowSums(p)[1]*rowSums(p)[2]*colSums(p)[1]*colSums(p)[2]
  }
  
  delta <- abs(sum(sapply(p,numerator))/sqrt(sum(sapply(p,denominator))))
  
  n <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 /(delta)^2
  n
}

p1 <- rbind(c(0.35,0.15),c(0.25,0.25))
p2 <- rbind(c(0.30,0.20),c(0.20,0.30))
p3 <- rbind(c(0.40,0.10),c(0.20,0.30))
p4 <- rbind(c(0.35,0.15),c(0.15,0.35))
p<-list(p1=p1,p2=p2,p3=p3,p4=p4)

CMH.Equality(0.05,0.2,p,4)
```
该研究每组需要`r round(CMH.Equality(0.05,0.2,p,4))`例。

###类别转换检验(Categorical Shift Test)
临床试验中，研究试验先后二分类的数据的变化情况，通常采用McNemar检验和Stuart-Maxwell检验。

####McNemar检验
对于下表，McNemar检验所需的样本两计算公式$$n=\frac{[z_{\alpha /2}(\varphi +1)+z_{\beta }\sqrt{(\varphi+1)^{2}-(\varphi-1)^{2}\pi_{Discordant}}]^{2}}{(\varphi -1)^{2}\pi _{Discordant}}$$,$\varphi =p_{01}/p_{10}$,$\pi_{Discordant}=p_{01}+p_{10}$。$p_{01}=P(x_{i1=0,x_{i2}=1})$,$p_{10}=P(x_{i1}=1,x_{i2}=1)$。

治疗前        治疗后阳性      治疗后阴性     合计
---           ---             ---            ---
阳性          $n_{00}$        $n_{01}$       $n_{0.}$
阴性          $n_{10}$        $n_{11}$       $n_{1.}$
合计          $n_{.0}$        $n_{01}$       $n_{..}$
              
例 某降血糖药物在餐前和餐后分别擦亮血糖值，根据临床预试验结果，治疗后有50%（$p_{10}=0.5$）低血糖患者转为正常，而20%（$p_{01}=0.2$）正常血糖转为低血糖，在$\alpha=0.05,\beta=0.2$时，双侧差异性检验，需要多少样本量？

```{r}
(McNemar.Test(0.05, 0.2, c(0.2/0.5), c(0.5+0.2)))
```
该研究至少需要`r round(McNemar.Test(0.05, 0.2, c(0.2/0.5), c(0.5+0.2)),0)`患者。

####Stuart-Maxwell检验
McNemar检验适合于二分类变量前后的比较，对于多分类变量，需要使用Stuart-Maxwell检验。其样本量计算公式如下：$$n=\delta _{\alpha ,\beta }\begin{bmatrix}
\sum_{i<j}\frac{(p_{ij}-p_{ji})^2}{p_{ij}+p_{ji}}
\end{bmatrix}^{-1}$$,$p_{ij}=P(x_{k1}=i,x_{k2}=j)$，$\delta =\underset{n \to \infty}{lim}n\sum _{i<j}\frac{(p_{ij}-p_{ji})^2}{p_{ij}+p_{ji}}$,$$F_{r(r-1)/2}(\chi _{\alpha ,r(r-1)/2}|\delta )=\beta $$。

治疗前     治疗后1      治疗后2     ...     治疗后r
---        ---          ---         ---     ---
1          $n_{11}$     $n_{12}$    ...     $n_{1r}$
2          $n_{21}$     $n_{22}$    ...     $n_{22}$
...
r          $n_{r1}$     $n_{r2}$    ...     $n_{rr}$
合计       $n_{.1}$     $n_{.2}$    ...     $n_{.r}$
           
例 一个小规模的探索性临床试验研究了某药物对单核细胞数量（按照比正常范围高、在正常范围和低于正常范围）的影响，结果如下

治疗前    治疗后低     治疗后正常    治疗后高
---       ---          ---           ---
低        3            4              4
正常      2            2              3
高        1            2              3

可以看出，该药有一定的升高单核细胞数量的作用。为证实这一趋势的存在，研究着设计一个临床试验，在$\alpha=0.05,\beta=0.2$时，需要多少样本量？

```{r}
Stuart.Maxwell.Test <- function(alpha,beta, p.ij, p.ji, r){
  b = 0
  noncen = 0
  
  for (i in 1:2000) {
    b[i + 1] <- pchisq(qchisq(alpha, df = r*(r - 1)/2, ncp = 0, 
                              lower.tail = FALSE), df = r*(r - 1)/2, ncp = i/100)
    noncen = rbind(noncen, c(i, b[i], b[i + 1]))
  }
  
  delta = noncen[which(noncen[, 2] > beta & noncen[, 3] < beta)]/100
  
  temp <-array(0,c(r,r)) 
  for (j in 1:r) {
    for (i in 1:j) {
      temp[i,j] <- (p.ij[i, j] - p.ji[j, i])^2/(p.ij[i, j] + p.ji[j, i])
    }
  }
  n <- delta*sum(temp)^-1
  n
}


alpha <- 0.05
beta <- 0.2
p.ij <- rbind(c(3, 4, 4), c(2, 3, 3), c(1, 2, 3))/25
p.ji <- rbind(c(3, 4, 4), c(2, 3, 3), c(1, 2, 3))/25
r <- 3

Stuart.Maxwell.Test(alpha,beta, p.ij, p.ji, r)
```

该研究至少需要`r round(Stuart.Maxwell.Test(alpha,beta, p.ij, p.ji, r),0)`例。TrialSize包中Stuart.Maxwell.Test()方法对自由度计算有误。

###残留效应检验(Carry-Over Effect Test)
残留效应是由于上一阶段的处理由于效应除去时间不足或其他原因干扰了下一阶段的处理效果，产生残留效应主要是由于第一阶段导致耐药性而产生的撤退效应、心理效应和患者身体状况因用药而改变所导致的遗留效应。在一些时候，研究者需要知道药物残留效应。其样本量估计公式如下：$$n=\frac{(z_{\alpha /2}+z_{\beta })^{2}(\sigma _{1}^{2}+\sigma _{2}^{2})}{\gamma ^{2}}$$ $\sigma _{1}$为AB顺序的标准差，$\sigma _{2}$为BA顺序的标准差，$\gamma$为AB和BA顺序残留效应的差值。

例 根据预试验得到A、B两种药物交叉设计的参数，$\gamma$为0.89,$\sigma_{1}$为2.3,$\sigma_{2}$为2.4,为证实这一残留效应在，研究着设计一个临床试验，在$\alpha=0.05,\beta=0.2$时，需要多少样本量？
```{r}
(Carry.Over(0.05,0.2,2.3^2,2.4^2,0.89))
```

该研究至少需要`r round(Carry.Over(0.05,0.2,2.3^2,2.4^2,0.89))`例。

##时间事件（生存分析）的样本量计算(Time-to-Event)
临床实验中，某些试验的结果并不是均数和有效率或治愈率，而是某种医学事件的发生时间，如果某项治疗能够阻止或延缓这些事件的发生，便认为治疗是有效。从观察到事件发生的时间称为事件发生时间(time-to-event)，如果研究的是终点是死亡，那么事件发生时间成为生存时间 (survial time)。除了生存结局作为判定标准以外，只要能让病人存活时间延长，这种治疗也应当是被认为有效的。基本概念有：事件（Event）指研究中规定的生存研究的终点，在研究开始之前就已经制定好。根据研究性质的不同，事件可以是患者的死亡、疾病的复发、仪器的故障等。生存时间(Survival time)指从某一起点到事件发生所经过的时间。生存是一个广义的概念，不仅仅指医学中的存活，也可以是肿瘤手术到复发和接触毒物到毒性反应等。删失（Sensoring）指由于所关心的事件没有被观测到或者无法观测到，以至于生存时间无法记录的情况。常由两种情况导致：（1）失访；（2）在研究终止时，所关心的事件还未发生。生存概率(survival probability)：表示某单位时段开始时存活的个体到该时段结束时仍存活的可能性大小。生存率(survival rate)：指研究对象经历个时段后仍存活的概率，即生存时间大于等于的概率，用$P(T \geqslant t)$表示。生存函数（Survival distribution function）又叫累积生存率，表达式为$S（t）=P(T>t)$,其中T为生存时间，该函数的意义是生存时间大于时间点t的概率。t=0时S(t)=1，随着t的增加S(t)递减（严格的说是不增），1-S(t)为累积分布函数，表示生存时间T不超过t的概率,其近似等于生存时间长于t的患者数/患者总数，生存函数在某时点的函数值就是生存率。死亡概率函数：简称为死亡概率，常用F(t)表示。代表一个观察对象从开始观察到时间t 为止的死亡概率，它与生存函数的关系为F(t)=1－S(t)。风险率函数(hazard function)指t时刻尚存活的研究对象死于t时刻后一瞬间的概率，为条件概率,用$h(t)=\underset{\Delta \rightarrow 0}{lim}\frac{n(t)-n(t+\Delta t)}{n(t)\Delta t}$表示，T为观察对象的生存时间，n(t)为t时刻的生存人数，$n(t+\Delta t)$为$t+\Delta t$时刻的生存人数，它与生存函数、死亡密度函数的关系为h (t)= f (t) / S(t)。

###基于指数模型的生存分析(Exponential Model)
生存时间是指从某个起始事件开始到某个终点事件的发生(出现反应)所经历的时间。一般不服从正态分布，有时近似服从指数分布、Weibull分布、Gompertz分布等，多数情况下往往不服从任何规则的分布类型。

####显著性检验
在假定服从指数分布的情况下，检验两组终点指标(生存率)的差异有无显著性。显著性检验样本量计算公式为：$$n_{2}=\frac{(z_{\alpha /2}+z_{\beta })^{2}}{(\lambda _{1}-\lambda _{2})^{2}}
\begin{bmatrix}
\frac{\sigma ^{2}(\lambda _{1})}{k}+\sigma ^{2}(\lambda _{2})
\end{bmatrix}
$$ 其中$k=\frac{n_{1}}{n_{2}}$，$$\sigma ^{2}(\lambda _{i})=\gamma _{i}^{2}\begin{bmatrix}
1+\frac{\lambda e^{-\lambda _{i} T}(1-e^{(\lambda _{i}-\gamma) T_{0}})}{(\lambda _{i}-\gamma)(1-e^{-\lambda T_{0}})}
\end{bmatrix}^{-1}$$ $n_{1}$为第一组样本量，$n_{2}$为第二组样本量，$k$为第一组样本量和第二组样本量的比值，$\lambda_{1}$为第一组风险率，$\lambda_{2}$为第二组风险率，
$\sigma$为标准差，$T$预期临床试验所用时间，即临床试验自启动至结束所用时间，可以月或年为单位，$T_{0}$预期受试者全部入组所用时间(与T保持一致即可)。

例 假设研究两种移植方法对恶性淋巴瘤转化成白血病时间的影响。其中一组用同种异体移植，另一组用大剂量化疗后的自身骨髓移植。观察时间持续3年（$T=3，T_{0}=1$）。假设两组风险率分别为1（$\lambda_{1}$）和2($\lambda_{2}$)。在$\alpha=0.05,\beta=0.2$时，显著性检验，需要多少样本量？

```{r}
TwoSampleSurvival.Equality(0.05,0.2,1,2,1,3,1,0.00001)
```
每组至少需要`r round(TwoSampleSurvival.Equality(0.05,0.2,1,2,1,3,1,0.00001))`例。

####非劣效/优效性检验
在假定服从指数分布的情况下,检验两组终点（生存率）的差异是否非劣于/优于设定的界值。非劣效/优效性检验样本量计算公式为：$$n_{2}=\frac{(z_{\alpha}+z_{\beta })^{2}}{(\epsilon -\delta )^{2}}
\begin{bmatrix}
\frac{\sigma ^{2}(\lambda _{1})}{k}+\sigma ^{2}(\lambda _{2})
\end{bmatrix}
$$ 其中$k=\frac{n_{1}}{n_{2}}$，$$\sigma ^{2}(\lambda _{i})=\gamma _{i}^{2}\begin{bmatrix}
1+\frac{\lambda e^{-\lambda _{i} T}(1-e^{(\lambda _{i}-\gamma) T_{0}})}{(\lambda _{i}-\gamma)(1-e^{-\lambda T_{0}})}
\end{bmatrix}^{-1}$$ $n_{1}$为第一组样本量，$n_{2}$为第二组样本量，$k$为第一组样本量和第二组样本量的比值，$\lambda_{1}$为第一组风险率，$\lambda_{2}$为第二组风险率，
$\sigma$为标准差，$T$预期临床试验所用时间，即临床试验自启动至结束所用时间，可以月或年为单位，$T_{0}$预期受试者全部入组所用时间(与T保持一致即可),$\epsilon$ 为第一组和第二组风险率之差。

例 假设研究两种移植方法对恶性淋巴瘤转化成白血病时间的影响。其中一组用同种异体移植，另一组用大剂量化疗后的自身骨髓移植。观察时间持续3年（$T=3，T_{0}=1$）。假设两组风险率分别为1（$\lambda_{1}$）和2($\lambda_{2}$)。在$\alpha=0.05,\beta=0.2$时，优效性检验，界值0.2，需要多少样本量？

```{r}
TwoSampleSurvival.NIS(0.05,0.2,1,2,1,3,1,0.00001,0.2)
```
每组至少需要`r round(TwoSampleSurvival.NIS(0.05,0.2,1,2,1,3,1,0.00001,0.2))`例。

####等效性检验
在假定服从指数分布的情况下,检验两组终点（生存率）的等效性，等效性检验检验样本量计算公式为：$$n_{2}=\frac{(z_{\alpha}+z_{\beta/2 })^{2}}{(\delta-|\epsilon| )^{2}}
\begin{bmatrix}
\frac{\sigma ^{2}(\lambda _{1})}{k}+\sigma ^{2}(\lambda _{2})
\end{bmatrix}
$$ 其中$k=\frac{n_{1}}{n_{2}}$，$$\sigma ^{2}(\lambda _{i})=\gamma _{i}^{2}\begin{bmatrix}
1+\frac{\lambda e^{-\lambda _{i} T}(1-e^{(\lambda _{i}-\gamma) T_{0}})}{(\lambda _{i}-\gamma)(1-e^{-\lambda T_{0}})}
\end{bmatrix}^{-1}$$ $n_{1}$为第一组样本量，$n_{2}$为第二组样本量，$k$为第一组样本量和第二组样本量的比值，$\lambda_{1}$为第一组风险率，$\lambda_{2}$为第二组风险率，
$\sigma$为标准差，$T$预期临床试验所用时间，即临床试验自启动至结束所用时间，可以月或年为单位，$T_{0}$预期受试者全部入组所用时间(与T保持一致即可)。

例 假设研究两种移植方法对恶性淋巴瘤转化成白血病时间的影响。其中一组用同种异体移植，另一组用大剂量化疗后的自身骨髓移植。观察时间持续3年（$T=3，T_{0}=1$）。假设两组风险率分别为1（$\lambda_{1}$）和2($\lambda_{2}$)。在$\alpha=0.05,\beta=0.2$时，等效性检验，界值0.5，需要多少样本量？

```{r}
TwoSampleSurvival.Equivalence(0.05,0.2,1,2,1,3,1,0.00001,0.5)
```
每组至少需要`r round(TwoSampleSurvival.Equivalence(0.05,0.2,1,2,1,3,1,0.00001,0.5))`例

###基于Cox比例风险模型的生存分析
不直接考察生存函数与协变量(影响因素)的关系，而是用风险函数作为因变量。$$h(t)=h_{0}(t)exp(\beta _{1}X_{1}+\beta _{2}X_{2}+...+\beta _{m}X_{m})$$ 将风险函数表达为基准风险率函数和相应协变量函数的乘积。Cox模型的参数估计不依赖于基准风险率函数的分布类型，是一种半参数的模型，但必须满足比例风险假定（PH假定），任何两个个体的风险函数及基准风险函数之比，即风险比（HR）保持一个恒定的比例，与时间t无关。模型中协变量的效应不随时间改变而改变。协变量是否满足PH假定，最简单的方法是观察按该变量分组的生存曲线，若生存曲线交叉，提示不满足PH假定。

####显著性检验
两组平行对照设计，基于Cox比例风险模型进行生存分析，检验两组终点的差异有无显著性,其样本量计算公式：$$n=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}}{log^{2}(b)p_{1}p_{2}d}$$ $p_{1},p_{2}$分别代表第一组和第二组的风险率，b为两组的风险比，d代表观察到规定事件的比率。

例 一临床试验用来比较一个新的治疗方法和传统治疗方法对延缓烧伤患者局部感染的作用。预试验中，传统方法和新方法的风险比为2(b=log(2)),80%的患者将被观察到局部感染(d=0.8),在$\alpha=0.05,\beta=0.2，p_{1}=p_{2}=0.5$时，两组1：1平行对照，显著性检验，需要多少样本量？

```{r}
Cox.Equality <- function (alpha, beta, loghr, p1, p2, d) 
{
  n = (qnorm(1-alpha/2) + qnorm(1 - beta))^2/(log(loghr)^2 * p1 * 
                                                p2 * d)
  n
}

Cox.Equality(0.05,0.2,2,0.5,0.5,0.8)
```

每组至少需要`r round(Cox.Equality(0.05,0.2,2,0.5,0.5,0.8))`例。Sample Size Calculations in Clinical Research书中对样本量公式有误（$z_{1-\alpha /2,z_{1-\beta }}$在书中错写为$z_{\alpha /2},z_{\beta }$），导致TrialSize包中Cox.Equality()函数计算错误。

####非劣效/优效性检验
两组平行对照设计，基于Cox风险比例模型进行生存分析，检验两组终点（生存率）的差异是否非劣于/优于设定的界值。$$n=\frac{(z_{1-\alpha}+z_{1-\beta })^{2}}{log^{2}(b-\delta )p_{1}p_{2}d}$$ $p_{1},p_{2}$分别代表第一组和第二组的风险率，b为两组的风险比，d代表观察到规定事件的比率，$\delta$代表具有临床意义的界值。

例 一临床试验用来比较一个新的治疗方法和传统治疗方法对延缓烧伤患者局部感染的作用。预试验中，传统方法和新方法的风险比为2(b=log(2)),80%的患者将被观察到局部感染(d=0.8),在$\alpha=0.05,\beta=0.2，p_{1}=p_{2}=0.5$时，两组1：1平行对照，优效性检验，界值为0.5，需要多少样本量？

```{r}
Cox.NIS <- function (alpha, beta, loghr, p1, p2, d, margin) 
{
  n = (qnorm(1-alpha) + qnorm(1 - beta))^2/((log(loghr) - margin)^2 * p1 * p2 * d)
  n
}

Cox.NIS(0.05,0.2,2,0.5,0.5,0.8,0.5)
```

每组至少需要`r round(Cox.NIS(0.05,0.2,2,0.5,0.5,0.8,0.5))`例。Sample Size Calculations in Clinical Research书中对样本量公式有误（$z_{1-\alpha ,z_{1-\beta }}$在书中错写为$z_{\alpha },z_{\beta }$）


####等效性检验
两组平行对照设计，基于Cox风险比例模型进行生存分析，检验两组终点（生存率）的等效性。$$n=\frac{(z_{1-\alpha}+z_{1-\beta/2 })^{2}}{log^{2}(\delta-|b| )p_{1}p_{2}d}$$ $p_{1},p_{2}$分别代表第一组和第二组的风险率，b为两组的风险比，d代表观察到规定事件的比率，$\delta$代表具有临床意义的界值。

例 一临床试验用来比较一个新的治疗方法和传统治疗方法对延缓烧伤患者局部感染的作用。预试验中，传统方法和新方法的风险比为2(b=log(2)),80%的患者将被观察到局部感染(d=0.8),在$\alpha=0.05,\beta=0.2，p_{1}=p_{2}=0.5$时，两组1：1平行对照，等效性检验，需要多少样本量？

```{r}
Cox.Equivalence <- function (alpha, beta, loghr, p1, p2, d, margin) 
{
  n = (qnorm(1-alpha) + qnorm(1 - beta/2))^2/
    ((margin - abs(log(loghr)))^2 * p1 * p2 * d)
  n
}

Cox.Equivalence(0.05,0.2,2,0.5,0.5,0.8,0.5)
```
每组至少需要`r round(Cox.Equivalence(0.05,0.2,2,0.5,0.5,0.8,0.5))`例。Sample Size Calculations in Clinical Research书中对样本量公式有误（$z_{1-\alpha ,z_{1-\beta /2}}$在书中错写为$z_{\alpha },z_{\beta/2 }$）

###基于Logrank检验的生存分析
也称为时序检验，是在无效假设成立的前提下，根据两种处理不同生存时间的期初观察人数和理论死亡概率计算出的理论死亡数（期望死亡数）应该与实际死亡数相差不大；如果相差较大，则无效假设不成立，可以认为两条生存曲线间的差异有统计学意义。非劣效/优效性检验和等效性检验样本量估计困难，显著性其样本量估计公式如下$n=\frac{2d}{p_{1}+p_{2}}$,其中$d=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\sum_{i=1}^{N}w_{i}^{2}\rho_{i}\eta _{i})}{(\sum_{i=1}^{N}w_{i}\rho _{i}\gamma _{i})^{2}}$。$w_{i}$分别为1,$n_{i}$,$\sqrt{n_{i}}$时，对应Log-rank、Wilcoxon和Tarone-Ware检验。

例 一为期2年的某心血管药物的临床试验（Lakatos 1998），假设试验组年风险率为1（年事件发生率为$1-e^{-1}$）,对照组年风险率为0.5（年事件发生率为$1-e^{-0.5}$）,年失访率为3%，年不依从率为4%，对照组有5%患者选择了其他与试验组类似的治疗（drop-in）。试验组的总事件发生率83.7%，对照组总事件发生率62.7%。

```{r}
Logrank.test <- function(alpha, beta, k, year, loss, herate, hcrate, noncompliance, 
    dropin, pe, pc) {
    eeventrate <- 1 - exp(-herate)
    ceventrate <- 1 - exp(-hcrate)
    e <- matrix(c(0, 0, 1, 0))
    c <- matrix(c(0, 0, 0, 1))
    transition <- function(x, k) {
        1 - (1 - x)^(1/k)
    }
    
    T <- matrix(c(1, 0, 0, 0, 0, 1, 0, 0, transition(loss, k), transition(eeventrate, 
        k), 1 - transition(noncompliance, k) - transition(eeventrate, k) - 
        transition(loss, k), transition(noncompliance, k), transition(loss, 
        k), transition(ceventrate, k), transition(dropin, k), 1 - transition(loss, 
        k) - transition(ceventrate, k) - transition(dropin, k)), nrow = 4)
    
    
    for (i in 1:(k * year)) {
        tempe <- list(T %^% i %*% e)
        tempc <- list(T %^% i %*% c)
        if (i == 1) {
            E <- tempe
            C <- tempc
            phi <- 1
            eta <- phi/(1 + phi)^2
            theta <- herate/hcrate
            gamma <- phi * theta/(1 + phi * theta) - phi/(1 + phi)
            rho <- (E[[i]][2] + C[[i]][2])/(pe + pc)  ##ρ
        } else {
            E <- append(E, tempe)
            C <- append(C, tempc)
            phi <- append(phi, (E[[i - 1]][3] + E[[i - 1]][4])/(C[[i - 
                1]][3] + C[[i - 1]][4]))  ##φ
            eta <- append(eta, phi[i]/(1 + phi[i])^2)  ##η
            theta <- append(theta, log(1 - (E[[i]][2] - E[[i - 1]][2]))/log(1 - 
                (C[[i]][2] - C[[i - 1]][2])))  ##θ
            gamma <- append(gamma, phi[i] * theta[i]/(1 + phi[i] * theta[i]) - 
                phi[i]/(1 + phi[i]))
            rho <- append(rho, ((E[[i]][2] - E[[i - 1]][2]) + (C[[i]][2] - 
                C[[i - 1]][2]))/(pe + pc))  ##ρ
        }
    }
    t <- seq(from = 1/k, to = year, by = 1/k)
    numerator <- 0
    denominator <- 0
    for (i in 1:(k * year)) {
        numerator = numerator + rho[i] * eta[i]
        denominator = denominator + rho[i] * gamma[i]
    }
    d <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * numerator/denominator^2
    n <- 2 * d/(pe + pc)
    n
}

Logrank.test(0.05, 0.2, 10, 2, 0.03, 1, 0.5, 0.04, 0.05, 0.627, 0.837)
```
两组共需要`r round(Logrank.test(0.05,0.2,10,2,0.03,1,0.5,0.04,0.05,0.627,0.837))`例。Sample Size Calculations in Clinical Research书中对$\theta$和$\gamma$的计算有误，矩阵T也有两个数字顺序反了！

##成组序贯设计(Group Sequential Methods)
传统的随机对照临床试验设计，要求试验开始前确定样本量, 并且只有当所有的受试者均完成入组之后才能进行数据的统计分析。序贯设计是一种节省样本的设计方法，通常事先不固定样本含量，而是按照受试者进入试验的次序，做一个（或者一个阶段）试验便进行一次分析，一旦发现达到预期结果，立即停止试验。序贯试验比较适合临床研究，因为临床研究的患者都是陆续到医院，可以一次纳入研究进行分析。这种逐个纳入受试对象，纳入一个便分析一个，下一个是否试验需要看上一个结果，花费时间较长，不适用急性传染病的研究，也不适用与显效迟缓的慢性病研究。成组序贯设计允许在试验过程中对已累积数据进行期中分析,评价试验药物的有效性和安全性,若已累积数据有足够证据说明试验药物有效或无效则可提前结束试验。与传统的试验设计方法相比,成组序贯设计具有更强的灵活性;由于期中分析为提前结束试验提供了可能性,成组序贯试验往往可以节约试验样本量,缩短试验周期，节约资金,而且更符合伦理学的要求。此外,从试验管理的角度来讲,成组序贯设计对数据的期中评价也可使研究者和监察员尽早发现试验中存在的问题,有利于改善试验质量。

实际中采用较多成组序贯试验是分阶段试验，分阶段分析。要求将整个试验划分成k个连续的阶段，每个阶段内都有2n个受试者加入试验，并被随机分配到实验组和对照组，每个处理组均为n个。当第i（$i \leqslant k$）个阶段试验结束后，把1到i阶段实验结果累计进行统计分析，如果拒绝$H_{0}$,即可结束试验，否则继续下一阶段试验。如果到最后第k个阶段结束后，仍不能拒绝$H_{0}$，则可接受$H_{0}$。成组序贯试验适用于多个地区同时进行的多中心临床试验，每隔一定时间将累积的资料进行统计分析，如果效果显著可以提前结束试验，能有效节省样本量和成本，但需要在方案中事先确定期中分析的次数和时间，不可在研究过程中修改，而且在双盲试验中应分批揭盲，以免影响后期的研究。

成组序贯试验中需要多次重复的显著性检验，这种检验将增加$I$类错误的概率，使得总显著水平上升。为使得总显著水平等于期望的$\alpha$，需要将每个阶段的显著行水平进行调整，调整后的显著性水平成为名义性显著水平(norminal significance level)，用$\ {\alpha}'$ 表示。各种方法的界值在R中可通过GroupSeq包中的groupseq(mode="c")或者groupseq(mode="g")方法获得。

成组序贯设计中有两种概念的时间点划分方式, 一种是日历时间(Calendar time),另一种是信息时间(Information time)。日历时间是以试验持续时间的进度来决定何时进行期中分析; 信息时间的含义是指在某一观察时点观察到的样本量占计划总样本量的百分比, 以可观察到的信息量来决定何时进行期中分析, 例如三阶段成组序贯试验预计死亡600例, 可在观察到死亡人数300例、450例和600例, 即信息时间为0.5、0.75和1时进行统计描述。对于生存资料, 因为生存时间是生存分析的主要指标, 故应该使用信息时间来划分时间点, 具体计算是用某时观察到的死亡数与期望总死亡数的比值$t_{k}=\kappa /K$来估计。


### Pocock’s Test
该法对每一阶段均采用相同的临界值和名义显著水平，下表列出了不同阶段的统计量，如5个阶段的显著水平为0.05的成组序贯设计，每一阶段均采用临界值2.413，每一阶段名义显著水平小于`r 2*(1-pnorm(2.413))`，才能拒绝$H_{0}$

```{r}
data <- read.csv("Cp.csv",header = T)
panderOptions('digits', 4)
pander(data)
```

K期Pocock 检验的样本量计算，首先根据没有期中分析的设计计算固定样本量，然后乘以$R_{p}(K,\alpha ,\beta )$。固定样本量计算公式如下$$n_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})}{(\mu _{1}-\mu _{2})^{2}}$$,$R_{p}$可查询下表：

```{r}
data <- read.csv("Rp.csv",header = T)
panderOptions('digits', 4)
pandoc.table(data, use.hyphening = TRUE, split.cells =8,justify = 'center')
```

例 一5期的比较某药及安慰剂疗效临床成组序贯试验，根据预试验总体的标准差为2（$\sigma ^{2}=\sigma_{1} ^{2}=\sigma_{2} ^{2}=4$），$\mu_{T} - \mu_{P} = 1$,在$\alpha=0.05,\beta=0.10$时，Pocock设计，每期需要多少病例？

```{r}
Pocock.Test <- function(alpha, beta, sigma1, sigma2, mu, k) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (sigma1^2 + sigma2^2)/(mu)^2
    
    data <- read.csv("Rp.csv", header = T)
    col <- paste(paste("alpha", alpha, sep = ""), paste("beta", format(beta, 
        nsmall = 2), sep = ""), sep = "")
    rp <- as.matrix(data)[k, col]
    nmax <- rp * nfixed
    n <- nmax/k
    n
}

Pocock.Test(0.05, 0.1, 2, 2, 1, 5)
```
每期至少需要`r round(Pocock.Test(0.05,0.10,2,2,1,5))`例。

### O’Brien and Fleming 检验
该法对不同阶段采用不同的临界值，早期阶段临界值设定较高，越到后期临界值越低。该法早期阶段较为保守，除非P值特别小，否则早期通常难以拒绝$H_{0}$，但最后一个阶段P值接近总的检验水平。下表列出了每阶段最后一阶段的临界值，比如5阶段最后一阶段的临界值值为2.040,前4阶段可采用差表，其值分别为4.562,3.226,2.634和2.281，5个阶段对应的名义显著水平可用2*(1-pnorm())方法求出。

```{r}
data <- read.csv("Cb.csv",header = T)
panderOptions('digits', 4)
pandoc.table(data, use.hyphening = TRUE, split.cells =8,justify = 'center')
```

K期O’Brien and Fleming’s 检验的样本量计算，首先根据没有期中分析的设计计算固定样本量，然后乘以$R_{b}(K,\alpha ,\beta )$。固定样本量计算公式如下$$n_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})}{(\mu _{1}-\mu _{2})^{2}}$$,$R_{b}$可查询下表：

```{r}
data <- read.csv("Rb.csv",header = T)
panderOptions('digits', 4)
pandoc.table(data, use.hyphening = TRUE, split.cells =8,justify = 'center')
```

例 一5期的比较某药及安慰剂疗效临床成组序贯试验，根据预试验总体的标准差为2（$\sigma ^{2}=\sigma_{1} ^{2}=\sigma_{2} ^{2}=4$），$\mu_{T} - \mu_{P} = 1$,在$\alpha=0.05,\beta=0.10$时，O’Brien and Fleming’s设计，每期需要多少病例？

```{r}
OBF.Test <- function(alpha, beta, sigma1, sigma2, mu, k) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (sigma1^2 + sigma2^2)/(mu)^2
    
    data <- read.csv("Rb.csv", header = T)
    col <- paste(paste("alpha", alpha, sep = ""), paste("beta", format(beta, 
        nsmall = 2), sep = ""), sep = "")
    rb <- as.matrix(data)[k, col]
    nmax <- rb * nfixed
    n <- nmax/k
    n
}

OBF.Test(0.05, 0.1, 2, 2, 1, 5)
```
每期至少需要`r round(OBF.Test(0.05,0.10,2,2,1,5))`例。

### Wang and Tsiatis 检验
该法是对Pocock和O’Brien and Fleming’s法的推广，其界值形状主要取决$\rho$和$\tau$参数，当$\rho=0,\tau=0$时，就是Pocock法，当$\rho=0.5,\tau=0$时,就是O’Brien and Fleming’s法。下表列出了每阶段的临界值

```{r}
data <- read.csv("Cwt.csv",header = T)
panderOptions('digits', 4)
pandoc.table(data, use.hyphening = TRUE, split.cells =8,justify = 'center')
```

K期Wang and Tsiatis 检验的样本量计算，首先根据没有期中分析的设计计算固定样本量，然后乘以$R_{wt}(K,\alpha ,\beta,\Delta)$。固定样本量计算公式如下$$n_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})}{(\mu _{1}-\mu _{2})^{2}}$$,$R_{wt}$可查询下表：

```{r}
data <- read.csv("Rwt.csv", header = T)
panderOptions("digits", 4)
pandoc.table(data, use.hyphening = TRUE, split.cells = 8, justify = "center")
```

例 一5期的比较某药及安慰剂疗效临床成组序贯试验，根据预试验总体的标准差为2（$\sigma ^{2}=\sigma_{1} ^{2}=\sigma_{2} ^{2}=4$），$\mu_{T} - \mu_{P} = 1$,在$\alpha=0.05,\beta=0.10$时，Wang and Tsiatis 设计，每期需要多少病例？

```{r}
WT.Test <- function(alpha, beta, sigma1, sigma2, mu, k, delta) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (sigma1^2 + sigma2^2)/(mu)^2
    
    data <- read.csv("Rwt.csv", header = T)
    col <- paste(paste("delta", format(delta, nsmall = 2), sep = ""), paste("beta", 
        format(beta, nsmall = 2), sep = ""), sep = "")
    rwt <- as.matrix(data)[k, col]
    nmax <- rwt * nfixed
    n <- nmax/k
    n
}

WT.Test(0.05, 0.1, 2, 2, 1, 5, 0.05)
```
每期至少需要`r round(WT.Test(0.05,0.10,2,2,1,5,0.05))`例。

### Inner Wedge 检验
上述三种成组序贯方法均可以在拒绝$H_{0}$接受$H_{1}$时停止试验，也就是说试验药如果有效时即可停止试验。Inner Wedge方法是一种接受$H_{0}$时，停止试验，即试验药无效时即可停止试验的一种方法。

K期Inner Wedge 检验的样本量计算，首先根据没有期中分析的设计计算固定样本量，然后乘以$R_{w}(K,\alpha ,\beta,\Delta )$。固定样本量计算公式如下$$n_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})}{(\mu _{1}-\mu _{2})^{2}}$$,$R_{w}$可查询下表：

```{r}
data <- read.csv("Rw.csv",header = T)
panderOptions('digits', 4)
pander(data)
```

例 一5期的比较某药及安慰剂疗效临床成组序贯试验，根据预试验总体的标准差为1（$\sigma ^{2}=\sigma_{1} ^{2}=\sigma_{2} ^{2}=1$），$\mu_{T} - \mu_{P} = 0.2$,$\Delta =0.25$,在$\alpha=0.05,\beta=0.20$时，Inner Wedge设计，每期需要多少病例？

```{r}
InnerWedge.Test <- function(alphap,betap,sigma1,sigma2,mu,kp,deltap){
  nfixed <- (qnorm(1-alphap/2) + qnorm(1 - betap))^2*(sigma1^2+sigma2^2)/(mu)^2
  data <- read.csv("Rw.csv",header = T)
  data%>>%
    subset(beta==betap)%>>%
    subset(alpha==alphap)%>>%
    subset(K==kp)%>>%
    subset(delta==deltap)%>>%
    subset(select=c(Rw))*nfixed/kp
}

InnerWedge.Test (0.05,0.20,1,1,0.2,5,0.25)
```

每期至少需要`r round(InnerWedge.Test (0.05,0.20,1,1,0.2,5,0.25))`例。

###率比较的样本量估计
基于率比较的样本量计算与均值比较的样本量计算基本过程类似，固定样本量计算公式略有不同，公式如下$$n_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(p _{1}(1-p _{1})+p _{2}(1-p _{2}))}{(p _{1}-p _{2})^{2}}$$。

例 一5期的比较某药及安慰剂疗效临床成组序贯试验，根据预试验总体的试验药的有效率为60%，安慰剂的有效率为50%,在$\alpha=0.05,\beta=0.20$时，分别进行Pocock、O’Brien and Fleming’s和Wang and Tsitis($\Delta=0.1$)设计，每期各需要多少病例？

```{r}
Pocock.Test.Binary <- function(alpha, beta, p1, p2, k) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (p1 * (1 - p1) + 
        p2 * (1 - p2))/(p1 - p2)^2
    data <- read.csv("Rp.csv", header = T)
    col <- paste(paste("alpha", alpha, sep = ""), paste("beta", format(beta, 
        nsmall = 2), sep = ""), sep = "")
    rp <- as.matrix(data)[k, col]
    nmax <- rp * nfixed
    n <- nmax/k
    n
}

Pocock.Test.Binary(0.05, 0.2, 0.6, 0.5, 5)
```

```{r}
OBF.Test.Binary <- function(alpha, beta, p1, p2, k) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (p1 * (1 - p1) + 
        p2 * (1 - p2))/(p1 - p2)^2
    data <- read.csv("Rb.csv", header = T)
    col <- paste(paste("alpha", alpha, sep = ""), paste("beta", format(beta, 
        nsmall = 2), sep = ""), sep = "")
    rb <- as.matrix(data)[k, col]
    nmax <- rb * nfixed
    n <- nmax/k
    n
}

OBF.Test.Binary(0.05, 0.2, 0.6, 0.5, 5)
```

```{r}
WT.Test.Binary <- function(alpha, beta, p1, p2, k, delta) {
    nfixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (p1 * (1 - p1) + 
        p2 * (1 - p2))/(p1 - p2)^2
    data <- read.csv("Rwt.csv", header = T)
    col <- paste(paste("delta", format(delta, nsmall = 2), sep = ""), paste("beta", 
        format(beta, nsmall = 2), sep = ""), sep = "")
    rwt <- as.matrix(data)[k, col]
    nmax <- rwt * nfixed
    n <- nmax/k
    n
}

WT.Test.Binary(0.05, 0.2, 0.6, 0.5, 5, 0.1)
```

Pocock、O’Brien and Fleming’s和Wang and Tsitis($\Delta=0.1$)设计，每期各需要各需要`r round(Pocock.Test.Binary(0.05, 0.2, 0.6, 0.5, 5))`例、`r round(OBF.Test.Binary(0.05, 0.2, 0.6, 0.5, 5))`例和`r round(WT.Test.Binary(0.05, 0.2, 0.6, 0.5, 5, 0.1))`例

###时间事件数据（生存分析）
对于生存数据资料,由于其资料的特殊性,如数据参数分布状态不明、截尾数据的存在、脱落病例处理的特殊性及受试者入组情况的影响等,该类型试验的样本量估计一直是临床试验中样本量估计问题中的难点。以时间事件为试验结果的成组序贯设计，为简单起见，仅Cox比例风险模型为例。固定样本量计算公式,$$I_{fixed}=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}}{\theta ^{2}}$$,最大样本计算公式$$I_{max}=I_{fixed}\times R_{B}(K,\alpha ,\beta )$$,样本量为$$n_{d}=\frac{I_{max}}{I_{k}}$$。

例 一5期的比较某抗癌药及安慰剂疗效的成组序贯试验，以时间事件为试验结果，根据预试验$\theta=0.405$,在$\alpha=0.05,\beta=0.20$时，每期各需要多少病例？

```{r}
Cox.Test <- function(alpha, beta, theta, k) {
    Ifixed <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2/theta^2
    data <- read.csv("Rb.csv", header = T)
    col <- paste(paste("alpha", alpha, sep = ""), paste("beta", format(beta, 
        nsmall = 2), sep = ""), sep = "")
    rb <- as.matrix(data)[k, col]
    Imax <- Ifixed * rb
    nd <- Imax/0.25  #theta接近零，对每一期，riA,k ≈ riB,k，Ik近似于0.25dk
    nd
}

Cox.Test(0.05, 0.2, 0.405, 5)
```

每期各需要`r round(Cox.Test(0.05, 0.2, 0.405, 5))`例，实际应用中还需根据删失、风险等因素进行调整。

###$\alpha$消耗函数
常用的成组序贯试验有以下几种: Pocock法(常数界值)、O'Brien-Fleming法(非常数界值)和成组序贯可信区间法等 。 虽然这几种方法都能根据期中分析次数制定检验临界值,达到控制I类错误的目的,但是都严格依赖期中分析计划,需要在完成固定数目的患者随访之后进行,因此缺乏灵活性,在实际应用中有一定的局限性。$\alpha$消耗函数法则弥补了这一局限，$\alpha$消耗函数法根据信息比例(information fraction)分配I类错误 ,从而在控制I类错误的前提下 ,不再依赖固定的期中分析频率和间隔 ,更具有灵活性 。信息比例指的是期中分析时收集到的试验信息量占试验结束时预期全部试验信息量的比例。最常用的是Lan和DeMets在1983年提出的α消耗函数法;1990年Hwang等提出了$\gamma$族$\alpha$消耗函数法。采用Pocock (1977) 或O’Brian-Fleming (1979) 等的方法，应计划好期间分析的时间及次数，并据此定义提早停止试验的边界点 (boundary)。若停止试验原则采用Lan-DeMets (1994) 之$\alpha$消耗函数 ，则可以不预先设定时间及次数。

$\alpha$消耗函数是随信息时间递增函数，当信息时间为0时，$\alpha$消耗函数的值为0,在信息时间为1时，$\alpha$消耗函数的值为$\alpha$。通常以$\alpha(s)$代表在s信息时间时，$\alpha$消耗函数的取值，该值表示在s信息时间时希望消耗的I类错误的概率。对一给定的$\alpha$消耗函数和一系列的标准统计量$Z_{k}，k=1,...,K$，相应的边界值$c_{k}，k=1,...,K$，有下面关系$$P(|Z_{1}|<c_{1},...,|Z_{k-1}|<c_{k-1},|Z_{k}|\geq c_{k})=\alpha (\frac{k}{K})-\alpha(\frac{k-1}{K})$$

常见的$\alpha$消耗函数如下

函数名             函数
---                ---
O’Brien-Fleming    $\alpha _{1}(s)=2\begin{Bmatrix}1-\Phi (z_{\alpha /2}\sqrt{s})\end{Bmatrix}$
Pocock             $\alpha _{2}(s)=\alpha log[1+(e-1)s]$
Lan-DeMets-Kim     $\alpha _{3}(s)=\alpha s^{\rho },\rho>0$
Hwang-Shih         $\alpha _{4}(s)=\alpha \begin{bmatrix}(1-e^{\zeta s})/(1-e^{-\zeta})\end{bmatrix},\zeta\neq 0$

R语言ldbounds包中bounds()函数可以计算$\alpha$消耗函数的界值。5阶段O'Brien Fleming方法的消耗函数的界值可如下获得

```{r}
options(digits = 4)
time <- seq(0.2, 1, length = 5)
obf.bd <- bounds(time, iuse = c(1, 1), alpha = c(0.025, 0.025))
summary(obf.bd)
plot(obf.bd)
```

time为信息时间，iuse为1表示O'Brien Fleming方法，为2表示Pocock方法，为3表示power family方法，为4表示Hwang-Shih-DeCani family方法。asf为指定的消耗函数，在iuse为5时alpha为I类错误概率，phi为选择power family方法和Hwang-Shih-DeCani family方法时，选择的$\rho$值和$\zeta$值。ztrun为选择的截取向量，默认为 c(-8,8)。

类似的5阶段Opower family方法的消耗函数的界值可如下获得
```{r}
options(digits = 4)
power.bd <- bounds(time, iuse = c(3,3), phi = c(2,2),alpha = c(0.025, 0.025))
summary(power.bd)
plot(power.bd)
```

结果中第一列Time为信息时间，第二列为Lower低界值，第三列Upper为高界值，Exit pr为名义的$\alpha$值可据此判断是否结束试验，Diff. pr.为本阶段与上一阶段$\alpha$值的差异。

###样本量再估计
在某些成组序贯试验的期中分析时，需要根据累计的数据对样本量进行再估计，应当注意盲目的进行再估计有可能造成偏移。Shih等提出完成50%样本两后，以率为观察结果的随机双盲样本量再估计方法,估计公式如下:$$n=\frac{(z_{1-\alpha /2}+z_{1-\beta })^{2}(\hat{p_{1}}(1-\hat{p_{1}})+\hat{p_{2}}(1-\hat{p_{2}}))}{\Delta^{2}}$$,$\Delta=|\hat{p_{1}}-\hat{p_{2}}|$,$\hat{p_{1}}=\frac{\pi\hat{\theta _{1}}-(1-\pi)\hat{\theta _{2}}}{2\pi-1}$,$\hat{p_{2}}=\frac{\pi\hat{\theta _{2}}-(1-\pi)\hat{\theta _{1}}}{2\pi-1}$。

例 两中心的临床实验，A中心以60%的概率将病人分配到试验组，B中心以40%的概率将病人分配到试验组，整个试验以40%的概率将病人分配到试验组，已完成的50%样本量的期中分析，A中心的有效率为60%，B中心的有效率为50%，请在$\alpha=0.05,\beta=0.10$时重新估计下一阶段所需样本量。

根据$0.4p_{1} + 0.6p_{2} = 0.6$和$0.6p_{1} + 0.4p_{2} = 0.5$,可$p_{1}=0.3,p_{2}=0.8$
```{r}
GroupSeqReEstimation <- function(alpha, beta, p1, p2) {
    n <- (qnorm(1 - alpha/2) + qnorm(1 - beta))^2 * (p1 * (1 - p1) + p2 * 
        (1 - p2))/(p1 - p2)^2
    n
}

GroupSeqReEstimation(0.05, 0.1, 0.3, 0.8)
```
重新估计样本量后，共计所需`r 2*round(GroupSeqReEstimation(0.05, 0.1, 0.3, 0.8))`例。

## 变异性比较的样本量估计(Comparing Variabilities)
变异性通常分为个体内变异和个体间变异两类，个体内变异指在相同的试验条件下，同一个体多次重复测量值之间存在的差异。个体间变异指不同个体间由于异质性而存在的差异。

###重复平行对照设计
####显著性检验
显著性检验的样本量需从下面公式中，
$$\frac{\sigma ^{2}_{WT}}{\sigma ^{2}_{WR}}=\frac{F_{1-\beta ,n(m-1),n(m-1)}}{F_{\alpha /2 ,n(m-1),n(m-1)}}$$解出n，$\sigma ^{2}_{WT}$和$\sigma ^{2}_{WR}$分别表示T和R的个体内标准差，T(test drug)和R(reference drug）分别表示测试药物和参比药物，T和R组的样本量相同均为n。

例 设计一个2组每个个体重复3次的平行对照实验，根据预试验，T组的个体内标准差为0.3,R组个体内标准差为0.45,在$\alpha=0.05,\beta=0.20$时，1：1显著性设计，需要多少样本量？

```{r}
ISV.Equality <- function(alpha, beta, sigma1, sigma2, m) {
    ratio = sigma1/sigma2
    n = 0
    for (i in 1:1000) {
        ratio.f = qf(p = (1 - beta), i * (m - 1), i * (m - 1), lower.tail = FALSE)/qf(alpha/2, 
            i * (m - 1), i * (m - 1), lower.tail = FALSE)
        if (round(ratio, digits = 2) == round(ratio.f, digits = 2)) {
            n = i
        }
    }
    n
}

ISV.Equality(0.05, 0.2, 0.3, 0.45, 3)
```
需要`r round(ISV.Equality(0.05,0.2,0.3,0.45,3))`例。

####非劣性/优效性
非劣性/优效性检验的样本量需从下面公式中，
$$\frac{\sigma ^{2}_{WT}}{\delta ^{2}\sigma ^{2}_{WR}}=\frac{F_{1-\beta ,n(m-1),n(m-1)}}{F_{\alpha ,n(m-1),n(m-1)}}$$解出n，$\sigma ^{2}_{WT}$和$\sigma ^{2}_{WR}$分别表示T和R的个体内标准差，T(test drug)和R(reference drug）分别表示测试药物和参比药物，T和R组的样本量相同均为n，$、delta$为界值。

例 设计一个2组每个个体重复3次的平行对照实验，根据预试验，T组的个体内标准差为0.3,R组个体内标准差为0.45,在$\alpha=0.05,\beta=0.20$时，1：1非劣性设计，在界值为-1.1时需要多少样本量？

```{r}
ISV.NIS <- function(alpha, beta, sigma1, sigma2, m, margin) {
    ratio = sigma1/(sigma2 * margin^2)
    n = 0
    for (i in 1:1000) {
        ratio.f = qf(p = (1 - beta), i * (m - 1), i * (m - 1), lower.tail = FALSE)/qf(alpha, 
            i * (m - 1), i * (m - 1), lower.tail = FALSE)
        if (round(ratio, digits = 2) == round(ratio.f, digits = 2)) {
            n = i
        }
    }
    n
}

ISV.NIS(0.05, 0.2, 0.3, 0.45, 3, -1.1)
```
需要`r round(ISV.NIS(0.05,0.2,0.3,0.45,3,1.1))`例。

####等效性
等效性检验的样本量需从下面公式中，
$$\frac{\delta ^{2}\sigma ^{2}_{WT}}{\sigma ^{2}_{WR}}=\frac{F_{\beta/2 ,n(m-1),n(m-1)}}{F_{1-\alpha ,n(m-1),n(m-1)}}$$解出n，$\sigma ^{2}_{WT}$和$\sigma ^{2}_{WR}$分别表示T和R的个体内标准差，T(test drug)和R(reference drug）分别表示测试药物和参比药物，T和R组的样本量相同均为n，$、delta$为界值。

例 设计一个2组每个个体重复3次的平行对照实验，根据预试验，T组的个体内标准差为0.3,R组个体内标准差为0.45,在$\alpha=0.05,\beta=0.20$时，1：1等效性设计，在界值为2时需要多少样本量？

```{r}
ISV.Equivalence <- function(alpha, beta, sigma1, sigma2, m, margin) {
    ratio = margin^2 * sigma1/sigma2
    n = 0
    for (i in 1:1000) {
        ratio.f = qf(beta/2, i * (m - 1), i * (m - 1), lower.tail = FALSE)/qf(1 - 
            alpha, i * (m - 1), i * (m - 1), lower.tail = FALSE)
        if (round(ratio, digits = 1) == round(ratio.f, digits = 1)) {
            n = i
        }
    }
    n
}

ISV.Equivalence(0.05, 0.2, 0.3, 0.45, 3, 2)
```
需要`r round(ISV.Equivalence(0.05,0.2,0.3,0.45,3,2))`例。

###简单随机效应模型
根据Quan和Shih提出的随机效应模型，可以到处方差的估计公式 $\sigma _{i}^{*2}=\frac{1}{2m}\hat{CV_{i}^{2}}+\hat{CV_{i}^{4}}$

####显著性检验
显著性检验样本量计算公式如下$$n=\frac{(\sigma _{T}^{*2}+\sigma _{R}^{*2})(z_{1-\alpha }+z_{1-\beta })^{2}}{(CV_{T}-CV_{R})^{2}}$$,$CV_{T},CV_{R}$分别为T和R组的变异度，$\sigma _{T}^{*2},\sigma _{R}^{*2}$分别为T和R组方差。

例 设计一个2组每个个体重复2次的平行对照实验，根据预试验，治疗组的变异度为50%,对照组变异度70%,在$\alpha=0.05,\beta=0.20$时，1：1显著性设计，需要多少样本量？

```{r}
ISCV.Equality <- function(alpha, beta, CVt, CVr, m) {
    sigma1 = 1/(2 * m) * CVt^2 + CVt^4
    sigma2 = 1/(2 * m) * CVr^2 + CVr^4
    n = (sigma1 + sigma2) * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(CVt - 
        CVr)^2
    n
}

ISCV.Equality(0.05, 0.2, 0.7, 0.5, 2)
```
需要`r round(ISCV.Equality(0.05,0.2,0.7,0.5,2))`例。

####非劣性/优效性检验
非劣性/优效性检验样本量计算公式如下$$n=\frac{(\sigma _{T}^{*2}+\sigma _{R}^{*2})(z_{1-\alpha }+z_{1-\beta })^{2}}{(CV_{T}-CV_{R}-\delta)^{2}}$$,$CV_{T},CV_{R}$分别为T和R组的变异度，$\sigma _{T}^{*2},\sigma _{R}^{*2}$分别为T和R组方差，$\delta$为界值。

例 设计一个2组每个个体重复2次的平行对照实验，根据预试验，治疗组的变异度为50%,对照组变异度70%,在$\alpha=0.05,\beta=0.20$时，1：1非劣性设计，界值为0.1，需要多少样本量？

```{r}
ISCV.NIS <- function(alpha, beta, CVt, CVr, m, margin) {
    sigma1 = 1/(2 * m) * CVt^2 + CVt^4
    sigma2 = 1/(2 * m) * CVr^2 + CVr^4
    n = (sigma1 + sigma2) * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(CVt - 
        CVr - margin)^2
    n
}

ISCV.NIS(0.05, 0.2, 0.7, 0.5, 2, -0.1)
```
需要`r round(ISCV.NIS(0.05,0.2,0.7,0.5,2,-0.1))`例。

####等效性检验
非劣性/优效性检验样本量计算公式如下$$n=\frac{(\sigma _{T}^{*2}+\sigma _{R}^{*2})(z_{1-\alpha }+z_{1-\beta })^{2}}{(\delta-|CV_{T}-CV_{R}|)^{2} }$$,$CV_{T},CV_{R}$分别为T和R组的变异度，$\sigma _{T}^{*2},\sigma _{R}^{*2}$分别为T和R组方差，$\delta$为界值。

例 设计一个2组每个个体重复2次的平行对照实验，根据预试验，治疗组的变异度为50%,对照组变异度70%,在$\alpha=0.05,\beta=0.20$时，1：1等效性设计，界值为0.1，需要多少样本量？

```{r}
ISCV.Equivalence <- function(alpha, beta, CVt, CVr, m, margin) {
    sigma1 = 1/(2 * m) * CVt^2 + CVt^4
    sigma2 = 1/(2 * m) * CVr^2 + CVr^4
    n = (sigma1 + sigma2) * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(margin - 
        abs(CVt - CVr))^2
    n
}

ISCV.Equivalence(0.05, 0.2, 0.7, 0.5, 2, 0.1)
```
需要`r round(ISCV.Equivalence(0.05,0.2,0.7,0.5,2,0.1))`例。

###个体间变异的比较
除了比较个体内变异和变异度外，实际工作中也需要比较个体间的变异。临床试验中，对个体进行重复测量通常难以实施，但测量不同处理的个体间变异和总变异却有实际应用价值。平行对照设计中估计变异的方法为修正大样本方法(modified large sample, MLS) ，交叉设计中，由于不满足独立性的要求，需要对MLS方法进行扩展。

#### 平行可重复设计
#####显著性检验
显著性检验样本量计算公式如下，
$$n= \frac{\sigma ^{*2}(z_{1-\alpha /2}+z_{1-\beta})^{2}}{(\sigma _{BT}^{2}-\sigma _{BR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}+\frac{\sigma_{WT}^{4}}{m^{2}(m-1)}+\frac{\sigma _{WR}^{4}}{m^{2}(m-1)}\end{bmatrix}$

例 设计一个2组每个个体重复3次的平行对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20$时，1：1显著性设计，需要多少样本量？

```{r}
InterSV.Equality <- function(alpha, beta, vbt, vwt, vbr, vwr, m) {
    sigma = 2 * (vbt^2 + vwt^2/m)^2 + (vbr^2 + vwr^2/m)^2 + vwt^4/(m^2 * 
        (m - 1)) + vwr^4/(m^2 * (m - 1))
    n = sigma * (qnorm(1 - alpha/2) + qnorm(1 - beta))^2/(vbt^2 - vbr^2)^2
    n
}

InterSV.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3)
```

需要`r round(InterSV.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3))`例。

####非劣性/优效性检验
样本量计算公式如下
非劣性/优效性检验$$n= \frac{\sigma ^{*2}(z_{1-\alpha}+z_{1-\beta})^{2}}{(\sigma _{BT}^{2}-\delta ^{2}\sigma _{BR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+\delta ^{4}(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}+\frac{\sigma_{WT}^{4}}{m^{2}(m-1)}+\frac{\delta ^{4}\sigma _{WR}^{4}}{m^{2}(m-1)}\end{bmatrix}$

例 设计一个2组每个个体重复3次的平行对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20$时，1：1非劣性设计，需要多少样本量？


```{r}
InterSV.NIS <- function(alpha, beta, vbt, vwt, vbr, vwr, m, margin) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + margin^4 * (vbr^2 + vwr^2/m)^2 + 
        vwt^4/(m^2 * (m - 1)) + margin^4 * vwr^4/(m^2 * (m - 1)))
    n = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 - margin^2 * 
        vbr^2)^2
    n
}

InterSV.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3, -1.1)
```

需要`r round(InterSV.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3, -1.1))`例。

#### 交叉可重复设计
#####显著性检验
显著性检验样本量计算公式如下，
$$n_{s}=\frac{\sigma^{*2}(z_{1-\alpha /2}+z_{1-\beta })^{2}}{(\sigma_{BT}^{2}-\sigma_{BR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}-2\rho ^{2}\sigma_{BT} ^{2}\sigma_{BR}^{2}+\frac{\sigma_{WT}^{4}}{m^{2}(m-1)}+\frac{\sigma _{WR}^{4}}{m^{2}(m-1)}\end{bmatrix}$

例 设计一个2组每个个体重复2次的交叉对照实验(ABAB,BABA)，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20,\rho= 0.75$时，1：1显著性设计，需要多少样本量？

```{r}
InterSV.Cross.Equality <- function(alpha, beta, vbt, vwt, vbr, vwr, m, 
    rho) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + (vbr^2 + vwr^2/m)^2 - 2 * rho^2 * 
        vbt^2 * vbr^2 + vwt^4/(m^2 * (m - 1)) + vwr^4/(m^2 * (m - 1)))
    ns = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 - vbr^2)^2
    ns
}

InterSV.Cross.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, 0.75)
```
总计需要`r round(InterSV.Cross.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2,0.75))`例，由于$n_{s}=n_{1}+n_{2}-2$，每组大约需要52例。

####非劣性/优效性检验
样本量计算公式如下
非劣性/优效性检验$$n_{s}= \frac{\sigma ^{*2}(z_{1-\alpha}+z_{1-\beta})^{2}}{(\sigma _{BT}^{2}-\delta ^{2}\sigma _{BR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+\delta ^{4}(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}-2\delta ^{2}\rho ^{2}\sigma_{BT} ^{2}\sigma_{BR}^{2}+\frac{\sigma_{WT}^{4}}{m^{2}(m-1)}+\frac{\delta ^{4}\sigma _{WR}^{4}}{m^{2}(m-1)}\end{bmatrix}$

例 设计一个2组每个个体重复2次的交叉对照实验(ABAB,BABA)，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20,\rho= 0.75$时，1：1非劣性设计，需要多少样本量？

```{r}
InterSV.Cross.NIS <- function(alpha, beta, vbt, vwt, vbr, vwr, m, margin, 
    rho) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + margin^4 * (vbr^2 + vwr^2/m)^2 - 
        2 * margin^2 * rho^2 * vbt^2 * vbr^2 + vwt^4/(m^2 * (m - 1)) + 
        margin^4 * vwr^4/(m^2 * (m - 1)))
    ns = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 - margin^2 * 
        vbr^2)^2
    ns
}

InterSV.Cross.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, -1.1, 0.75)
```

总计需要`r round(InterSV.Cross.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2,-1.1,0.75))`例，由于$n_{s}=n_{1}+n_{2}-2$，每组大约需要29例。

###总体变异的比较
总体变异的估计可从标准的2×2交叉/平行设计或者重复的2×2m的交叉/平行设计中获得。

####无重复的平行对照试验

#####显著性检验
显著性检验样本量计算公式需要解下公式$$\frac{\sigma _{TT}^{2}}{\sigma _{TR}^{2}}=\frac{F_{1-\beta,n-1,n-1}}{F_{\alpha /2,n-1,n-1}}$$，其中$\sigma _{TT}$和$\sigma _{TR}$为T组和R组的方差。

例 设计一无重复的平行对照的临床试验，根据预试验，T组和R组的方差分别为0.55和0.75,在$\alpha=0.05,\beta=0.20$时，显著性设计需要多少样本量？

```{r}
Variabilities.Parallel.Equality <- function(alpha, beta, vtt, vtr) {
    ratio = vtt^2/vtr^2
    n = 0
    for (i in 2:1000) {
        ratio.f = qf(p = (1 - beta), i - 1, i - 1, lower.tail = FALSE)/qf(alpha/2, 
            i - 1, i - 1, , lower.tail = FALSE)
        if (round(ratio, digits = 2) == round(ratio.f, digits = 2)) {
            n = i
        }
    }
    n
}

Variabilities.Parallel.Equality(0.05, 0.2, 0.55, 0.75)
```
每组需要`r round(Variabilities.Parallel.Equality(0.05, 0.2, 0.55, 0.75))`例。

#####非劣性/优效性检验
非劣性/优效性检验样本量计算公式需要解下公式$$\frac{\sigma _{TT}^{2}}{\delta ^{2}\sigma _{TR}^{2}}=\frac{F_{1-\beta,n-1,n-1}}{F_{\alpha ,n-1,n-1}}$$，其中$\sigma _{TT}$和$\sigma _{TR}$为T组和R组的方差，$delta$为界值。                                                                                                                                                                                                             

例 设计一无重复的平行对照的临床试验，根据预试验，T组和R组的方差分别为0.55和0.75,在$\alpha=0.05,\beta=0.20$时，非劣性设计，在界值为1.1时，需要多少样本量？
```{r}
Variabilities.Parallel.NIS <- function(alpha, beta, vtt, vtr, margin) {
    ratio = vtt^2/margin^2 * vtr^2
    n = 0
    for (i in 2:1000) {
        ratio.f = qf(p = (1 - beta), i - 1, i - 1, lower.tail = FALSE)/qf(alpha, 
            i - 1, i - 1, , lower.tail = FALSE)
        if (round(ratio, digits = 2) == round(ratio.f, digits = 2)) {
            n = i
        }
    }
    n
}

Variabilities.Parallel.NIS(0.05, 0.2, 0.55, 0.75, -1.1)
```
每组需要`r round(Variabilities.Parallel.NIS(0.05, 0.2, 0.55, 0.75, -1.1))`例。

#####等效性检验
等效性检验样本量计算公式需要解下公式$$\frac{\delta ^{2}\sigma _{TT}^{2}}{\sigma _{TR}^{2}}=\frac{F_{\beta/2,n-1,n-1}}{F_{1-\alpha ,n-1,n-1}}$$，其中$\sigma _{TT}$和$\sigma _{TR}$为T组和R组的方差，$delta$为界值。                                                                                                                                                                                                             

例 设计一无重复的平行对照的临床试验，根据预试验，T组和R组的方差分别为0.55和0.75,在$\alpha=0.05,\beta=0.20$时，等效性设计，在界值为1.8时，需要多少样本量？
```{r}
Variabilities.Parallel.Equivalence <- function(alpha, beta, vtt, vtr, margin) {
    ratio = margin^2 * vtt^2/vtr^2
    n = 0
    for (i in 2:1000) {
        ratio.f = qf(beta/2, i - 1, i - 1, lower.tail = FALSE)/qf(p = (1 - 
            alpha), i - 1, i - 1, , lower.tail = FALSE)
        if (round(ratio, digits = 1) == round(ratio.f, digits = 1)) {
            n = i
        }
    }
    n
}

Variabilities.Parallel.Equivalence(0.05, 0.2, 0.55, 0.75, 1.8)
```
每组需要`r round(Variabilities.Parallel.Equivalence(0.05, 0.2, 0.55, 0.75,1.8))`例。

####重复的平行对照试验

#####显著性检验
显著性检验样本量计算公式如下，
$$n= \frac{\sigma ^{*2}(z_{1-\alpha /2}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}+\frac{(m-1)\sigma_{WT}^{4}}{m^{2}}+\frac{(m-1)\sigma _{WR}^{4}}{m^{2}}\end{bmatrix}$

例 设计一个3组每个个体重复3次的平行对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20$时，1：1显著性设计，需要多少样本量？

```{r}
Variabilities.Parallel.Rep.Equality <- function(alpha, beta, vbt, vwt, 
    vbr, vwr, m) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + (vbr^2 + vwr^2/m)^2 + (m - 1) * 
        vwt^4/m^2 + (m - 1) * vwr^4/m^2)
    n = sigma * (qnorm(1 - alpha/2) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        (vbr^2 + vwr^2))^2
    n
}

Variabilities.Parallel.Rep.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3)
```

需要`r round(Variabilities.Parallel.Rep.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3))`例。

####非劣性/优效性检验
样本量计算公式如下
非劣性/优效性检验$$n= \frac{\sigma ^{*2}(z_{1-\alpha}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\delta ^{2}\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+\delta ^{4}(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}+\frac{(m-1)\sigma_{WT}^{4}}{m^{2}}+\delta ^{4}\frac{(m-1)\sigma _{WR}^{4}}{m^{2}}\end{bmatrix}$

例 设计一个3组每个个体重复3次的平行对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20$时，1：1非劣性设计，需要多少样本量？


```{r}
Variabilities.Parallel.Rep.NIS <- function(alpha, beta, vbt, vwt, vbr, 
    vwr, m, margin) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + margin^4 * (vbr^2 + vwr^2/m)^2 + 
        (m - 1) * vwt^4/(m^2) + margin^4 * (m - 1) * vwr^4/(m^2))
    n = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        margin^2 * (vbr^2 + vwr^2))^2
    n
}

Variabilities.Parallel.Rep.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3, -1.1)
```

需要`r round(Variabilities.Parallel.Rep.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 3, -1.1))`例。

####标准2×2交叉设计

#####显著性检验
显著性检验样本量计算公式如下，
$$n_{s}= \frac{\sigma ^{*2}(z_{1-\alpha /2}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2(\sigma _{TT}^{4}+\sigma _{TR}^{4}-2\rho^{2}\sigma _{BT}^{2}\sigma_{BR} ^{2})$

例 设计一个2×2的标准交叉对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20，\rho=1$时,1：1显著性检验设计，需要多少样本量？

```{r}
Variabilities.Cross.Equality <- function(alpha, beta, vbt, vwt, vbr, vwr, 
    rho) {
    sigma = 2 * ((vbt^2 + vwt^2)^2 + (vbr^2 + vwr^2)^2 - 2 * rho^2 * vbt^2 * 
        vbr^2)
    ns = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        (vbr^2 + vwr^2))^2
    ns
}

Variabilities.Cross.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 1)
```
由于$n_{s}=n_{1}+n_{2}-2$,每组需`r round((Variabilities.Cross.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 1)+2)/2)`例。

####非劣性/优效性检验
样本量计算公式如下
非劣性/优效性检验$$n_{s}= \frac{\sigma ^{*2}(z_{1-\alpha}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\delta ^{2}\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2(\sigma _{TT}^{4}+\delta ^{4}\sigma _{TR}^{4}-2\delta ^{2}\rho^{2}\sigma _{BT}^{2}\sigma_{BR} ^{2})$

例 设计一个2×2的标准交叉对照实验，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20，\rho=1$时,1：1非劣性检验设计，在界值为1.1的情况下需要多少样本量？

```{r}
Variabilities.Cross.NIS <- function(alpha, beta, vbt, vwt, vbr, vwr, margin, 
    rho) {
    sigma = 2 * ((vbt^2 + vwt^2)^2 + margin^4 * (vbr^2 + vwr^2)^2 - 2 * 
        margin^2 * rho^2 * vbt^2 * vbr^2)
    ns = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        margin^2 * (vbr^2 + vwr^2))^2
    ns
}

Variabilities.Cross.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, -1.1, 1)
```

由于$n_{s}=n_{1}+n_{2}-2$,每组需`r round((Variabilities.Cross.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, -1.1, 1)+2)/2)`例。

####重复2×2m交叉设计
#####显著性检验
$$n= \frac{\sigma ^{*2}(z_{1-\alpha /2}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}-2\rho^2\sigma _{BT}^{2}\sigma _{BR}^{2}+\frac{(m-1)\sigma_{WT}^{4}}{m^{2}}+\frac{(m-1)\sigma _{WR}^{4}}{m^{2}}\end{bmatrix}$

例 设计一个2组每个个体重复2次的交叉对照实验(ABAB,BABA)，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20,\rho= 0.75$时，1：1显著性设计，需要多少样本量？

```{r}
Variabilities.Cross.Rep.Equality <- function(alpha, beta, vbt, vwt, vbr, 
    vwr, m, rho) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + (vbr^2 + vwr^2/m)^2 - 2 * rho^2 * 
        vbt^2 * vbr^2 + (m - 1) * vwt^4/m^2 + (m - 1) * vwr^4/m^2)
    ns = sigma * (qnorm(1 - alpha/2) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        (vbr^2 + vwr^2))^2
    ns
}

Variabilities.Cross.Rep.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, 0.75)
```

由于$n_{s}=n_{1}+n_{2}-2$,每组需`r (round(Variabilities.Cross.Rep.Equality(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, 0.75))+2)/2`例。

####非劣性/优效性检验
非劣性/优效性检验样本量计算公式如下$$n= \frac{\sigma ^{*2}(z_{1-\alpha}+z_{1-\beta})^{2}}{(\sigma _{TT}^{2}-\delta ^{2}\sigma _{TR}^{2})^{2}}$$,其中$\sigma^{*2}=2\begin{bmatrix}(\sigma_{BT}^{2}+\frac{\sigma _{WT}^{2}}{m})^{2}+\delta ^{4}(\sigma _{BR}^{2}+\frac{\sigma_{WR}^{2}}{m})^{2}-2\delta^{2}\rho^{2}\sigma_{BT}^{2}\sigma_{BR}^{2}+\frac{(m-1)\sigma_{WT}^{4}}{m^{2}}+\delta ^{4}\frac{(m-1)\sigma _{WR}^{4}}{m^{2}}\end{bmatrix}$

例 设计一个2组每个个体重复2次的交叉对照实验(ABAB,BABA)，根据预试验，T组和R组的个体间标准差分别为0.3,0.4,T组和R组的个体内标准差分别为0.2,0.3,在$\alpha=0.05,\beta=0.20,\rho= 0.75$时，1：1非劣性设计，需要多少样本量？

```{r}
Variabilities.Cross.Rep.NIS <- function(alpha, beta, vbt, vwt, vbr, vwr, 
    m, margin, rho) {
    sigma = 2 * ((vbt^2 + vwt^2/m)^2 + margin^4 * (vbr^2 + vwr^2/m)^2 - 
        2 * margin^2 * rho^2 * vbt^2 * vbr^2 + (m - 1) * vwt^4/(m^2) + 
        margin^4 * (m - 1) * vwr^4/(m^2))
    ns = sigma * (qnorm(1 - alpha) + qnorm(1 - beta))^2/(vbt^2 + vwt^2 - 
        margin^2 * (vbr^2 + vwr^2))^2
    ns
}

Variabilities.Cross.Rep.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, -1.1, 0.75)
```

由于$n_{s}=n_{1}+n_{2}-2$,每组需`r (round(Variabilities.Cross.Rep.NIS(0.05, 0.2, 0.3, 0.2, 0.4, 0.3, 2, -1.1, 0.75))+2)/2`例。

##生物等效性(Bioequivalence)
生物利用度(bioavailability)指药物吸收进入血液循环的程度和速度。通常它的吸收程度是用血浆药物浓度与时间曲线下的面积（AUC）表示的，不管曲线下的形状如何，曲线下面积越大，表示吸收越完全。而吸收速度是以用药后所能达到的最高血药浓度（峰浓度，$C_{max}$）与达到最高血药浓度的时间（达峰时间，$T_{max}$）比值。一般认为静脉注射的生物利用度是100%，如果把静脉注射(iv)与血管外给药(ev)的AUC值进行比较，并计算后者的生物利用度，即为绝对生物利用度。同一给药途径下，对不同制剂进行比较，即为相对生物利用度。

生物等效性(bioequivalence, BE)是指统一种药物的不同制剂在相同实验条件下，给予相同剂量，其吸收程度和速度没有显著的差异，主要用于评价仿制药(generic drug)与专利药(brand-name drug)是否相当。FDA规定,例如仿制药与标准药,天然药与化学药,口服药与针剂,长效药与短效药,某药低剂量与高剂量的比较需要用生物等效性方法来评价。FDA规定,若仿制药品与注册药品间具有生物等效性,申报过程可按缩略申报程序进行,而不需要按新药申报程序进行,避免了耗时、昂贵的I、II、III期临床试验，所以生物等效性在新药临床试验中占有重要的地位。

生物等效性与药剂等效性(pharmaceutical eqivalents)不同，药剂等效性是指统一药物相同剂量制成同一剂型，但非活性成分不一定相同，在含量、纯度、均度等符合同一规定标准的制剂。药剂等效性没有反映药物制剂在体内的情况。生物等效性均以试验品与参考品作比较, 二者应有相似的剂量形式, 并且它们在生物体内吸收的速率和延缓(吸收率和吸收度)没有显著的差别。目前关于生物等效性的实验设计与分析是基于以下假设的：两药物的吸收率和吸收度相同即认为生物等效, 它们的治疗效果也应是相同的。吸收率和吸收度是通过测量药代动力学响应, 如AUC和$C_{max}$而得到的。因此生物等效性应该是对于这些观测值所在总体分布而言的, 当它是正态分布或对数正态分布时 , 只要比较均数和变异就可以了。也就是说, 要看生物利用度是否是等效的, 需要把这些利用度数值作为总体参数在两种配方中的样本作统计推断 。1996年Chinchilli给出3个关于生物等效性定义群体生物等效性(population bioequivalence, PBE): 对于两药物有关的概率分布函数而言是生物等效性 ;平均生物等效性(average bioequivalence, ABE): 对于两药物有关的概率分布函数的均数或中位数而言是生物等效性 ;个体生物等效性(individual bioequivalence, IBE): 对于总体中大部分个体而言是生物等效性。ABE虽然保证平均效应相同，但不一定保证效应的变异度相同，即两总体的均值相同，但方差不一定相同。PBE能保证使用T药物和使用R药物所得效应，不仅其平均值相同，而且效应的变异度相同，即两总体的边缘分布相同。PBE虽保证其边缘分布相同，但对每个个体而言，使用T药物和使用R药物所得效应不一定相同。即个体与药物可能存在交互作用。IBE对每个个体而言，使用T药物和使用R药物所得效应值接近。从等效的程度看，IBE>PBE>ABE。从应用角度看，两个具有个体生物等效性的药物，具有药物可交替性(switchability),即某患者在服用某药物一段时间后，如果改用另一个与之具有个体等效性的药物，可以得到相同的效果。具有群体生物等效性的药物，具有处方可选择性(prescribability),即医生在给患者初次开药时可以任意选用，这对该类患者的群体来说效应是相同的。基于以上考虑，美国FDA较为提倡PBE和IBE。

###平均生物等效性
标准2(顺序)×2(时期) 交叉试验，即两种处理T和R, 则将受试对象随机分为两组, 第一组在第一时期接受T处理,在第二时期接受R处理,实验顺序为TR;第二组则相反,在第一时期接受R处理,在第二时期接受T处理, 实验顺序为 RT。平均生物等效性基于2×2交叉设计的样本量可用如下公式进行估计$$n=\frac{(z_{1-\alpha }+z_{1-\beta /2})^{2}\sigma _{1,1}^{2}}{2(\delta -|\epsilon |)^{2}}$$,其中$\delta$为平均等效界值在ln(8/10)到ln(10/8)之间，$\sigma _{1,1}$为个体内标准差，$\epsilon$为T和R的差值。

例 某研究者预设计一个2×2交叉设计的、比较某种药物的吸入剂和皮下注射剂差异的平均生物等效性试验，根据药代动力学的预试验，个体内标准差为0.4，平均等效界值为ln(10/8)约为0.2231，差值为0.05,$\sigma=0.4$,，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(ABE(0.05,0.2,0.4,0.223,0.05))
```
每组需要`r round((ABE(0.05,0.2,0.4,0.223,0.05)))`例。

###群体生物等效性
群体生物等效性基于2×2交叉设计的样本量可用如下公式进行估计$$n=\frac{\zeta (z_{1-\alpha}+z_{\beta })^{2}}{\lambda ^{2}}$$,其中$\zeta =2\delta ^{2}\sigma _{1,1}^{2}+\sigma _{TT}^{4}+(1+a)^{2}\sigma_{TR}^{4}-2(1+a)\rho ^{2}\sigma _{TT}^{2}\sigma_{TR}^{2}$,$\delta$为界值，$\sigma_{a,b}^{2}=\sigma_{D}^{2}+a\sigma _{WT}^{2}+b\sigma _{WT}^{2}$，$\rho$为个体间相关系数，a为1.74,$\delta$为AUC值的平均差。

例 某研究者预设计一个2×2交叉设计的、比较某种药物的吸入剂和皮下注射剂差异的群体生物等效性试验，根据药代动力学的预试验 $\sigma _{1,1}=0.2,\sigma _{tt}=\sqrt{0.17},\sigma_{tr}=\sqrt{0.17},\sigma _{bt}=0.4,\sigma_{br}=0.4,\rho=0.75,a=1.74,\delta=0.00,\lambda =-0.2966$ ,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
PBE(0.05,0.2,0.2,sqrt(0.17),sqrt(0.17),0.4,0.4,0.75,1.74,0.00,-0.2966)
```
每组需要`r round(PBE(0.05,0.2,0.2,sqrt(0.17),sqrt(0.17),0.4,0.4,0.75,1.74,0.00,-0.2966))`例。

###个体生物等效性
个体生物等效性基于2×4交叉设计(TRTR，RTRT)的样本量可用如下公式$$\hat{\gamma }+\sqrt{\hat{U}}+\sqrt{\hat{U_{1-\beta }}}\leq 0$$,其中$$U=\begin{bmatrix}(|\hat{\delta}|+t_{0.05,n_{1}+n_{2}-2}\frac{\hat{\sigma} _{0.5,0.5}}{2}\sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}})^{2}-\hat{\delta}^{2}\end{bmatrix}^{2}$$$$+\hat{\sigma} _{0.5,0.5}^{4}(\frac{n_{1}+n_{2}-2}{\chi_{0.95,n_{1}+n_{2}-2} ^{2}}-1)^{2}$$$$+0.5^{2}\hat{\sigma}_{WT}^{4}(\frac{n_{1}+n_{2}-2}{\chi_{0.95,n_{1}+n_{2}-2} ^{2}}-1)^{2}$$$$+(1.5+\theta _{IBE})^{2}\hat{\sigma}_{WT}^{4}(\frac{n_{1}+n_{2}-2}{\chi_{0.05,n_{1}+n_{2}-2} ^{2}}-1)^{2}$$，$$\gamma =\delta ^{2}+\sigma _{D}^{2}+\sigma _{WT}^{2}-\sigma _{WR}^{2}-\theta_{IBE}max\begin{Bmatrix}\sigma _{0},\sigma _{WR}^{2}\end{Bmatrix}$$，$$\sigma _{a,b}^{2}=\sigma _{D}^{2}+a\sigma _{WT}^{2}+b\sigma _{WR}^{2}$$，$\sigma_{WT}^{2},\sigma_{WR}^{2}$分别为T、R效应的个体内方差,$\sigma_{BT}^{2},\sigma_{BR}^{2}$分别为T、R效应的个体间方差，$\delta$为T和R效应的差值，$\sigma_{D}^{2}$为个体与药物的交互作用。

例 某研究者预设计一个2×4交叉设计的、比较某种药物的吸入剂和皮下注射剂差异的个体生物等效性试验，根据药代动力学的预试验 $\sigma _{BT}=0.1,\sigma _{BR}=0.4,\sigma _{WT}=0.6,\sigma _{WR}=0.4,\delta=0,a=b=0.5,\theta_{IBE}=5.11,\rho=0.75$ ,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
IBE <- function(alpha, beta, delta, sigmaBT, sigmaBR, sigmaWT, sigmaWR, 
    a, b, thetaIBE, rho) {
    sigmaD <- sqrt(sigmaBT^2 + sigmaBR^2 - 2 * rho * sigmaBT * sigmaBR)
    Sigma <- function(sigmaD, sigmaWT, sigmaWR, a, b) {
        Sigma = sigmaD^2 + a * sigmaWT^2 + b * sigmaWR^2
    }
    U <- function(n, alpha, beta, delta, sigmaD, sigmaWT, sigmaWR, a, b, 
        thetaIBE) {
        U = ((abs(delta) + qt(alpha, 2 * n - 2) * Sigma(sigmaD, sigmaWT, 
            sigmaWR, 0.5, 0.5)/2 * sqrt(2/n))^2 - delta^2)^2 + Sigma(sigmaD, 
            sigmaWT, sigmaWR, 0.5, 0.5)^4 * ((2 * n - 2)/qchisq(1 - alpha, 
            2 * n - 2) - 1)^2 + 0.5^2 * sigmaWT^4 * ((2 * n - 2)/qchisq(1 - 
            alpha, 2 * n - 2) - 1)^2 + (1.5 + thetaIBE)^2 * sigmaWR^4 * 
            ((2 * n - 2)/qchisq(alpha, 2 * n - 2) - 1)^2
    }
    gamma = delta^2 + sigmaD^2 + sigmaWT^2 - sigmaWR^2 - thetaIBE * sigmaWR^2
    n <- 0
    for (i in 2:1000) {
        bound = gamma + sqrt(U(i, alpha, 0.05, delta, sigmaD, sigmaWT, 
            sigmaWR, a, b, thetaIBE)) + sqrt(U(i, alpha, beta, delta, sigmaD, 
            sigmaWT, sigmaWR, a, b, thetaIBE))
        if (round(bound, digits = 2) == 0) {
            n = i
        }
    }
    n
}

IBE(0.05, 0.2, 0, 0.1, 0.4, 0.6, 0.4, 0.5, 0.5, 5.11, 0.75)
```

每组需要`r round(IBE(0.05, 0.2, 0, 0.1, 0.4, 0.6, 0.4, 0.5, 0.5, 5.11, 0.75))`例，与Sample Size Calculation in Clinical Research书中的计算结果有差异。

### 体外实验法
体外实验法的样本量可用如下公式$$\hat{\zeta }+\sqrt{\hat{U}}+\sqrt{\hat{U_{1-\beta }}}\leq 0$$进行估算,其中$$U=\begin{bmatrix}(|\hat{\delta}|+z_{0.05}\sqrt{\frac{s_{BT}^{2}}{m_{T}}+\frac{s_{BR}^{2}}{m_{R}}})^{2}-\hat{\delta}^{2}\end{bmatrix}^{2}$$$$+s_{BT}^{4}(\frac{m_{T}-1}{\chi_{0.95,m_{T}-1} ^{2}}-1)^{2}$$$$+(1-n_{T}^{-1})^{2}s_{WT}^{4}(\frac{m_{T}(n_{T}-1)}{\chi_{0.95,m_{T}(n_{T}-1)} ^{2}}-1)^{2}$$$$+(1+\theta _{BE})^{2}s_{BR}^{4}(\frac{m_{R}-1}{\chi_{0.05,m_{R}-1} ^{2}}-1)^{2}+$$$$(1+c\theta _{BE})^{2}(1-n_{R}^{-1})^{2}s_{WR}^{4}(\frac{m_{R}(n_{R}-1)}{\chi_{0.05,m_{R}(n_{R}-1)}}-1)$$，$$\zeta =\delta ^{2}+\sigma _{T}^{2}-\sigma _{R}^{2}-\theta _{BE}max\begin{Bmatrix}\sigma _{0}^{2},\sigma _{R}^{2},\end{Bmatrix}$$，$\sigma_{WT}^{2},\sigma_{WR}^{2}$分别为T、R效应的个体内方差,$\sigma_{BT}^{2},\sigma_{BR}^{2}$分别为T、R效应的个体间方差，$\delta$为T和R效应的差值。

例 某研究者预设计一个无重复的平行对照的体外实验法，根据药代动力学的预试验 $\sigma _{BT}=0.5,\sigma _{BR}=0.5,\sigma _{WT}=0.5,\sigma _{WR}=0.5,\delta=0,a=b=0.5,\theta_{BE}=15$ ,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？
```{r}
Vitro.BE <- function(alpha, beta, delta, sigmaBT, sigmaBR, sigmaWT, sigmaWR, 
    thetaBE) {
    U <- function(m, n, alpha, beta, delta, sigmaBT, sigmaBR, sigmaWT, 
        sigmaWR, thetaBE) {
        U = ((abs(delta) + qnorm(alpha) * sqrt(sigmaBT^2/m + sigmaBR^2/m))^2 - 
            delta^2)^2
        +(sigmaBT^2 + sigmaWT^2)^2 * ((m - 1)/qchisq(1 - alpha, m - 1) - 
            1)^2
        +(1 + thetaBE)^2 * (sigmaBR^2 + sigmaWR^2)^2 * ((m - 1)/qchisq(alpha, 
            m - 1) - 1)^2
    }
    sigmaT = sqrt(sigmaBT^2 + sigmaWT^2)
    sigmaR = sqrt(sigmaBR^2 + sigmaWR^2)
    gamma = delta^2 + sigmaT^2 - sigmaR^2 - thetaBE * sigmaR^2
    n <- 0
    for (i in 2:1000) {
        bound = gamma + sqrt(U(i, 1, alpha, 0.05, delta, sigmaBT, sigmaBR, 
            sigmaWT, sigmaWR, thetaBE))
        +sqrt(U(i, 1, alpha, beta, delta, sigmaBT, sigmaBR, sigmaWT, sigmaWR, 
            thetaBE))
        if (round(bound, digits = 2) == 0) {
            n = i
        }
    }
    n
}

Vitro.BE(0.05, 0.2, 0, 0.5, 0.5, 0.5, 0.5, 1)
```

每组需要`r round(Vitro.BE(0.05, 0.2, 0, 0.5, 0.5, 0.5, 0.5, 1))`例

##剂量反应研究(Dose Response Studies)
II期临床试验目的在于对新药的安全性和有效性进行初步评价，并通过对剂量反应关系的研究，为III期临床实验给药剂量方案的制定提供依据。实际中，I期临床试验的剂量反应关系关注安全性，II期临床试验的剂量反应关系关注有效性。剂量反应关系研究主要包括：确认不同剂量组之间是否存在剂量反应关系，剂量反应关系曲线的形状如何，最佳剂量应该为多少？剂量反映关系的研究通常采用随机平行对照设计，通过测量方差来证明药物的有效性，通过Williams方法比较实验组和对照组的最小有效剂量（MED），通过模型来证明剂量反应关系，通过最大耐受剂量（MTD）说明最优剂量。

###计量资料（Continuous Response）
基于线性对比法的样本量可根据$$N=\begin{bmatrix}\frac{(z_{1-\alpha }+z_{1-\beta })\sigma }{\varepsilon }\end{bmatrix}^{2}\sum_{i=0}^{k}\frac{c_{i}^{2}}{f_{i}}$$进行估计，$\sigma$为标准差，$\varepsilon =\sum_{i=0}^{k}c_{i}u_{i}$,$c_{i}$为分组情况，但应使得$\sum c_{i}=0$,$u_{i}$为各组相对于基线提高的百分率。

例 为某药物设计一个4组平行对照剂量反应试验，其中有1个对照组，3个试验组（剂量分别为20mg, 40mg,60mg），根据预实验，$\sigma=0.22,c_{0}= −6, c_{1} = 1, c_{2}= 2, c_{3} = 3,u_{0}= 0.05, u_{1} = 0.12, u_{2}= 0.14, u_{3} = 0.16$,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
mui=c(0.05,0.12,0.14,0.16)
ci=c(-6,1,2,3)
(Dose.Response.Linear(alpha=0.05,beta=0.2,sigma=0.22,mui=mui,ci=ci,fi=1/4))
```
每组需要`r round((Dose.Response.Linear(alpha=0.05,beta=0.2,sigma=0.22,mui=mui,ci=ci,fi=1/4)))/4`例。

###二分类变量（Binary Response）
结果为二分类的样本量可根据$$N\geq \begin{bmatrix}\frac{z_{1-\alpha }\sqrt{\sum_{i=0}^{k}\frac{c_{i}^{2}}{f_{i}}\bar{p}(1-\bar{p})}+z_{1-\beta}\sqrt{\sum_{i=0}^{k}\frac{c_{i}^{2}}{f_{i}}p_{i}(1-p_{i})}}{\varepsilon }\end{bmatrix}^{2}$$进行估计，$\varepsilon =\sum_{i=0}^{k}c_{i}p_{i}$,$c_{i}$为分组情况，但应使得$\sum c_{i}=0$,$p_{i}$为各组的反应率。

例 为某药物设计一个4组平行对照剂量反应试验，其中有1个对照组，3个试验组（剂量分别为20mg, 40mg,60mg），根据预实验，$\sigma=0.22,c_{0}= −6, c_{1} = 1, c_{2}= 2, c_{3} = 3,p_{0}= 0.05, p_{1} = 0.12, p_{2}= 0.14, p_{3} = 0.16$,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
pi=c(0.05,0.12,0.14,0.16);
ci=c(-6,1,2,3);
(Dose.Response.binary(alpha=0.05,beta=0.2,pi=pi,ci=ci,fi=1/4))
```
每组需要`r round((Dose.Response.binary(alpha=0.05,beta=0.2,pi=pi,ci=ci,fi=1/4)))/4`例。

###时间事件数据（Time-to-Event Endpoint）
分析结果为时间事件样本量可根据$$N\geq \begin{bmatrix}\frac{z_{1-\alpha }\sigma _{0}\sqrt{\sum_{i=0}^{k}\frac{c_{i}^{2}}{f_{i}}}+z_{1-\beta}\sqrt{\sum_{i=0}^{k}\frac{c_{i}^{2}}{f_{i}}\sigma _{i}}}{\varepsilon }\end{bmatrix}^{2}$$进行估计，其中$\sigma ^{2}(\lambda _{i})=\lambda _{i}^{2}\begin{bmatrix}1+\frac{e^{-\lambda _{i}T}(1-e^{\lambda _{i}T_{0}})}{T_{0}\lambda _{i}}\end{bmatrix}^{-1}$,
$T_{0}$为试验的纳入时间，$T$为整个试验时间，$c_{i}$为分组情况，但应使得$\sum c_{i}=0$。

例 某抗肿瘤药物进行II期临床实验，设计1个对照组，1个低剂量组，1个高剂量组和1个联合治疗组，研究结果为患者的生存时间。假定试验的纳入时间为9个月，总实验时间为16个月，估计四组的中位生存时间为14,20,22和24个月（相应的风险率为0.0495/月,0.0347/月,0.0315/月和0.0289/月）。在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
Ti=c(14,20,22,24);
ci=c(-6,1,2,3);
(Dose.Response.time.to.event(alpha=0.05,beta=0.2,T0=9,T=16,Ti=Ti,ci=ci,fi=1/4))
```

每组需要`r round((Dose.Response.time.to.event(alpha=0.05,beta=0.2,T0=9,T=16,Ti=Ti,ci=ci,fi=1/4)))/4`例。

###最小有效剂量（MED）
基于Williams检验的最小有效剂量样本量可根据$$n=\frac{2\sigma ^{2}[t_{k}(\alpha )+z\beta ]^{2}}{\Delta ^{2}}$$进行计算，$t_{k}(\alpha )$ 依赖于自由度。

例 某研究者设计一个Williams方法检测最小有效计量的剂量反映实验，根据预试验$\sigma=0.22,t_{3}(\alpha)=1.75,\Delta=0.11$,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(Dose.Min.Effect(0.05,0.2,1.75,0.22,0.11))
```

每组需要`r round(Dose.Min.Effect(0.05,0.2,1.75,0.22,0.11))`例。

###Cochran-Armitage 趋势检验
Cochran-Armitage 趋势检验样本量可根据$$n=\frac{n^{*}}{4}\begin{bmatrix}1+\sqrt{1+\frac{2\Delta}{An_{0}^{*}}}\end{bmatrix}^{2}$$进行计算，其中$$n^{*}\begin{Bmatrix}z_{1-\alpha }\sqrt{k(k^{2}-1)pd}+z_{1-\beta }\sqrt{\sum b_{i}^{2}p_{i}q_{i}}\end{Bmatrix}^{2}$$,$b_{i}=i-0.5k,D=\sum b_{i}p_{i}$。$p_{i}$为每组的反应率,$A=\sum r_{i}p_{i}(d_{i}-\hat(d)),p=1/N\sum n_{i}p_{i},q=1-p,r_{i}=n_{i}/n_{0}$

例 某研究者设计一个4组Cochran-Armitage趋势检测的剂量反映实验，根据预试验$p_{1}=0.1,p_{2}=0.3,p_{3}=0.5,p_{4}=0.7,d_{1}=1,d_{2}=2,d_{3}=3,d_{4}=4,n_{1}=n_{2}=n_{3}=n_{4}=10$,在$\alpha=0.05,\beta=0.20，\Delta=1$时，需要多少样本量？

```{r}
pi=c(0.1,0.3,0.5,0.7)
di=c(1,2,3,4)
ni=c(10,10,10,10)

Cochran.Armitage.Trend(alpha=0.05,beta=0.2,pi=pi,di=di,ni=ni,delta=1)
```

每组需要`r round(Cochran.Armitage.Trend(alpha=0.05,beta=0.2,pi=pi,di=di,ni=ni,delta=1))`例。

###爬坡试验(Dose Escalation Trials)
多数抗肿瘤药物的治疗指数很窄，为避免较高的起始剂量可能出现严重毒性，过低的起始剂量造成的试验周期延长和资源浪费，通常使用爬坡试验的方法。根据各剂量组人数分配策略变化，非参数的爬坡试验设计又被称为 “M+N”试验设计或“A+B”试验设计。全部受试者被随机分配至若干组，每组均包含若干名受试者。同组的受试者服用相同剂量水平的受试药物。按照随机分配方案逐组进入试验的流程，各组内受试者服用且只服用一次某剂量水平的受试药物。不论是否探测到预期的药物响应，均记录其药物响应结果。当在某一剂量水平药物响应人数满足整体试验停止的条件时，整 体试验过程结束并获得探索的目标剂量。在探索剂量限制性毒性(DLT，dose limiting toxicity)和最大耐受剂量（MTD，maximum tolerable dose）时以爬坡试验“3+3”设计应用为广泛，即每次进入试验过程的一组受试者都是3名，某剂量水平最多6名受试者服用药物。爬坡试验设计整体剂量爬升规则又可以分为TER策略（traditional escalation rules）与STER 策略（strict traditional escalation rules）两种不同的剂量爬升策略。TER策略与STER策略的最大区别仅仅在于：当在$x_{j}$剂量水平探测到受试药物毒性响应时，遵循TER剂量爬升策略的Ⅰ期临床试验并不允许在$x_{j-1}$剂量水平继续纳入受试者进行试验，而要求直接停止试验，此时认为剂量水平$x_{j}$为预期的目标剂量水平。而遵循STER剂量爬升规则的临床试验则要求在$x_{j-1}$剂量水平继续纳入受试者进行试验，以观察$x_{j-1}$剂量水平受试者整体的毒性反应，从而才能推断目标剂量。相对于TER规则而言，遵循STER规则的Ⅰ期临床试验获得的目标剂量更加保守，使得目标剂量被高估的可能性降低。在评价研发药物安全性、探索药物毒性指标MTD的Ⅰ期临床试验中，这一点就显得更加重要，使得STER 规则的应用更加广泛 。

A+B TER策略设计的样本量可依据$$N_{j}=\sum_{i=0}^{n-1}N_{ji}P_{i}^{*}$$进行估计，其中$$N_{ji}= \begin{cases} \frac{AP_{0}^{j}+(A+B)Q_{0}^{j}}{P_{0}^{j}+Q_{0}^{j}}& \text{if }j< i+1\\ \frac{A(1-P_{0}^{j}-P_{1}^{j})+(A+B)(P_{1}^{j}-Q_{0}^{j})}{1-P_{0}^{j}-Q_{0}^{j}}& \text{if } j=i+1 \\0 & \text{if } j>i+1 \end{cases}$$,$$P_{0}^{j}=\sum_{k=0}^{C-1}\bigl(\begin{smallmatrix}\\ A\\k\end{smallmatrix}\bigr)p_{j}^{k}(1-p_{j})^{A-k}$$,$$Q_{0}^{j}=\sum_{k=C}^{D}\sum_{m=0}^{E-k}\bigl(\begin{smallmatrix}\\ A\\k\end{smallmatrix}\bigr)p_{j}^{k}(1-p_{j})^{A-k}\bigl(\begin{smallmatrix}\\B\\m\end{smallmatrix}\bigr)p_{j}^{m}(1-p_{j})^{B-m}$$,$$P_{n}^{*}=\prod _{j=1}^{n}(P_{0}^{j}+Q_{0}^{j})$$。

A+B STER策略设计的样本量可依据$$N_{j}=N_{jn}P_{n}^{*}+\sum_{i=0}^{n-1}\sum_{k=i+1}^{n}N_{jik}P_{ik}$$进行估计，其中$$N_{jik}= \begin{cases} \frac{AP_{0}^{j}+(A+B)Q_{0}^{j}}{P_{0}^{j}+Q_{0}^{j}}& \text{if }j< i\\ A+B & \text{if }i\leq j<k\\ \frac{A(1-P_{0}^{j}-P_{1}^{j})+(A+B)(P_{1}^{j}-Q_{0}^{j})}{1-P_{0}^{j}-Q_{0}^{j}}& \text{if } j=k \\0 & \text{if } j>k \end{cases}$$,$$P_{i}^{*}=\sum _{k=i+1}^{n}p_{ik}$$,$$p_{ik}=(Q_{0}^{i}+Q_{0}^{i})(1-P_{0}^{k}-Q_{0}^{k})\left (\prod_{j=1}^{i-1}(P_{0}^{j}+Q_{0}^{j}) \right )\prod_{j=i+1}^{k-1}Q_{2}^{j}$$,$$P_{n}^{*}=\prod _{j=1}^{n}(P_{0}^{j}+Q_{0}^{j})$$。

例 爬坡试验“3+3”设计，根据预试验某抗肿瘤药物7种剂量(10 15 23 34 51 76 114)的剂量限制性毒性分别为0.01 0.014 0.025 0.056 0.177 0.594 0.963，请估计每种剂量的样本量?

```{r}
DLT=c(0.01,0.014,0.025,0.056,0.177,0.594,0.963)
# 3+3 TER策略设计
AB.withoutDescalation(A=3,B=3,C=1,D=1,E=1,DLT=DLT)
# 3+3 STER策略设计
AB.withDescalation(A=3,B=3,C=1,D=1,E=1,DLT=DLT)
```

##微阵列研究(Microarray Studies)
微阵列数据样本含量较小，而变量数非常多，传统的t检验和Wilcoxon检验在应用时需要进行调整，为克服多重比较的问题，按控制指标可分为控制FWER(family-wise error rate ,族错误率), 控制FDR(fasle discover rate , “错误发现率”) 等;按控制的操作程序可分为:单步(single-step)法 , 逐步(step-wise)法,基于再抽样(resampling -based)的方法等;按学派主要分为频率学派方法和Bayes学派的方法等。

多重检验是传统的多重比较概念的推广，通过对同一问题的多变量反复检验来验证$H_{0}$假设，该假设是一系列的假设(a family of hypotheses),并非单一假设，如任意基因的组间表达无差异。

###错误发现率(False Discovery Rate)
设同时对m个假设进行检验，其中$m_{0}$个是正确的，R表示检验结果为阳性的假设个数，具体如下表

              不拒绝$H_{0}$      拒绝$H_{0}$      合计
---           ---                 ---             ---
$H_{0}$为真   U                   V               $m_{0}$
$H_{1}$为真   T                   S               $m-m_{0}$
合计          m-R                 R               m

其中，m在假设检验前已知，R是可观察的随机变量，而U、V、S、T是不可观察的随机变量，FDR的定义为$$FDR= \begin{cases}E(V/R) & \text{if } R \neq \\0 & \text{if } R=0\end{cases}$$,即为拒绝$H_{0}$的结果中错误这所占的比例。
FDR设计，单侧固定效应检验样本量估计公式为$$n=\begin{bmatrix}\frac{(z_{\alpha ^{*}}+z_{\beta ^{*}})^{2}}{a_{1}a_{2}\delta ^{2}}\end{bmatrix}+1$$其中$\alpha ^{*}=\frac{r_{1}f}{m_{0}(1-f)}$,$\beta ^{*}=1-r_{1}/m_{1}$,$a_{2}=1-a_{1}$。f为错误发现率，$r_{1}$为是实际拒绝的数量，$a_{k}$为两组分配比，m为测试基因的总数，$m_{1}$为预后基因的数量，$\delta_{j}$预后基因效应的大小。单侧可变效应检验需解$$h(n)=0$$这个方程，其中$h(n)=\sum _{j\in M_{1}}\Phi (z_{\alpha ^{*}}-\delta _{j}\sqrt{na_{1}a_{2}})-r_{1}$,$a^{*}=r_{1}f/{m_{0}(1-f)}$。

例 设计一个4000个候选基因的微阵列(m=4000)研究，预计两组之间有40($m_{1}$=40)个不同表达的基因,实际拒绝基因数约为24($r_{1}$=40)，单侧固定效应设计，预计错误发现率为0.01,在$\delta=1,a_{1}=a_{2}=0.5$时，需要多少样本量？

```{r}
OneSide.fixEffect(m=4000,m1=40,delta=1,a1=0.5,r1=24,fdr=0.01)
```
每组需要`r round(OneSide.fixEffect(m=4000,m1=40,delta=1,a1=0.5,r1=24,fdr=0.01))/2`例。

例 设计一个4000个候选基因的微阵列(m=4000)研究，预计两组之间有40($m_{1}$=40)个不同表达的基因,实际拒绝基因数约为24($r_{1}$=40)，单侧可变效应设计，预计错误发现率为0.01，$\delta_{j}= \begin{cases} 1& \text{if } 1\leq i \leq 20\\ 1/2& \text{if } 21\leq i \leq 40\end{cases}$,$,在$a_{1}=a_{2}=0.5$时，需要多少样本量？
```{r}
delta=c(rep(1,40/2),rep(1/2,40/2))
OneSide.varyEffect(100,150,4000,40,delta,0.5,24,0.01)
```
每组需要`r round(OneSide.varyEffect(100,150,4000,40,delta,0.5,24,0.01)$s2)/2`例。

双侧固定效应检验样本量估计公式为$$n=\begin{bmatrix}\frac{(z_{\alpha ^{*}/3}+z_{\beta ^{*}})^{2}}{a_{1}a_{2}\delta ^{2}}\end{bmatrix}+1$$,其中其中$\alpha ^{*}=\frac{r_{1}f}{m_{0}(1-f)}$,$\beta ^{*}=1-r_{1}/m_{1}$。双侧可变效应检验需解$$h(n)=0$$这个方程，其中$h(n)=\sum _{j\in M_{1}}\Phi (z_{\alpha ^{*}/2}-|\delta| _{j}\sqrt{na_{1}a_{2}})-r_{1}$,$a^{*}=r_{1}f/{m_{0}(1-f)}$。

例 设计一个4000个候选基因的微阵列(m=4000)研究，预计两组之间有40($m_{1}$=40)个不同表达的基因,实际拒绝基因数约为24($r_{1}$=40)，双侧固定效应设计，预计错误发现率为0.01,在$\delta=1,a_{1}=a_{2}=0.5$时，需要多少样本量？

```{r}
TwoSide.fixEffect(m=4000,m1=40,delta=1,a1=0.5,r1=24,fdr=0.01)
```
每组需要`r round(TwoSide.fixEffect(m=4000,m1=40,delta=1,a1=0.5,r1=24,fdr=0.01))/2`例。

例 设计一个4000个候选基因的微阵列(m=4000)研究，预计两组之间有40($m_{1}$=40)个不同表达的基因,实际拒绝基因数约为24($r_{1}$=40)，双侧可变效应设计，预计错误发现率为0.01，$\delta_{j}= \begin{cases} 1& \text{if } 1\leq i \leq 20\\ 1/2& \text{if } 21\leq i \leq 40\end{cases}$,$,在$a_{1}=a_{2}=0.5$时，需要多少样本量？
```{r}
delta=c(rep(1,40/2),rep(1/2,40/2))
TwoSide.varyEffect(s1=100,s2=200,m=4000,m1=40,delta=delta,a1=0.5,r1=24,fdr=0.01)
```
每组需要`r round(TwoSide.varyEffect(s1=100,s2=200,m=4000,m1=40,delta=delta,a1=0.5,r1=24,fdr=0.01)$s2)/2`例。

##非参数检验(Nonparametrics)
非参数检验不依赖参数进行的假设检验。适用于未知分布型、偏态资料、等级性资料等的假设检验。非参数检验在应用上无严格的限制条件，适用范围广，对数据的要求不像参数检验那样严格。

###单组位置检验(One-Sample Location Problem)
单组位置检验样本量估计公式为$$n=\frac{(z_{1-\alpha /2}\sqrt{12}+z_{1-\beta }\sqrt{p_{3}+4p_{4}-4p_{2}^{3}})^{2}}{1/4-p_{2}}$$,其中$p_{2}=P(|z_{i}|>=|z_{j}|,z_{i}>0)$,$p_{3}=P(|z_{i}|>=|z_{j1}|,|z_{i}|>=|z_{j2}|,z_{i}>0)$,$p_{4}=P(|z_{j1}|>=|z_{i}|>=|z_{j2}|>=0,z_{i}>0)$。

例 某预防更年期骨质疏松症药物,进行单组位置检验，根据5例的预试验，$p_{2}=0.3,p_{3}=0.4,p_{4}=0.05$,在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(Nonpara.One.Sample(0.05,0.2,0.3,0.4,0.05))
```
需要`r round((Nonpara.One.Sample(0.05,0.2,0.3,0.4,0.05)))`例。


###两组位置检验(Two-Sample Location Problem)
两组位置检验样本量估计公式为$$n_{2}=\frac{(z_{1-\alpha/2}\sqrt{\kappa(\kappa+1)/12}+z_{1-\beta}\sqrt{\kappa^{2}(p_{2}-p_{1}^{2})+\kappa(p_{3}-p_{1}^{2})})^{2}}{\kappa^{2}(1/2-p_{1})^2}$$,其中$n_{1}=\kappa n_{2}$,$p_{1}=P(y_{i}>x_{i})$,$p_{2}=P(y_{i}\geq x_{j1} \sim and \sim y_{i}\geq x_{j2})$,$p_{3}=P(y_{i1}\geq x_{j} \sim and \sim y_{i2}\geq x_{j})$。

例 某降低胆固醇药物，进行两组平行对照位置检验，根据预试验，$p_{2}=0.7,p_{3}=0.8,p_{4}=0.8$，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(Nonpara.Two.Sample(0.05,0.2,1,0.7,0.8,0.8))
```
需要`r round((Nonpara.Two.Sample(0.05,0.2,1,0.7,0.8,0.8)))`例。

###独立性检验(Test for Independence)
独立性检验样本量估计公式为$$n=\frac{4(z_{1-\alpha}/3+z_{1-\beta}\sqrt{2p_{2}-1-(2p_{1}-1)^{2}})^{2}}{(2p_{1}-1)^2}$$，其中$p_{1}=P((x_{1}-x_{2})(y_{1}-y_{2})>0)$,$p_{2}=P((x_{1}-x_{2})(y_{1}-y_{2})(x_{1}-x_{3})(y_{1}-y_{3})>0)$。

例 某预试验中观察到，随着x变量增大，y变量也有增大的趋势，设计一临床试验，以验证以上猜想。根据预试验，$p_{1}=0.6,p_{2}=0.7$，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(Nonpara.Independ(0.05,0.2,0.6,0.7))
```
需要`r round(((Nonpara.Independ(0.05,0.2,0.6,0.7))))`例。

##其他研究(Sample Size Calculation in Other Areas)

###QT/QTc
QT间期是指心室去极化和复极化的时程，即QRS波群的起点到T波恢复到基线时终点的时程。心脏复极化延迟将产生特殊的心脏电生理环境，这种环境下，容易发生心律失常，最常见的是引发尖端扭转型室性心动过速（TdP），但也可发生其它类型室性快速心律失常。由于QT间期延长的程度可被看作是一个致心律失常危险性的相对的生物标记，通常QT间期延长与TdP之间存在一种定性关系，对于那些可能引发QT间期延长的药物更是如此。由于QT间期与心率呈负相关，因此，常规通过各种公式将测得的QT间期校正为较少心率依赖的QTc间期。然而，尚不明确心律失常的发生与QT间期或QTc绝对值增加之间是否存在必然联系。大多数引发TdP的药物都可明显引起QT/QTc间期的延长（后称作QT/QTc）。由于QT/QTc间期延长是与提高发现心律失常敏感性有关的心电图表现，因此，新药在上市前进行充分的安全性评价应包括详细描述其对QT/QTc间期影响的特点。 

####平行对照设计
平行对照设计样本量估计公式为$$n=\frac{2(z_{1-\alpha/2}+z_{1-\beta})^{2}}{\delta ^{2}}(\rho+\frac{1-\rho}{K})$$，其中$\rho=\sigma _{s}^{2}/(\sigma _{s}^{2}+\sigma _{e}^{2})$，$K$为每个个体重复的次数，$\delta =d/(\sigma _{s}^{2}+\sigma _{e}^{2})$,$\sigma _{s}$为个体间变异(between subject variance),$\sigma _{e}$，$\sigma _{e}$为个体内变异(between subject variance),d为临床差异。

例 某非抗心律失常药物进行全面的心电图平行对照研究，以明确对QT/QTc间期影响。根据预试验$\rho=0.8,\delta=0.5$,每个个体重复3次，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
QT.parallel(0.05,0.2,0.8,3,0.5)
```
每组需要`r round(QT.parallel(0.05,0.2,0.8,3,0.5))`例。

####交叉对照设计
交叉对照设计样本两估计公式为$$n=\frac{(z_{1-\alpha/2}+z_{1-\beta})^{2}}{\delta ^{2}-\gamma (z_{1-\alpha}+z_{1-\beta})^{2}}(\rho+\frac{1-\rho}{K})$$，其中$\rho=\sigma _{s}^{2}/(\sigma _{s}^{2}+\sigma _{e}^{2})$，$K$为每个个体重复的次数，$\delta =d/(\sigma _{s}^{2}+\sigma _{e}^{2})$,$\sigma _{s}$为个体间变异,$\sigma _{e}$，$\sigma _{e}$为个体内变异,d为临床差异，$\gamma =\sigma_{p}^{2}/(\sigma_{s}^{2}+\sigma_{e}^{2})$,$\sigma_{p}^{2}$为交叉设计的额外变异。

例 某非抗心律失常药物进行全面的心电图交叉对照研究，以明确对QT/QTc间期影响。根据预试验$\rho=0.8,\delta=0.5，\gamma=0.002$,每个个体重复3次，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
QT.crossover(0.05,0.2,0.8,3,0.5,0.002)
```
每组需要`r round(QT.crossover(0.05,0.2,0.8,3,0.5,0.002))`例。

####有协变量平行对照设计
有协变量平行对照设计样本量估计公式为$$n=\frac{(z_{1-\alpha/2}+z_{1-\beta})^{2}}{\delta ^{2}}\begin{bmatrix}\frac{(v_{1}-v_{2})^{2}}{\tau_{1} ^{2}+\tau_{2} ^{2}}+2\end{bmatrix}(\rho+\frac{1-\rho}{K})$$，其中$\rho=\sigma _{s}^{2}/(\sigma _{s}^{2}+\sigma _{e}^{2})$，$K$为每个个体重复的次数，$\delta =d/(\sigma _{s}^{2}+\sigma _{e}^{2})$,$\sigma _{s}$为个体间变异,$\sigma _{e}$，$\sigma _{e}$为个体内变异,d为临床差异，$v_{1},v_{2}$分别为第一组和第二组的均数，$\tau_{1},\tau_{2}$分别为第一组和第二组的方差。

例 某非抗心律失常药物进行全面的心电图平行对照研究，已知该药$C_{max}$对QT/QTc间期有影响，以明确对QT/QTc间期影响。根据预试验$\rho=0.8,\delta=0.5$,每个个体重复3次,第一组和第二的均数均为1,方差分别为4,5，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
QT.PK.parallel(0.05,0.2,0.8,3,0.5,1,1,4,5)
```
每组需要`r round(QT.PK.parallel(0.05,0.2,0.8,3,0.5,1,1,4,5))`例。

####有协变量交叉对照设计
有协变量交叉对照设计样本量估计公式为$$n=\frac{(z_{1-\alpha/2}+z_{1-\beta})^{2}}{\delta ^{2}-\gamma (z_{1-\alpha}+z_{1-\beta})^{2}}\begin{bmatrix}\frac{(v_{1}-v_{2})^{2}}{\tau_{1} ^{2}+\tau_{2} ^{2}}+1\end{bmatrix}(\rho+\frac{1-\rho}{K})$$，其中$\rho=\sigma _{s}^{2}/(\sigma _{s}^{2}+\sigma _{e}^{2})$，$K$为每个个体重复的次数，$\delta =d/(\sigma _{s}^{2}+\sigma _{e}^{2})$,$\sigma _{s}$为个体间变异,$\sigma _{e}$，$\sigma _{e}$为个体内变异,d为临床差异，$\gamma =\sigma_{p}^{2}/(\sigma_{s}^{2}+\sigma_{e}^{2})$,$\sigma_{p}^{2}$为交叉设计的额外变异，$v_{1},v_{2}$分别为第一组和第二组的均数，$\tau_{1},\tau_{2}$分别为第一组和第二组的方差。

例 某非抗心律失常药物进行全面的心电图交叉对照研究，已知该药$C_{max}$对QT/QTc间期有影响，以明确对QT/QTc间期影响。根据预试验$\rho=0.8,\delta=0.5，\gamma=0.002$,每个个体重复3次,第一组和第二的均数均为1,方差分别为4,5，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
QT.PK.crossover(0.05,0.2,0.8,3,0.5,0.002,1,1,4,5)
```
每组需要`r round(QT.PK.crossover(0.05,0.2,0.8,3,0.5,0.002,1,1,4,5))`例。

###非随机化临床试验中的倾向得分
非随机化实验中，对象的分配依赖于对象基线协变量(covariates)。例如病人是否会得到降血脂药物治疗，可能受到很多因子的影响（如中风严重程度、中风类型、有无其他血管性危险因子，甚至是年龄、性别、社经地位等），当这些因子也同时会影响预后时，它们就是潜在的干扰因子。如果有治疗和没有治疗的病人，其基本特性是不同的，两组就无法直接比较预后。倾向性得分分析中倾向得分(propensity score)则是一个机率（0~1），代表一个病人在其既有的基本特性（或干扰因子）下，得到药物治疗的机会。倾向得分关注对象在基本特性和有无药物治疗的关系，企图再造一个类似随机分配的情境。在随机试验中，每一个受试者得到治疗的倾向得分应该是0.5。在非随机的观察性研究，倾向得分就会因病人的基本特性而异。最常见的倾向得分来自logistic回归模型：将得到治疗与否当作是因变量，把基本特性的各个因子当作是自变量。倾向得分方法已经被广泛的应用到这些非随机对照试验中来降低由于混杂因素导致的选择性偏倚,从而保证组间基线数据的均衡可比。

####权重分层分析法(WMH,weighted Mantel-Haenszel)
权重分层分析法样本量估计公式为$$n=\frac{(\sigma_{0}z_{1-\alpha/2}+\sigma_{0}z_{1-\beta})^{2}}{\delta^{2}}$$,其中$\delta =(1-\phi )\sum _{j=1}^{J}w_{j}a_{j}b_{j1}b_{j2}\frac{p_{j1}q_{j1}}{q_{j1}+\phi p_{j1}}$,$\sigma _{1}^{2}=\sum_{j=1}^{J}w_{j}^{2}a_{j}b_{j1}b_{j2}(b_{j2}p_{j1}q_{j1}+b_{j1}p_{j2}q_{j2})$,$\sigma _{0}^{2}=\sum_{j=1}^{J}w_{j}^{2}a_{j}b_{j1}b_{j2}(b_{j1}p_{j1}+b_{j2}p_{j2})(b_{j1}q_{j1}+b_{j2}q_{j2})$,$\phi =p_{j2}q_{j1}/(p_{j1}q_{j2})$，J为层数，a为每层的样本数占总样本数的比例$a_{j}=n_{j}/n$，$b_{jk}=n_{jk}/n_{j}$ k为1,2代表采取的处理方式，假设以1组为对照$b_{j1}+b_{j2}=2$，p1为j层k处理的概率。

例 某药物与传统药物对照的临床试验，主要评价指标为心血管事件，对基线变量进行组间均衡性检验发现基线变量 在试验药和对照药是不均衡的，设计层数为5的临床试验，根据预试验，每层的样本数占总样本数的比例为0.15 0.15 0.2 0.25 0.25，每层中处理组的分配比例分别为0.4 0.4 0.5 0.6 0.6，每层中出现反应的概率分别为0.5 0.6 0.7 0.8 0.9，在$\alpha=0.05,\beta=0.20，\phi=2$时，权重分层分析设计需要多少样本量？

```{r}
a=c(0.15,0.15,0.2,0.25,0.25)
b=c(0.4,0.4,0.5,0.6,0.6)
p1=c(0.5,0.6,0.7,0.8,0.9)

(Propensity.Score.strata(alpha=0.05,beta=0.2,J=5,a,b,p1,phi=2))
```
需要`r round((Propensity.Score.strata(alpha=0.05,beta=0.2,J=5,a,b,p1,phi=2)))`例。

####非分层分析法
非分层分析法样本量估计公式为$$\tilde{n}=\frac{(\tilde{\sigma_{0}}z_{1-\alpha/2}+\tilde{\sigma_{1}}z_{1-\beta})^{2}}{(p_{1}-p_{2})^{2}}$$,$\delta =\sum _{j=1}^{J}a_{j}b_{j1}b_{j2}(p_{j1}-p_{j2})$,$\sigma _{1}^{2}=\sum_{j=1}^{J}a_{j}b_{j1}b_{j2}(b_{j2}p_{j1}q_{j1}+b_{j1}p_{j2}q_{j2})$,$\sigma _{0}^{2}=\sum_{j=1}^{J}a_{j}b_{j1}b_{j2}(b_{j1}p_{j1}+b_{j2}p_{j2})(b_{j1}q_{j1}+b_{j2}q_{j2})$ J为层数，a为每层的样本数占总样本数的比例$a_{j}=n_{j}/n$，$b_{jk}=n_{jk}/n_{j}$ k为1,2代表采取的处理方式，假设以1组为对照$b_{j1}+b_{j2}=2$，p1为j层k处理的概率。

例 某药物与传统药物对照的临床试验，主要评价指标为心血管事件，对基线变量进行组间均衡性检验发现基线变量 在试验药和对照药是不均衡的，设计层数为5的临床试验，根据预试验，每层的样本数占总样本数的比例为0.15 0.15 0.2 0.25 0.25，每层中处理组的分配比例分别为0.4 0.4 0.5 0.6 0.6，每层中出现反应的概率分别为0.5 0.6 0.7 0.8 0.9，在$\alpha=0.05,\beta=0.20，\phi=2$时，非分层分析设计需要多少样本量？

```{r}
a=c(0.15,0.15,0.2,0.25,0.25)
b=c(0.4,0.4,0.5,0.6,0.6)
p1=c(0.5,0.6,0.7,0.8,0.9)

(Propensity.Score.nostrata(alpha=0.05,beta=0.2,J=5,a,b,p1,phi=2))
```

需要`r round((Propensity.Score.nostrata(alpha=0.05,beta=0.2,J=5,a,b,p1,phi=2)))`例。

###重复测量方差分析(ANOVA with Repeated Measures)
重复测量设计的方差分析可以是同一条件下进行的重复测度，也可以是不同条件下的重复测量，可以考察：(1)各种处理之间是否存在显著性差异;(2)被试之间的差异;(3)各种处理与被试分组之间的交互作用。在平行对照设计的临床试验中，主要用于评价有效性和安全性。重复测量方差分析样本量估计公式为$$n\geq \frac{2\sigma ^{*2}(z_{1-\alpha /2}+z_{1-\beta })}{\Delta ^{2}}$$,$\sigma ^{*2}$为各组分的方差总和。

例 某治疗多发性硬化(MS)药物与传统药物在实验动物身上进行平行对照试验，每只实验动物记录3次重复的疾病得分，根据预试验$\sigma ^{*2}=1.25,\Delta=1.5$，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
(ANOVA.Repeat.Measure(0.05,0.2,1.25,1.5,3))
```
需要`r round((ANOVA.Repeat.Measure(0.05,0.2,1.25,1.5,3)))`例。

###生存质量(Quality of Life,QOL)
由于慢性非传染病较难治愈，很难采用治愈率来评价治疗效果，生存率的作用也有限（明显提高其生存时间较为困难），因此采用生存质量作为新药的评价的项目。生存质量分析样本量估计公式为$$n_{\delta }=\frac{c(z_{1-\alpha /2}+z\delta )}{\epsilon ^{2}}$$,$$n_{\phi }=\frac{c}{\Delta -\eta }(z_{1/2+1/2\phi }+z_{1-1/2\alpha })$$，取两个样本量计算公式计算结果的最大值，其中$\epsilon$差值，c为常数。

例 某抗癌药进行以生存质量为结果进行临床试验，根据预试验$c=0.5,\epsilon=0.25,phi=0.1,eta=0.5$，在$\alpha=0.05,\beta=0.20$时，需要多少样本量？

```{r}
QOL <- function (alpha, beta, c, epsilon,phi,eta) 
{
  n1 = c * (qnorm(1 - 1/2 * alpha) + qnorm(1 - beta))^2/epsilon^2
  n2 = (c/(epsilon-phi)^2) * (qnorm(1/2+eta/2) + qnorm(1 - alpha/2))^2
  n = max(n1, n2)
  n
}

QOL(0.05,0.1,0.5,0.25,0.1,0.5)
```
需要`r round(QOL(0.05,0.1,0.5,0.25,0.1,0.5))`例。

###衔接性设计(Bridging Studies)
该设计主要评估“族群因素”（ethnic factors）对药品的影响，提供相关药动/药效学或疗效、安全、用法用量等临床试验数据，使得一国的临床实验数据能够外推至其他国家，减少重复的临床试验，迅速提供病患药品，以保障其权益。族群因素一般定义为与种族或与一群有共同特质和习性的人相关的因素，通常分为内因性（如遗传、生理等）和外因性（如文化、环境）。Chow等提出以敏感性指数（Sensitivity Index）作为指标，以外推安慰剂平行对照试验设计的试验结果。以敏感性指数设计的样本量估计公式为$$\tilde{P_{\Delta }}=E_{\delta,u}\begin{bmatrix}1-\tau _{n-2}(t_{n-2}|\frac{\Delta \delta }{u})-\tau_{n-2}(-t_{n-2}|\frac{\Delta \delta }{u})
\end{bmatrix}$$，$Delta$为不同族群之间的敏感性指数。

例 某药厂欲将某药推广至A国，进行平行对照的衔接性设计，以敏感性指数作为族群因素的考核指标，根据预试验$\Delta =2.92,SI=0.80$，在$\alpha=0.05$时，需要多少样本量？

```{r}
Sensitivity.Index <- function (alpha, deltaT,SI) 
{
  n = 3
  for (i in 3:1000) {
    t = qt(1 - alpha/2, i - 2)
    p = 1 - pt(t, i - 2, deltaT) + pt(-t, i - 2, deltaT)
    if (round(p, digits = 2) == round(SI, digits = 2)) {
      n = i
    }
  }
  n
}

Sensitivity.Index(0.05,2.92,0.80)
```
需要`r round(Sensitivity.Index(0.05,2.92,0.80))`例。

###疫苗临床试验(Vaccine Clinical Trials)
评价疫苗最重要的目标就是它的预防疾病的能力，通常需要大样本的安慰剂对照设计。相对发病减少率(ralative reduction in disease incidence,$pi$)被认为是疫苗有效性评价的重要指标，$\pi =\frac{p_{C}-p_{T}}{P_{C}}$,其中$p_{C}$和$p_{T}$分别代表试验组和对照组的发病率。

#### 发病率较高的试验(Reduction in Disease Incidence)
发病率较高的疫苗试验样本量可根据$$n=\frac{z_{1-\alpha /2}^{2}}{d^{2}}(\frac{1-p_{T}}{p_{T}}+\frac{1-p_{c}}{p_{c}})$$进行估计，其中$d=z_{1-\alpha/2}\sqrt{\frac{1-p_{T}}{np_{T}}+\frac{1-P_{C}}{np_{C}}}$。

例 一研究者计划实施一个疫苗临床试验，与安慰剂对照，主要指标选择相对发病减少率，根据预试验，疫苗组发病率为1%，安慰剂组发病率为2%，在$\alpha=0.05,\beta=0.2$时，两组1：1平行对照，双侧差异性检验需要多少样本量？

```{r}
options(scipen=200) #取消科学计数
(Vaccine.RDI(0.05,0.2,0.01,0.02))
```
每组需要`r round((Vaccine.RDI(0.05,0.2,0.01,0.02)))` 例。

####发病率极低的试验(The Evaluation of Vaccine Efficacy with Extremely Low Disease Incidence)
发病率极低的疫苗试验样本量可根据$$n=\frac{[z_{1-\alpha }\sqrt{\theta_{0}(1-\theta _{0})}+z_{1-\beta}\sqrt{\theta(1-\theta )}]^{2}}{(p_{T}+p_{C})(\theta -\theta _{0})^{2}}$$进行估计,其中$\theta =\frac{1-\pi}{1-\pi+n_{C}/n_{T}}$,$\theta_{0} =\frac{1-\pi_{0}}{1-\pi_{0}+n_{C}/n_{T}}$。
  
例 一研究者计划实施一个疫苗临床试验，与安慰剂对照，主要指标选择相对发病减少率，根据预试验，疫苗组发病率为0.1%，安慰剂组发病率为0.2%，$\theta_{0}=0.5,\theta=1/3$，在$\alpha=0.05,\beta=0.2$时，两组1：1平行对照，双侧差异性检验需要多少样本量？

```{r}
options(scipen=200)
(Vaccine.ELDI(0.05,0.2,0.5,1/3,0.001,0.002))
```
每组需要`r round((Vaccine.ELDI(0.05,0.2,0.5,1/3,0.001,0.002)))`例。

####综合疗效评价(Composite Efficacy Measure)
疫苗不仅能预防针对疾病的发生，也能预防针对疾病引起的感染。综合疗效评价指标既包含了对疾病发生的评价，也包含了疾病的感染的评价。综合疗效评价的样本量可根据$$n=\frac{1}{\mu _{T}p_{T}-\mu_{R}p_{R}}$$$$\begin{bmatrix}z_{1-\alpha /2}\sqrt{2\mu_{*}^{2}p_{*}(1-p_{*})+2p_{*}(\sigma _{T}^{2}+\sigma _{C}^{2})}+z_{1-\beta}\sqrt{p_{T}(\sigma _{T}^{2}+\mu_{T}^{2}(1-p_{T}))+p_{R}(\sigma _{R}^{2}+\mu_{R}^{2}(1-p_{R}))}\end{bmatrix}^{2}$$进行估计,其中$\mu_{T},\mu_{C}$分别为试验组和对照组的均数，$\sigma _{T},\sigma _{C}$分别为试验组和对照组标准差。

例 一研究者计划实施一个疫苗临床试验，与安慰剂对照，主要是表选择相对发病减少率，根据预试验，$\mu_{T}=0.2,\mu_{C}=0.3,p_{T}=0.1,p_{R}=0.2,\sigma _{T}^{2}=\sigma _{C}^{2}=0.15$，在$\alpha=0.05,\beta=0.2$时，两组1：1平行对照，双侧差异性检验需要多少样本量？

```{r}
(Vaccine.CEM(0.05,0.2,0.2,0.3,sqrt(0.15),sqrt(0.15),0.1,0.2))
```
每组需要`r (Vaccine.CEM(0.05,0.2,0.2,0.3,sqrt(0.15),sqrt(0.15),0.1,0.2))`例。
```{r echo=F}
try(detach(package:TrialSize))
try(detach(package:pipeR))
try(detach(package:pander))
try(detach(package:expm))
try(detach(package:koRpus))
try(detach(package:ldbounds))
```

#假设检验
```{r include=FALSE}
library(vcd)
library(pander)
library(psych)
library(ggm)
library(coin)
library(DescTools)
```

假设检验（hypothesis test），就是根据已掌握的资料对一个总体参数是否等于某一个数值，某一随机变量是否服从某种概率分布的假设，然后根据所取得的样本资料，利用一定的统计方法计算出有关检验的统计量，依据一定的概率原则，以较小的风险来判断估计数值与总体数值（或估计分布与实际分布）是否存在显著差异，是否应当接受原假设的一种检验方法。假设检验是根据小概率事件的实际不可能性原理来推断的。假设检验中的小概率标准称为显著性水平，用$\alpha$表示。依据显著性水平的大小将检验统计量的所有可能值组成的样本空间分为两个区域 ：否定域或拒绝域：在原假设成立的情况下，如果检验统计量的值落在这个区域里，则否定原假设。接受域：在原假设成立的情况下，如果检验统计量的值没有落在这个区域里，则接受原假设。 假设检验的步骤:1. 建立统计假设,包括原假设,备择假设。2. 确立合适的检验统计量，确定其分布。3. 规定显著性水平 4. 根据样本观测值计算检验，统计量的取值。5. 判断原假设是否成立。假设检验的四种情况

                          $H_{0}$为真         $H_{0}$为假 
---                      ---                  --- 
接受$H_{0}$              正确决策              第二类错误 $\beta$
拒绝$H_{0}$              第一类错误$\alpha$    正确决策 

第一类错误，也称弃真错误,本来是真的，却根据检验统计量的值把它给否定了。发生这种错误的概率通常用$\alpha$表示。第二类错误，也称取伪错误，本来是假的，却根据检验统计量的值把它给接受了。

##参数假设检验
参数假设检验，是指在总体的分布形式已知的条件下，对总体参数的某一假设进行的检验 。

###正态总体均值的假设检验

####单个总体的情况及实例
当总体分布为正态分布，总体标准差为已知时，检验所使用的检验统计量为$z=\frac{\bar{x}-\mu _{0}}{\sigma _{0}/\sqrt{n}}\sim N(0,1)$。$\sigma$为总体方差，$\mu _{0}$为总体均数，$n$为样本数，$\bar{x}$为样本均数。
在总体方差未知的情况下，用样本方差$S$代替总体$\sigma$,检验统计量为$t=\frac{\bar{x}-\mu _{0}}{S/\sqrt{n}}\sim t(n-1)$

例 某药厂生产一批新的药品，规定直径为10mm,方差为0.4。为了检验机器的性能是否良好，随机抽取了25件产品，测得其平均长度为9.30  9.32 10.41  9.06 10.21  9.31  9.96  9.03 10.22  9.19 10.36  9.67 10.43 10.36  9.83 10.67 10.38 9.29  9.74  9.99  9.98  9.89  9.52  9.88  9.67。假设生产的药品直径服从正态分布，问在显著性水平0.05时，该机器的性能是否良好。
```{r}
z.test<-function(x,sigma,alpha,u0=0,alternative="two.sided"){
  n <- length(x)
  options(digits=4)
  result<-list( )
  mean<-mean(x)
  z<-(mean-u0)/(sigma/sqrt(n))
  p<-pnorm(z,lower.tail=FALSE)
  result$mean<-mean
  result$z<-z
  result$p.value<-p
  if(alternative=="two.sided"){
    p<-2*p
    result$p.value<-p
  }
  else if (alternative == "greater"|alternative =="less" ){
    result$p.value<-p
  }
  else return("your input is wrong")
  result$conf.int<- c(
    mean-sigma*qnorm(1-alpha/2,mean=0, sd=1,
                     lower.tail = TRUE)/sqrt(n),
    mean+sigma*qnorm(1-alpha/2,mean=0, sd=1,
                     lower.tail = TRUE)/sqrt(n))
  result
}

x <- c(9.30,9.32,10.41,9.06,10.21,9.31,9.96,9.03,10.22
       ,9.19,10.36,9.67,10.43,10.36,9.83,10.67,10.38,9.29,
       9.74,9.99,9.98,9.89,9.52,9.88,9.67)

z.test(x,0.4,0.05,10)

```
P值大于0.05,可以该机器的性能良好。

例 假设上提的总体方差未知，假设生产的药品直径服从正态分布，问在显著性水平0.05时，该机器的性能是否良好。
```{r}
t.test(x,alternative = "two.sided",mu=10)#总体方差未知，使用t检验
```
P值大于0.05,可以该机器的性能良好。

####两个总体的情况及实例
两个总体为正态分布，方差已知,检验所使用的检验统计量为$z=\frac{(x_{1}-x_{2})-(u_{1}-u_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}}+\frac{\sigma_{1}^{2}}{n_{2}}}}\sim N(0,1)$

两个总体为正态分布，方差未知,检验所使用的检验统计量为$T=\frac{(x_{1}-x_{2})-(u_{1}-u_{2})}{\sqrt{\frac{S^{2}}{n_{1}}+\frac{S^{2}}{n_{2}}}}\sim t(n_{1}+n_{2}-2)$

例 制药厂试制某种安定神经的新药，两台仪器制造药品服从正态分布，从各自加工药品中，分别取若干个测量其直径，两组直径如下A组 20.5 19.8 19.7 20.4 20.1 20.0 19.0 19.9 B组 20.7 19.8 19.5 20.8 20.4 19.6 20.2，问两台仪器的加工精度有无显著差异？
```{r}
x<-c(20.5, 19.8, 19.7, 20.4, 20.1, 20.0, 19.0, 19.9)
y<-c(20.7, 19.8, 19.5, 20.8, 20.4, 19.6, 20.2)

t.test(x, y, var.equal=TRUE)
```
P值大于0.05,可以两台仪器的加工精度无显著差异。

###总体比例的假设检验
####单样本率的检验
样本率与总体率比较的目的，是推断该样本所代表的未知总体率π与已知总体率$\hat{p}$ 是否不同。 当样本含量$n$足够大，且样本率$p_{0}$ 和$1-p_{0}$均不太小，如 $np_{0}$与$n(1-p_{0})$均大于5 时，样本率的分布近似正态分布统计量$Z=\frac{\hat{p}-p_{0}}{\sqrt{p_{0}(1-p_{0})}}\sim N(0,1)$。当$np_{0}$与$n(1-p_{0})$均小于5时，样本率的分布近似二项分布。

例 按照以往经验，新生儿染色体异常率一般为1%，某医院观察了当地400名新生儿，有一例染色体异常，问该地区新生儿染色体是否低于一般水平？

```{r}
binom.test(1,400,p=0.01,alternative="less")

#样本量较小时，不宜选择prop.test(),有警告！
prop.test(1,400,p=0.01,alternative="less")
```
P值大于0.05，尚不能认为该地区新生儿染色体异常低于一般水平。

####两样本率的检验
两个总体比例$\hat{p_{1}}$和$\hat{p_{1}}$的极大似然估计分别为近似地服从正态分布:
  $Z=\frac{\hat{p_{1}}-\hat{p_{2}}}{\sqrt{(n_{1}+n_{2})\hat{p}(1-\hat{p})/n_{1}n_{2}}}$,$\hat{p}=\frac{n_{1}\hat{p_{1}}+n_{2}\hat{p_{2}}}{n_{1}+n_{2}}$
  
例 某综合医院随机抽取了345个男病例与451个女性病例调查吸烟的暴露情况, 调查结果为187个男性病例与76女性病例中有吸烟的暴露, 能否认为男、女病例吸烟的暴漏一致?

```{r}
s <- c(187,76)
t <- c(345,451)
prop.test(s,t)
```
P值较小，可以认为男女病例的吸烟暴漏情况不同。

两个服从Poisson分布比率，欲检验这两个率是否不同，需要Poisson检验。
例 分别观察了两种疫苗17877与16660个受种者, 结果分别出现2例和9例格林巴利，能否认这两种疫苗接种后发生格林巴利不一致?

```{r}
library(rateratio.test)
rateratio.test(c(2,9),c(17877,16660))

library(exactci)
poisson.exact(c(2,9),c(17877,16660))

poisson.test(c(2,9),c(17877,16660))
```
poisson.test()检验不是Poisson精确检验,参考其他两种方法在$\alpha=0.05$时可以认为接种两种疫苗发生格林巴利的情况基本一致。

##相关性度量
独立性检验评估了变量之间的相互独立情况，如果拒绝原假设，相关性强弱的度量通常用phi系数(Phi-Coefficient)描述$2*2$(四格表)数据相关程度，$\varphi =\sqrt{x^{2}/n}$,$n$总频数；列联系数(Contingency Coefficient)主要用于大于$2*2$的列联表，$C=\sqrt{\frac{x^{2}}{x^{2}+n}}$；Cramer's V系数,$V =\sqrt{\frac{x^{2}}{n*\min[(R-1),(C-1)]}}$;可用vcd包中的assocstats()函数计算。

```{r}
mytable <- xtabs(~Treatment+Improved,data=Arthritis)
assocstats(mytable)
```
总体来说，较大的值意味着较强的相关性。vcd包也提供了一个kappa()函数，可以计算混淆矩阵的Cohen’s kappa值以及加权的kappa值。（混淆矩阵可以表示两位评判者对于一系列对象进行分类所得结果的一致程度。）

###相关
协方差是描述X和Y相关程度的量，定义为$s_{xy}=\frac{1}{n-1}\sum (x_{i}-\bar{x})(y_{i}-\bar{y})$,用于衡量两个变量的总体误差。方差是协方差的一种特殊情况，即当两个变量是相同的情况下。相关系数是中心化与标准化后的协方差，定义为$r=\frac{s_{xy}}{\sqrt{s_{xx}}\sqrt{s_{yy}}}$,用来描述定量变量之间的关系。相关系数避免了协方差量纲的影响，其值的大小表示关系的强弱程度（完全不相关时为0，完全相关时为1），其符号（±）表明关系的方向（正相关或负相关）。
有多种相关系数，其中Pearson积差相关系数衡量了两个定量变量之间的线性相关程度。Spearman等级相关系数则衡量分级定序变量之间的相关程度。Kendall’s Tau相关系数也是一种非参数的等级相关度量。cor()函数可以计算这三种相关系数，而cov()函数可用来计算协方差。Pearson相关检验，适用于正态分布总体的数据，如果总体不服从正态分布，可用秩相关检验。秩相关检验是在成对观测数据的符号检验基础上发展起来的，比传统的单独用正负号的检验更加有效。在R软件中，使用rank()函数计算秩统计量。
###Pearson、Spearman和Kendall相关
除计算相关系数外，对相关系数是否为0进行统计学检验，可以用cor.test()函数对Pearson、Spearman和Kendall相关系数进行统计并完成系数的相关检验。

###Pearson积矩相关系数
Pearson相关用于双变量正态分布的资料，定义为$r=\frac{1}{n-1}\sum _{i=1}^{n}(\frac{x_{i}-\bar{x}}{s_{x}})(\frac{y_{i}-\bar{y}}{s_{y}})$，反映两个变量线性相关程度的统计量。

例 某医生为了探讨缺碘地区母婴TSH水平的关系，应用免疫放射分析测定了160名孕妇（15-17周）及分娩时脐带血TSH水平（mU/L），现随机抽取10对数据，母血TSH1.21 1.30 1.39	1.42 1.47 1.56 1.68	1.72 1.98	2.1,脐血TSH3.90 4.5 4.20	4.83 4.16 4.93 4.32	4.99 4.7 5.2，试对母血TSH水平与新生儿脐带血TSH水平进行相关分析。
```{r}
x <- c(1.21,3.90,1.30,4.50,1.39,4.20,1.42,4.83,1.47,4.16)
y <- c(1.56,4.93,1.68,4.32,1.72,4.99,1.98,4.70,2.10,5.20)
cor.test(x,y)
```
Pearson积差相关系数0.96，P值小于0.05,可以认为母血TSH水平与新生儿脐带血TSH水平相关。

####Spearman秩相关检验
当X和Y相互独立时，$r_{i}$为X产生的秩统计量，$R_{i}$为Y产生的秩统计量，Spearman秩相关系数为$r_{s}=[\frac{1}{n}\sum r_{i}R_{i}-(\frac{n+1}{x})^{2}]/(\frac{n^{2}-1}{12})$
$。

例 两位评分员对新出生的5名新生儿进行Apgar评分，甲：6  7  8  9 10，乙：5  6  7  8 10。试用Spearman秩相关检验方法检验两个评分员对等级评定有无相关关系。
```{r}
x <- c(6,7,8,9,10)
y <- c(5,6,7,8,10)
cor.test(x,y,method = "spearman")
```
Spearman相关系数为1,P值小于0.05，可以认为两位评分员结论有关。

####Kendall秩相关检验

从两变量是否协同（concordant）来检验变量之间的相关性，如果$(x_{j}-x_{i})(y_{j}-y_{i})>0$则对子协同，如果$(x_{j}-x_{i})(y_{j}-y_{i})<0$则对子不协同。Keandall $\tau$相关系数$\hat{\tau }=\frac{n_{d}-n_{c}}{C_{n}^{2}}$,$n_{d}$是不协同的对子数目，$n_{c}$是能够协同的对子数目。

例 欲研究体重和肺活量的关系，调查某地10名初中女生的体重和肺活量如下，进行相关性检验。体重:75 95 85 70 76 68 60 66 80 88,肺活量：2.62 2.91 2.94 2.11 2.17 1.98 2.04 2.20 2.65 2.69。

```{r}
x <- c(75,95,85,70,76,68,60,66,80,88)
y <- c(2.62,2.91,2.94,2.11,2.17,1.98,2.04,2.20,2.65,2.69)
cor.test(x,y,method = "kendall")
```
Kendall秩相关系数为0.68,P值小于0.05，可以认为体重和肺活量是相关的，且为正相关。

###偏相关
偏相关是指在控制一个或多个定量变量时，另外两个定量变量之间的相互关系。可以使用ggm包中的pcor()函数计算偏相关系数,函数调用格式为：pcor(u,S)其中的u是一个数值向量，前两个数值表示要计算相关系数的变量下标，其余的数值为条件变量（即要排除影响的变量）的下标。S为变量的协方差阵。

例 WHO数据集中有每10万人的HIV病人死亡率和医生的数量，试在控制国家后，分析HIV死亡率和当地医生数量是否有关?
```{r}
who <- read.csv("WHO.csv", header = T)
x<- who[,c(2,4,120,291)]
y <- na.omit(x)
pcor(c(2,4,1),cov(y))
```

##独立性检验
独立性检验用于两个或两个以上因素多项分类的计数资料分析，如果要研究的两个因素(又称自变量)或两个以上因素之间是否具有独立性或有无关联或有无“交互作用”的存在，就要应用$\chi ^{2}$独立性检验。如果两个自变量(暂以两个自变量为例)是独立的，即无关联，就意味对其中一个自变量(因素)来说，另一个自变量的多项分类次数上的变化是在取样误差的范围之内。假如两个因素是非独立，则称这二变量之间有关联或有交互作用存在。

例 vcd包中Arthritis数据集包含了关节炎的治疗情况（Treatment）、性别（Sex）和改善情况（Improved），治疗情况和改善情况是否独立？
```{r}
mytable<-xtabs(~Treatment+Improved,data=Arthritis)
mytable
chisq.test(mytable)
```
p值较小，可以认为治疗情况和改善情况不独立。

对于大于2*2二维列联表，可以用Fisher精确检验
```{r}
fisher.test(mytable)
```

###Cochran-Mantel-Haenszel检验
CMH检验可以对一些分层变量进行调整，从而获得反应率的总体比较。最为最为常见的应用是在多中心试验中对研究中心进行调整而进行两组率的比较。

例 vcd包中Arthritis数据集包含了关节炎的治疗情况（Treatment）、性别（Sex）和改善情况（Improved），在性别分层的情况下治疗情况和改善情况是否独立？
```{r}
mytable<-xtabs(~Treatment+Improved+Sex,data=Arthritis)
mytable
mantelhaen.test(mytable)
```
P值较小，分性别来看，治疗情况和改善情况并不独立。

####以最大信息为基础的非参数探索 (MINE，Maximal Information-base Nonparametric Exploration)
该方法用网格判断数据的集中程度，集中程度用最大信息系数(MIC，the Maximal Information Coefficient)表示，传统的相关系数得到结果用MIC值同样可以得到。该方法适用于任何分布的数据类型，不要求成两变量成直线关系。如果MIC值趋进于0,则两变量之间无关，如果MIC趋进于1,则两变量之间有关。

例 WHO数据集中有每10万人的HIV病人死亡率和医生的数量，试分析HIV死亡率和当地医生数量是否有关?

```{r}
who <- read.csv("WHO.csv", header = T)
plot(who$Deaths.due.to.HIV.AIDS..per.100.000.population.per.year., who$Medical_Doctors)
cor.test(who$Deaths.due.to.HIV.AIDS..per.100.000.population.per.year., 
    who$Medical_Doctors, method = "pearson")
```
由于两变量不是线性关系，从线性相关的结果来看，相关性较差。

```{r eval=FALSE}
#调用MINE.jar，Java中列以0开始
col1 <- which(names(who) == "Deaths.due.to.HIV.AIDS..per.100.000.population.per.year.")-1
col2 <- which(names(who) == "Medical_Doctors")-1

source("MINE.r")
MINE("WHO.csv", c(col1, col2))
MINE("WHO.csv", "all.pairs")  #两两比较所有变量
```
```{r}
whoresult <- read.csv("WHO.csv,119-vs-290,cv=0.0,B=n^0.6,Results.csv", 
    header = T)
whoresult$MIC..strength.
```
MIC值大于0.5,说明两变量有一定的相关性，结合绘图的结果，两变量有如下关系：随着医生数量的增加，HIV的死亡率降低，但降低到一定程度后不再继续降低。

###趋势检验
####Cox-Stuart趋势检验
是一种不依赖与趋势结构的快速判断趋势是否存在的方法，它将数据一分为二，形成前后数对，根据数对差值的符号进行判断，如果负值较多，说明数据有增大趋势，如果正值较多，说明数据有减小的趋势。

例 某医院传染病门诊15天的门诊量如下：5 9 12 18 17 16 19 20 4 3 18 16 17 15 14，试问该15天内的门诊量是否有下降的趋势？

```{r}
cox.stuart.test <- function(x) {
    method = "Cox-Stuart test for trend analysis"
    leng = length(x)
    apross = round(leng)%%2
    if (apross == 1) {
        delete = (length(x) + 1)/2
        x = x[-delete]
    }
    half = length(x)/2
    x1 = x[1:half]
    x2 = x[(half + 1):(length(x))]
    difference = x1 - x2
    signs = sign(difference)
    signcorr = signs[signs != 0]
    pos = signs[signs > 0]
    neg = signs[signs < 0]
    if (length(pos) < length(neg)) {
        prop = pbinom(length(pos), length(signcorr), 0.5)
        names(prop) = "Increasing trend, p-value"
        rval <- list(method = method, statistic = prop)
        class(rval) = "htest"
        return(rval)
    } else {
        prop = pbinom(length(neg), length(signcorr), 0.5)
        names(prop) = "Decreasing trend, p-value"
        rval <- list(method = method, statistic = prop)
        class(rval) = "htest"
        return(rval)
    }
}

customers = c(5, 9, 12, 18, 17, 16, 19, 20, 4, 3, 18, 16, 17, 15, 14)

cox.stuart.test(customers)
```

P值大于0.05，接受原假设，可以认为该15天内的门诊量是没有下降的趋势。

####Cochran Armitage 趋势检验
Cochran Armitage 趋势检验也称$\chi^{2}$趋势检验，其目的是说明某一事件发生率是否随着原因变量不同水平的变化而呈线性趋势。

例 下表表示不同年龄血液病患者真菌感染发生情况
年龄   发生   未发生
---    ---    ---
<=29   18     131
30~59  52     232
>=60   26     82

现欲比较患者年龄与真菌感染发生率之间是否存在线性趋势?

```{r}
s1 <- c(18, 52, 26)
s2 <- c(131, 232, 82)
tot = s1 + s2
prop.trend.test(s1, tot)
```
P值小于0.05,拒绝原假设，可以认为血液病患者年龄与真菌感染发生率之间存在变化趋势。

####t检验
亦称student t检验（Student's t test），主要是用于小样本（样本容量小于30）的两个平均值差异程度的检验方法。它是用T分布理论来推断差异发生的概率，从而判定两个平均数的差异是否显著，t检验适用与正态分布资料。检验的调用格式为：t.test(y~x,data)其中的y是一个数值型变量，x是一个二分变量。调用格式或为：t.test(y1,y2)其中的y1和y2为数值型向量（即各组的结果变量）。可选参数data的取值为一个包含了这些变量的矩阵或数据框。

#####单个样本t检验
单个样本t检验又称单样本均数t检验(one sample t test),适用于样本均数与已知总体均数$\mu _{0}$的比较,其比较目的是检验样本均数所代表的总体均数$\mu$是否与已知总体均数$\mu _{0}$有差别,单样t检验的应用条件是总体标准s未知的小样本资料( 如n<50),且服从正态分布。单样本的t检验计算公式为$t=\frac{\bar{X}-\mu _{0}}{s/\sqrt{x}}$

例 某地35名难产儿出生体重为3.38 3.51 4.08 4.44 3.44 3.25 3.49 3.29 3.93 4.06 3.29 2.99 3.87 3.19 3.30 3.45 3.50 3.52 3.01 3.80 3.20 3.64 3.85 4.09 3.53 3.93 3.29 3.70 4.13 3.81 2.96 4.44 3.98 2.82 4.23，一般婴儿出生体重$\mu _{0}$ 3.30（大规模调查获得），问相同否？

```{r}
weight <- c(3.38,3.51,4.08,4.44,3.44,3.25,3.49,3.29,3.93,4.06,3.29,2.99,3.87,3.19,3.30,3.45,3.50,3.52,3.01,3.80,3.20,3.64,3.85,4.09,3.53,3.93,3.29,3.70,4.13,3.81,2.96,4.44,3.98,2.82,4.23)
shapiro.test(weight) #正态性检验
t.test(weight,alternative = "two.side",mu=3.30)
```
P值小于0.05,可以认为两地的出生体重有差异。

#####配对样本均数t检验
配对样本均数t检验简称配对t检验(paired t test),又称非独立两样本均数t检验,适用于配对设计计量资料均数的比较,其比较目的是检验两相关样本均数所代表的未知总体均数是否有差别。配对设计(paired design)是将受试对象按某些重要特征相近的原则配成对子，每对中的两个个体随机地给予两种处理。应用配对设计可以减少实验的误差和控制非处理因素，提高统计处理的效率。配对t检验的公式为$t=\frac{\bar{d}}{s_{d}/\sqrt{n}}$ 配对设计处理分配方式主要有三种情况：①两个同质受试对象分别接受两种处理，如把同窝、同性别和体重相近的动物配成一对，或把同性别和年龄相近的相同病情病人配成一对；②同一受试对象或同一标本的两个部分，随机分配接受两种不同处理；③自身对比(self-contrast)。即将同一受试对象处理（实验或治疗）前后的结果进行比较，如对高血压患者治疗前后、运动员体育运动前后的某一生理指标进行比较。

例 某单位研究饮食中缺乏VE与肝中VA的关系，将同种属的大白鼠按性别相同，年龄、体重相近者配成对子，共8对，并将每对中的两头动物随机分到正常饲料组和VE缺乏组，过一定时期将其处死，测得肝中VA的含量。问不同饲料组大白鼠肝中VA的含量有无差别？

大白鼠对号  1     2	  3	    4	    5	    6	    7	     8
---         ---   ---  ---   ---   ---   ---   ---   ---
正常饲料组  3550  2000	3000	3950	3800	3750	3450	3050
VE缺乏组    2450  2400	1800	3200	3250	2700	2500	1750

```{r}
normal <- c(3550,2000,3000,3950,3800,3750,3450,3050)
ve <- c(2450,2400,1800,3200,3250,2700,2500,1750)
t.test(normal,ve,paired = T)
```
P值小于0.05,可以认为不同饲料组大白鼠中VA含量有差异。

#####两独立样本t检验
两独立样本t 检验(two independent samples  t-test)，又称成组 t 检验，适用于完全随机设计的两样本均数的比较,其目的是检验两样本所来自总体的均数是否相等。完全随机设计是将受试对象随机地分配到两组中，每组对象分别接受不同的处理，分析比较处理的效应。或分别从不同总体中随机抽样进行研究。两独立样本t检验要求两样本所代表的总体服从正态分布且两总体方差相等,即方差齐性(homogeneity of variance, homoscedasticity)。  若两总体方差不等,即方差不齐，可采用t’检验,或进行变量变换,或用秩和检验方法处理。$t=\frac{\bar{x_{1}}-\bar{x_{2}}}{\sqrt{s^{2}/n_{1}+s^{2}/n_{2}}}$,$s^{2}=\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}$

例 25例糖尿病患者随机分成两组，甲组单纯用药物治疗，乙组采用药物治疗合并饮食疗法，二个月后测空腹血糖(mmol/L)甲组8.4 10.5 12 12 13.9 15.3 16.7 18 18.7 20.7 21.1 15.2 乙组 5.4 6.4 6.4 7.5 7.6 8.1 11.6 12.0 13.4 13.5 14.8 15.6 18.7，假设两组方差齐，问两种疗法治疗后患者血糖值是否相同？

```{r}
x <- c(8.4,10.5,12,12,13.9,15.3,16.7,18,18.7,20.7,21.1,15.2)
y <- c(5.4,6.4,6.4,7.5,7.6,8.1,11.6,12.0,13.4,13.5,14.8,15.6,18.7)
shapiro.test(x)
shapiro.test(y)
t.test(x,y,var.equal = T)
```

```{r eval=FALSE}
tIndDf <- data.frame(DV=c(x, y),IV=factor(rep(c("f", "m"), c(length(x),length(y)))))
t.test(DV ~ IV, var.equal=TRUE, data=tIndDf)
```

P值小于0.05,可以认为两种疗法治疗后患者血糖值不相同。
```{r echo=F}
try(detach(package:vcd))
try(detach(package:psych))
try(detach(package:pander))
try(detach(package:ggm))
try(detach(package:coin))
try(detach(package:DescTools))
```

# 回归分析
```{r include=FALSE}
library(pander)
library(ggplot2)
library(pspearman)
library(gvlma)
library(car)
library(lmtest)
library(leaps) 
library(plyr) 
library(bootstrap) 
library(rJava)
library(quantreg)
```
因变量是分类的，则为分类分析，因变量是连续的，称为回归分析。回归分析通过建立函数表达式，用一个或者多个自变量的变化解释或预测因变量，常用于描述、探索和检验自变量和因变量之间因果关系，根据自变量的变化预测因变量的取值。通常按照自变量的个数划分为一元回归和多元回归。按照函数表达式的形式，分为线性回归和非线性回归。

##一元线性回归
假设有两个变量X和Y，X为自变量，Y为因变量。则一元线性回归模型的基本结构形式为$$Y=\beta _{0}+\beta _{1}X+\varepsilon $$。$\varepsilon$是误差项，表示未知或不易测量的随机因素对因变量影响的总和。$\beta _{0}$为回归的常数，$\beta _{1}$为回归系数，它表示增加和减少一个单位时，Y的平均变化量。线性回归就是根据已经观测到的样本数据，应用最小二乘法获得对$\beta _{0}$和$\beta _{1}$的估计，进而得到回归方程。由于参数估计时并不知道是否存在线性关系，回归方程在应用前需要完成对回归方程的检验，即对回归模型的系数是否为零进行检验。常用t检验、F检验和相关系数检验评价回归方程的回归系数是否为0。
线性回归应用有四个前提条件：线性、独立、正态和方差齐性。线性指自变量和因变量在散点图大致呈直线趋势。独立性值观察值之间应相互独立。正态性指残差应符合正态分布。方差齐性指在自变量取值范围内，对于自变量的取值，因变量都有相同的方差。

例1 某医生分别采用盐析法和结合法测定正常皮肤中胶原蛋白的含量。盐析法只能部分提纯，结合法较为复杂单精确。该医生欲寻求找盐析法和结合法之间的关系，以便通过盐析法预测结合法的测定值。

编号   盐析法   结合法
---    ---      ---
1      6.8      546
2      7.8      553
3      8.7      562
4      8.7      563
5      8.9      570
6      9.5      575
7      10.1     581
8      10.2     605
9      10.3     607
10     10.4     621
11     11.1     624
12     12.4     626
13     13.3     632
14     13.1     640
15     13.2     656
 

解 做散点图，观察是否存在线性关系。由于线性回归的条件（线性、正态性、方差齐性和独立性）是通过残差来完成的，可先建立回归方程，然后通过回归诊断来完成线性回归条件的检验。
线性条件可通过散点图直接观察。
```{r}
y <- c(546,553,562,563,570,575,581,605,607,621,624,626,632,640,656)
x <- c(6.8,7.8,8.7,8.7,8.9,9.5,10.1,10.2,10.3,10.4,11.1,12.4,13.3,13.1,13.2)
df <- as.data.frame(cbind(x,y))

#ggplot(df,aes(x,y))+geom_point()+stat_smooth(method = "lm")
plot(x,y)
```
通过散点图，可以发现二者近似直线关系，符合线性条件。

对数据进行线性回归分析。
```{r}
model <- lm(y~x) #~左边为响应变量，右边为各个预测变量，预测变量之间用+符号分隔
summary(model)
```
结果中Coefficients是参数估计的结果。结果显示，截距项和回归系统均有统计学意义。模型简单评价$R^{2}$为0.9017，校正决定系数$R_{adj}^{2}$为0.9841。决定系数越大表明自变量对因变量的解释程度越高。F检验检验所有的预测变量预测响应变量是否都在某个几率水平之上，结果表明(F=119.2,P=6.426e-08),方程总体有统计学意义。残差的标准误则可认为模型用自变量预测因变量的平均误差。
所建立的方程为
Y=426.625+16.580×X
对估计值做出区间估计

```{r}
confint(model)
```

```{r}
plot(df$x,df$y)
abline(model)
```
###模型评价

####回归诊断 
主要包括三方面：（1）误差项是否满足独立性、等方差性和正态性，选择模型是否合适。（2）是否存在异常样本，回归分析的结果是否对某些样本依赖过重，即回归模型是否具备稳定性。（3）自变量之间是否存在高度相关，即是否有多重共线性问题存在。

```{r}
par(mfrow=c(2,2))
plot(model) 
par(mfrow=c(1,1))
```
标准方法
正态性 当预测变量值固定时，因变量成正态颁，则残差图也应是一个均值为0的正态颁。正态Q-Q图是在正态颁对应的值上，标准化残差的概率图，若满足正态假设，则图上的点应该落在45度角的直线上，若不是，则违反了正态性假设。第二幅Normal QQ-plot图中数据点分布趋于一条直线, 说明残差是服从正态分布的。

独立性 无法从图中分辨因变量值是否相互独立，只能从收集的数据中验证。本例中适用结合法进行测量时，无理由相信一个测量结果会影响另外一次的测量。

线性 若因变量与自变量线性相关，则残差值与预测（拟合）值就没有系统关联，若存在关系，则说明可能城要对回归模型进行调整。第一幅图Residual vs fitted为拟合值y对残差的图形, 可以看出,数据点都基本均匀地分布在直线y=0的两侧, 无明显趋势，满足线性假设。

方差齐性 若满足不变方差假设，则在第三幅图位置尺度图（Scale-Location Graph）中，水平线周围的点应随机分布，Scale-Location 图显示了标准化残差(standardized residuals)的平方根的分布情况，最高点为残差最大值点。第三副图显示基本符合方差齐性的要求。

第四幅图（Residuals vs Leverage）提供了单个观测点的信息，从图中可以鉴别离群点、高高杆值点和强影响点。

改进方法

正态性 通过对残差正态性检验予以证实。
```{r}
model <- lm(y~x)
shapiro.test(residuals(model))
```
正态性检验结果表明W值为`r shapiro.test(residuals(model))$statistic`，P值为`r shapiro.test(residuals(model))$p.value`,残差符合正态分布。

独立性 判断因变量（或残差）最好的方法时依据收集数据的方式的先验知识。lmtest包提供了dwtest检验函数，car包提供了Durbin-Watson检验的函数，都能够检验误差序列的相关性。
```{r}
dwtest(model)
#durbinWatsonTest(model)
```
本例结果P值比较显著，但根据先验知识，并不能否定因变量的独立性。

线性 可通过成分残差图(component plus residual plot)即偏残差图(partial residual plot)，判断因变量与自变量之间是否呈非线性关系，也可以看是否不同于已设定线性模型的系统偏差，图形可用car包中crPlots()函数绘制。图形存在非线性，则说明可能对预测变量的函数形式建模不够充分.
```{r}
crPlots(model) 
```
图形呈现线性，建模比较充分。car包中提供了一个linearHypothesis()函数可以自动的进行线性假设检验,比图形更为精准。根据对模型的设定，这个函数既可以用一般的方法或调整后的协方差矩阵进行F或Wald检验。
```{r}
linearHypothesis(model, "x=0") #x的系数是否为0
# tests Beta1 = Beta2
#linear.hypothesis(fit,"x1 = x2") 
# Tests  Beta0 = Beta1 = Beta2= 1
#linear.hypothesis(fit,c("(Intercept)", "x1","x2"),rep(1,3)) 
# Tests  Beta0 = Beta1 = Beta2 = 0
#linear.hypothesis(fit,c("(Intercept)", "x1","x2"),rep(0,3)) 
# Tests Beta1 = Beta2 = 0
#linear.hypothesis(fit,c("x1","x2"),rep(0,2)) 
```
P值小于0.05，可以认为x的系数不为0。


方差齐性 通过以因变量为x轴，学生化残差为y轴做残差图，进行判断。
```{r}
plot(predict(model),rstudent(model))
```
所有的学生化残差均在$\pm 2$在范围内波动，没有明显的上升或下降趋势，可以认为符合方差齐性。还通过自变量与残差绝对值的等级相关检验来判断。

```{r}
spearman.test(x,abs(residuals(model))) #R中pspearman包中的spearman.
#test函数可以完成斯皮尔曼等级相关检验

#cor.test(x,abs(residuals(model)),method="spearman") #或者用cor.test()
```
自变量与残差绝对值的等级相关系数为`r cor.test(x,abs(residuals(model)),method="spearman")$p.value`,P值大于0.05，无统计学意义，可以认为残差方差齐性。

car包提供了两个有用的函数，可判断误差方差是否恒定，ncvTest()函数生成一个计分检验，零假设为误差方差不变,备择假设为误差方差随着拟合值水平的变化而变化。若检验显著，择说明存在异方差性。spreadLevelPlot()函数创建一个添加了最佳拟合曲线的散点图，展示标准化残差绝对值与拟合值的关系。
```{r}
ncvTest(model)  
spreadLevelPlot(model) 
```
计分检验结果不显著，说明满足方差齐性的假设。通过水平分布图，可以看到其中的点在水平的最佳拟合曲线周围呈水平随机分布。若违反了该假设，将会呈现一个非水平的曲线。


线性模型假设的综合验证
```{r}
gvlma(model)
```
Global Stat给模型假设提供了一个单独的综合检验（通过/不通过），本例中，可以看到数据满足线性回归模型所有的统计假设（P=0.7071）。同时还对偏度(Skewness)、峰度(Kurtosis)、连接函数(Link function)和异方差性(Heteroscedasticity)进行了评价。

####影响分析
是探查对估计有异常影响的数据，如果一个样本不服从某个模型，其余数据服从这个模型，则称该样本点为强影响点。影响分析就是区分这样的样本数据。

#####离群点
指那些模型预测效果不佳的观测点，通常有很大的、或正或负的残差，正残差说明模型低估了响应值，负残差说明高佑了响应值。

```{r}
outlierTest(model) #Bonferroni离群点检验
qqPlot(model,labels=row.names(df),id.method = "identify",simulate=T,main="QQPlot") #car包
```
outlierTest（）函数是根据单个最大（或正或负）残差值的显著性来判断是否有离群点，若不显著，则说明数据集中没有离群点，若显著，则必须删除该离群点，然后再检验是否还有其他离群点存在。qqPlot图中落在置信区间带外的点可被认为时离群点。本例中未发现有离群点。

#####高杠杆值点
是与其他预测变量有关的离群点，即它们是由许多异常的预测变量组合起来的，与响应变量值没有关系。
高杠杆值的观测点可通过帽子矩阵的值（hat statistic）判断。对于一个给定的数据集，帽子均值为p/n，其中p是模型估计的参数数目（包含截距项），n是样本量。一般来说，若观测点的帽子值大于帽子均值的2或3倍，则可认定为高杠杆值点。
```{r}
 hat.plot<-function(fit){  
  p<-length(coefficients(fit))  
  n<-length(fitted(fit))  
  plot(hatvalues(fit),main="Index Plot of Hat Values")  
  abline(h=c(2,3)*p/n,col="red",lty=2)  
  identify(1:n,hatvalues(fit),names(hatvalues(fit)))  
}  
hat.plot(model) 
```
此图中可以看到1号点是高杠杆值点。

#####强影响点
强影响点，即对模型参数估计值影响有些比例失衡的点。例如，当移除 模型的一个观测点时模型会发生巨大的改变，那么需要检测一下数据中是否存在强影响点。Cook距离，或称为D统计量。Cook's D值大于4/(n-k-1)，则表明它是强影响点，其中n为样本量大小，k是预测变量数目（有助于鉴别强影响点，但并不提供关于这些点如何影响模型的信息）。
```{r}
plot(model,which=4)
```
Cook距离(Cook’s distance)图显示了对回归的影响点。根据Cook距离，13号点可能是个强影响点。

帽子统计量、DFFITS准测、Cook统计量和COVRATIO准则在R软件可分别通过hatvalues(),dffits(),cooks.distance()和covration()函数计算。influence.measures()可对一次获得这四个统计量的结果。
影响分析综合分析 
```{r}
influencePlot(model) 
#car包中的influencePlot（）函数，可将离群点、
#杠杆点和强影响点的信息整合到一幅图形中
influence.measures(model)
```
纵坐标超过2或小于-2的州可被认为是离群点，水平轴超过0.2或0.3的州有高杠杆值（通常为预测值的组合）。圆圈大小与影响成比例，圆圈很大的点可能是对模型估计造成的不成比例影响的强影响点。influence.measures()的inf用×标注异常值。

###共线性，条件数 
本例只有一个自变量，不涉及。

###预测新值及其置信区间
把预测变量数据保存为一个数据框，调用predict函数，将数据框做为参数。
```{r}
preds <- data.frame(x=14)
#默认0.95的置信水平，可通过level改变
predict(model,newdata = preds,interval = "prediction") 
```
###改进措施
```{r}
model2 <- lm(y~x,subset=-1)
gvlma(model2)
influence.measures(model2)
```
提示2号点也是是个异常值。
```{r}
model3 <- lm(y~x,subset=c(-1,-2))
gvlma(model3)
influence.measures(model3)
```
删除1、2观测值后，模型的影响分析的结果变得更好。但应该对删除观测点的方法谨慎，因为收集数据的异常点可能是最有意义东西，除非确定数据点时记录错误或者没有相关遵守规程。

##多元线性回归
例２　某项“冠状动脉缓慢血流现象”的影响因素的研究，以前降支、回旋支、右冠状动脉三支血管的平均TIMI帧基数(MTFC)表示，调查的影响因素有年龄(AGE,岁)、收缩压(SBP,mmHg)、舒张压(DBP,mmHg)、白细胞(WBC,$10^{2}$/L),寻找影响MTFC变化的因素。

age sbp dbp wbc   mtfc
--- --- --- ---   ---
43  110 50	6.19	33.67
63	105	60	6.03	26.67
59	100	60	5.28	23
78	100	60	6.52	26
67	100	60	7.31	28
65	119	61	5.67	30.33
66	120	64	5.11	27
73	130	88	6.40  47
53	113	68	4.41	27.67
76	120	70	4.20	37.33
76	136	70	5.38	35.67
76	130	70	4.94	31.33
68	126	70	4.56	32.33
61	136	70	5.42	30.67
78	124	70	5.75	37.67
80	110	70	4.68	36
74	140	70	8.67	41
75	130	70	6.62	41.67
66	130	70	6.86	22
55	114	70	7.52	23.33
71	120	70	4.94	25.67
62	130	70	4.59	25
69	130	70	4.26	27
45	110	70	10.21	29
79	120	70	6.46	30.33
58	110	70	4.70	27
65	100	70	6.06	28
44	119	70	5.55	22.33
53	110	70	14.0	29.33
62	130	72	7.29	43
62	118	72	3.97	27.33
53	122	74	3.97	18.33
71	130	75	3.78	31
54	116	75	4.35	22.33
64	120	76	6.59	30
71	140	78	5.70	35.67
50	121	78	5.27	40.33
51	138	80	5.65	34.67
73	130	80	7.45	35.33
64	138	80	6.58	33.67
40	130	80	7.51	35.33
72	120	80	4.42	34
51	100	80	7.85	21
49	120	89	5.14	20.67
63	150	90	8.18	42.67
56	130	90	5.23	30.67
69	160	90	7.10	39
78	130	90	6.03	29
78	120	90	4.52	30.67
61	150	92	7.52	40
76	142	92	4.66	38
51	140	100	5.70	28.33
51	140	100	6.71	42.67
57	160	100	6.14	41
63	190	100	5.25	46
69	150	80	6.33	22.67

```{r warning=FALSE}
records <- read.table("example1")
ex <- rename(records, c("V1"="age","V2"="sbp","V3"="dbp","V4"="wbc","V5"="mtfc"))
attach(ex)
#scatterplotMatrix()函数默认在非对角线区域绘制变量间的散点图，并添加平滑（loess）和线性拟合区间
scatterplotMatrix(ex,spread=F,lty.smooth=2,main="scatter plot matrix")
```
绘制因变量与自变量的散点图矩阵显示mtfc和wbc线性关系不是很好。首先做单因素的线性回归，尽管有时候单因素的分析不是必须的，其结果也不一定可靠，但有助于初步探索自变量和因变量之间的关系。
```{r}
summary(lm(mtfc~age,data = ex))
summary(lm(mtfc~sbp,data = ex))
summary(lm(mtfc~dbp,data = ex))
summary(lm(mtfc~wbc,data = ex))
summary(lm(mtfc~age+sbp+dbp+wbc,data = ex))
```
分析结果表明，单因素分析中dbp有统计学，而多因素分析中却没有统计学意义。分析自变量的相关系数
```{r}
cor(ex[1:4])
cor.test(ex$dbp,ex$sbp)
```
相关分析结果表明sbp和dbp有明显的正相关作用，说明单因素分析中dbp对因变量的作用同时包含了部分sbp的正向作用。在删除dbp变量，继续建模。
```{r}
summary(lm(mtfc~age+sbp+wbc,data = ex))
```
结果显示三个因素均有统计学意义，F检验也通过了，但决定系数较低，说明自变量对因变量的解释程度较低。查看wbc变量估计结果，其标准误为0.44远高于age和sbp变量，计算这三个变量的变异系数。
```{r}
cv <- function(x){
  return(100*sd(x)/mean(x))
}

cv(age)
cv(sbp)
cv(wbc)
```
wbc变量的变异系数远高于其他连个变量，为减少wbc变量的变异，对其进行对数变换后重新建模
```{r}
fit <- lm(mtfc~age+sbp+log10(wbc),data = ex)
summary(fit)
gvlma(fit)
influence.measures(fit)
```
所建立的模型通过回归诊断，影响分析存在异常点，但没有理由怀疑是异常点所以予以保留。

###多重共线性
指线性回归模型中的解释变量之间由于存在精确相关关系或高度相关关系而使模型估计失真或难以估计准确。一般来说，由于数据的限制使得模型设计不当，导致设计矩阵中解释变量间存在普遍的相关关系目前常用的多重共线性诊断方法
1.自变量的相关系数矩阵R诊断法：研究变量的两两相关分析，如果自变量间的二元相关系数值很大，则认为存在多重共线性。但无确定的标准判断相关系数的大小与共线性的关系。有时，相关系数值不大，也不能排除多重共线性的可能。

2.方差膨胀因子（the variance inflation factor，VIF)诊断法：方差膨胀因子表达式为：$VIF_{i}=1/（1-R^{2}_{i})$。其中Ri为自变量$x_{i}$对其余自变量作回归分析的复相关系数。当$VIF_{i}$很大时，表明自变量间存在多重共线性。该诊断方法也存在临界值不易确定的问题，在应用时须慎重。

3.容忍值（Tolerance，简记为Tol）法：容忍值实际上是VIF的倒数，即Tol＝1/VIF。其取值在0～1之间，Tol越接近1，说明自变量间的共线性越弱。在应用时一般先预先指定一个Tol值，容忍值小于指定值的变量不能进入方程，从而保证进入方程的变量的相关系数矩阵为非奇异阵，计算结果具有稳定性。但是，有的自变量即使通过了容忍性检验进入方程，仍可导致结果的不稳定。

4.多元决定系数值诊断法：假定多元回归模型p个自变量，其多元决定系数为R2y（X1，X2,…，Xp）。分别构成不含其中某个自变量（$x_{i}$,i=1,2,…，p）的p个回归模型，并应用最小二乘法准则拟合回归方程，求出它们各自的决定系数$R^{2}_{i}（i=1,2,…，p）$。如果其中最大的一个R2k与R2Y很接近，就表明该自变量在模型中对多元决定系数的影响不大，说明该变量对Y总变异的解释能力可由其他自变量代替。它很有可能是其他自变量的线性组合。因此，该自变量进入模型后就有可能引起多重共线性问题。该方法也存在临界值和主观判断问题。

5.条件数与特征分析法：在自变量的观测值构成的设计矩阵X中，求出变量相关系数R的特征值，如果某个特征值很小（如小于0．05 ），或所有特征值的倒数之和为自变量数目的5倍以上，表明自变量间存在多重共线性关系。利用主成分分析，如果X′X的特征值RK小于0．05时，RK所对应的主成分FK可近似为零，表明自变量间存在K个多重共线性关系。 

从实际经验的角度,一般若条件数<100,则认为多重共线性的程度很小,若100<=条件数<=1000,则认为存在中等程度的多重共线性,若条件数>1000,则认为存在严重的多重共线性。kappa大于1000，或vif大于10说明存在多重共线性。在R中判断多重共线性的命令为kappa（条件数），vif（方差膨胀因子）

```{r}
kappa(cor(ex))
vif(fit) #car包
sqrt(vif(fit)) > 2
```
一般来说kappa大于1000，或vif大于10说明存在多重共线性,vif开平方是否大于2，若大于2，则存在多重共线性问题。本例中未发现存在多重共线性。

###模型比较
AIC(Akaike Information Criterion,赤池信息准则)也可以用来比较模型,它考虑了模型的统计拟合度以及用来拟合的参数数目。AIC值越小的模型要优先选择,它说明模型用较少的参数获得了足够的拟合度。

```{r}
fit2 <- lm(mtfc~age+sbp+wbc,data=ex)
AIC(fit,fit2)
```
选择AIC值较小的模型lm(mtfc~age+sbp+log10(wbc))。

尽管log10(wbc)回归系数最高，但并不代表log10(wbc)对mtfc的影响最大，因为三个变量的单位不同。对于不同的单位，如果要衡量对因变量大小的影响，需采用标准化回归系数。
```{r}
lm.beta <- function(MOD) 
{
  b <- summary(MOD)$coef[-1, 1]
  sx <- sapply(MOD$model[-1], sd)
  sy <- sapply(MOD$model[1], sd)
  beta <- b * sx/sy
  return(beta)
}
lm.beta(fit)
detach(ex)
```
尽管通过模型比较，获得了lm(mtfc~age+sbp+log10(wbc))模型，模型的回归诊断也能通过，但从决定系数来看自变量对因变量的解释程度并不高。

##逐步回归
实际中，影响因变量的自变量较多，对如何从自变量中选择若干个，得到最佳的回归方程，在不同的准则下有不同的方法来获得最佳回归方程。对于一个包含n个自变量的的回归问题，全部的回归模型将有$2^{n}-1$个。常用的逐步方法有“向前法”，“向后法”，“逐步法”和“最优子集法”。在R中，通过step()函数的direction = c("both", "backward", "forward")选项分别完成“逐步回归法”、“向后法”和“向前法”。leaps包可以完成全子集回归法,leaps()函数以$C_{p}$准则（默认）、校正$R^{2}$和$R^{2}$来选择全局最优模型。

例 有5个自变量x1～x5和1个因变量，请完成自变量的筛选。
```{r}
x1<- c(7,1,11,11,7,11,3,1,2,21,1,11,10)
x2<- c(26,29,56,31,52,55,71,31,54,47,40,66,68)
x3<- c(6,15,8,8,6,9,17,22,18,4,23,9,8)
x4<- c(60,52,20,47,33,22,6,44,22,26,34,12,12)
y<- c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,93.1,115.9,83.8,113.3,109.4)
df <- as.data.frame(cbind(x1,x2,x3,x4,y))

leapmodels <- leaps(x = cbind(x1,x2,x3,x4),y = y)
plot(leapmodels$size, leapmodels$Cp)
abline(0,1)
cbind(leapmodels$size,leapmodels$which, leapmodels$Cp)
```
选择$C_{p}$统计量最小的变量集合，本例中$C_{p}$统计量最小值所对应的变量集合为x1和x2。结果中1为选中，0为未选中。
```{r}
subsets <- regsubsets(y~x1+x2+x3+x4,data=df)
summary(subsets)
plot(subsets,scale="adjr2") #基于调整R平方，不同子集大小的最佳模型
```
图的顶部的图形便是最适合的模型，校正R平方值0.98最高，x1和x2两预测变量是最佳模型。也可以通过$C_{p}$统计量完成变量的选择。
```{r}
sbs<- regsubsets(y~x1+x2+x3+x4,data=df)
subsets(sbs,legend=FALSE,statistic="cp",main="cp plot for all subsets regression")
abline(1,1,lty=2,col="red") #画截距项和斜率均为1的直线
summary(sbs)
```
$C_{p}$图越好的模型离截距项和斜率均为1的直线越近，x1-x2、x1-x2-x4和x1-x2-x3-x4均与直线比较接近，这三个模型根据$C_{p}$统计量结果类似。

```{r}
fit <- lm(y~x1+x2+x3+x4,data=df)
fit.step <- step(fit)  #基于AIC
summary(fit.step)
```
step()函数通过AIC信息准则，删除了x3变量后AIC值最小24.97，得到y ~ x1 + x2 + x4。回归系数的显著性检验水平有较大提升，但x2和x4的系数检验仍不理想。
```{r}
drop1(fit.step)
```
去掉x4后，AIC值会上升到25.42，残差的平方和会上升到9.93，是上升最少的。去掉x4后
```{r}
lm.opt<-lm(y ~ x1+x2, data=df)
summary(lm.opt)
gvlma(lm.opt)
influence.measures(lm.opt)
sqrt(vif(lm.opt)) > 2
```
检验结果显著，回归诊断和多重共线性均通过，影响分析中只发现有一个异常点。因为全子集回归考虑了更多模型，全子集回归要优于逐步回归，但当自变量个数较多时，全子集回归较慢。一般来所，变量的自动筛选应建立在背景知识理解基础上进行，防止出现拟合效果好，但没有实际意义的模型。

##交叉验证
就是按一定比例将原始数据按照拆分成训练集和测试集，现在训练集上获取回归方程，然后在测试集上做预测。由于测试集不涉及模型参数的选择，该样本可获得比新数据获得更为精确的估计。$k$重交叉验证中，样本被分为$k$个子样本，轮流将$k-1$个子样本作为训练集，另外1个样本作为测试集。通过获得$k$个预测方程，记录$k$个测试集的预测结果，然后求其平均值。

```{r}
shrinkage<-function(fit,k=5){  
  require(bootstrap)  
  theta.fit<-function(x,y){lsfit(x,y)}  
  theta.predict<-function(fit,x){cbind(1,x)%*%fit$coef}  
  x<-fit$model[,2:ncol(fit$model)]  
  y<-fit$model[,1]  
  results<-crossval(x,y,theta.fit,theta.predict,ngroup=k)  
  r2<-cor(y,fit$fitted.values)^2  
  r2cv<-cor(y,results$cv.fit)^2  
  cat("Original R-square=",r2,"\n")  
  cat(k,"Fold Cross-Validated R-square=",r2cv,"\n")  
  cat("Change=",r2-r2cv,"\n")  
}  

fit <- lm(y~x1+x2,data=df)
shrinkage(fit)
```
获得原始R平方为0.9786,交叉验证后的R平方为0.9962（基于BootStrap方法，每次运行结果会有不同）。R平方减少得越少，预测越精准。

##相对重要性
评价自变量相对重要性，最简单的方法为比较标准化的回归系数，它表示当其他自变量不变时，该自变量变化1个单位引起的因变量的变化。前面通过lm.beta()函数获得了标准化的回归系数。基于相对权重的重要性测量，是对所有可能自模型添加一个自变量引起的R平方平均增加量的一个近似值，比标准化回归系数更为直观。

```{r}
relweights<-function(fit,...){  
  R<-cor(fit$model)  
  nvar<-ncol(R)  
  rxx<-R[2:nvar,2:nvar]  
  rxy<-R[2:nvar,1]  
  svd<-eigen(rxx)  
  evec<-svd$vectors  
  ev<-svd$values  
  delta<-diag(sqrt(ev))  
  lambda<-evec%*%delta%*%t(evec)  
  lambdasq<-lambda^2  
  beta<-solve(lambda)%*%rxy  
  rsquare<-colSums(beta^2)  
  rawwgt<-lambdasq%*%beta^2  
  import<-(rawwgt/rsquare)*100  
  lbls<-names(fit$model[2:nvar])  
  rownames(import)<-lbls  
  colnames(import)<-"Weight"  
  barplot(t(import),names.arg=lbls, 
          ylab="% of R-Square",  
          xlab="Predictor Variables",  
          main="Relative Importance of Predictor Variables",  
          sub=paste("R-Square=",round(rsquare,digits=3)),...)  
  return(import)  
}  
fit <- lm(y~x1+x2,data=df)
relweights(fit,col="lightgrey")  
```

可以看到x2解释了56.7%的R平方，x1解释了43.2的平方，x2相比x1更为重要。

##分位数回归
传统的线性回归模型描述了因变量的条件均值分布受自变量的影响过程。最小二乘法是估计回归系数的最常用的方法。如果模型的随机误差项来自均值为零、方差相同的分布，那么模型回归系数的最小二乘估计为最佳线性无偏估计（BLUE）；如果随机误差项是正态分布，那么模型回归系数的最小二乘估计与极大似然估计一致，均为最小方差无偏估计（MVUL）。分位数回归(Quantile Regression)利用解释变量的多个分位数（例如四分位、十分位、百分位等）来得到被解释变量的条件分布的相应的分位数方程。与传统的OLS只得到均值方程相比，它可以更详细地描述变量的统计分布。
在数据出现尖峰或厚尾的分布、存在显著的异方差等情况，传统的线性回归模型的假设常常不被满足，最小二乘法估计将不再具有上述优良性且稳健性非常差。最小二乘回归假定自变量只能影响因变量的条件分布的位置，但不能影响其分布的刻度或形状的任何其他方面。分位数回归依据因变量的条件分位数对自变量进行回归，这样得到了所有分位数下的回归模型。因此分位数回归相比普通最小二乘回归只能描述自变量对于因变量局部变化的影响而言，更能精确地描述自变量对于因变量的变化范围以及条件分布形状的影响。分位数回归能够捕捉分布的尾部特征，当自变量对不同部分的因变量的分布产生不同的影响时．例如出现左偏或右偏的情况时。它能更加全面的刻画分布的特征，从而得到全面的分析，而且其分位数回归系数估计比OLS回归系数估计更稳健。

例 quantreg包中自带数据集engel描述了食物支出与家庭收入之间关系，其数据格式如下，请完成分位数回归。
```{r}
data(engel,package = "quantreg")
pander(head(engel))
```

```{r}
#进行分位数回归
fit = rq(foodexp ~ income, tau = c(0.1,0.25,0.5,0.75,0.9), 
         data = engel,method = "br")  
summary(fit)
# 通过设置参数se，可以得到系数的假设检验
summary(fit, se = "nid")  
plot(fit)
```
tau表示计算多个分位点的分位数回归结果，如tau = c(0.25,0.5,0.75)是同时计算25%、50%、75%分位数下的回归结果。method：进行拟合的方法，取值包括：默认值“br”，表示 Barrodale & Roberts算法的修改版；“fn”，针对大数据可以采用的Frisch–Newton内点算法；“pfn”，针对特别大数据，使用经过预处理的Frisch–Newton逼近方法；“fnc”，针对被拟合系数特殊的线性不等式约束情况； “lasso”和“scad”，基于特定惩罚函数的平滑算法进行拟合。 se = “rank”: 按照Koenker(1994)的排秩方法计算得到的置信区间，默认残差为独立同分布。注意的是，上下限是不对称的。se=”iid”: 假设残差为独立同分布，用KB（1978）的方法计算得到近似的协方差矩阵。se = “nid”: 表示按照Huber方法逼近得到的估计量。se=”ker”:采用Powell(1990)的核估计方法。se=”boot”:采用bootstrap方法自助抽样的方法估计系数的误差标准差。

###穷人和富人的消费比较
```{r}
data(engel,package = "quantreg")
z=rq(foodexp~income,tau=-1,data = engel) #tau不再[0,1]时，表示按最细分位点划分
x.poor=quantile(income,0.1) #10%分位点的收入，穷人
x.rich=quantile(income,0.9) #90%分位点的收入，富人
ps=z$sol[1,] #每个分位点的tau值
qs.poor=c(c(1,x.poor)%*%z$sol[4:5,]) #穷人的消费估计值
qs.rich=c(c(1,x.rich)%*%z$sol[4:5,]) #富人的消费估计值
par(mfrow=c(1,2))
# type=”n”表示初始化图形区域，但不画图
plot(c(ps,ps),c(qs.poor,qs.rich),type="n",     
     xlab=expression(tau), ylab="quantile")
plot(stepfun(ps,c(qs.poor[1],qs.poor)), do.points=F,
     add=T)
plot(stepfun(ps,c(qs.poor[1],qs.rich)), do.points=F,
     add=T, col.hor="gray", col.vert="gray")

ps.wts = ( c(0,diff(ps)) + c(diff(ps),0) )/2
ap = akj(qs.poor, z=qs.poor, p=ps.wts)
ar = akj(qs.rich, z=qs.rich, p=ps.wts)
plot(c(qs.poor,qs.rich), c(ap$dens, ar$dens),
     type="n", xlab="Food Expenditure", ylab="Density")
lines(qs.rich,ar$dens,col="gray")
lines(qs.poor,ap$dens,col="black")
legend("topright", c("poor","rich"), lty=c(1,1),
       col=c("black","gray"))
par(mfrow=c(1,1))
```
穷人和富人的食品消费支出有明显的不同，穷人在不同分位点食品消费支出差别不大，富人不同分位点食品消费支出差别较大。右图表示，穷人消费支出集中于400左右，富人消费支出集中于800～1200。

###模型比较
```{r}
# 比较不同分位点下，收入对食品支出的影响机制是否相同
fit1 = rq(foodexp ~ income, tau = 0.25, data = engel)
fit2 = rq(foodexp ~ income, tau = 0.5, data = engel)
fit3 = rq(foodexp ~ income, tau = 0.75, data = engel)
anova(fit1,fit2,fit3)
```
P值远小于0.05，故不同分位点下收入对食品支出的影响机制不同。

不同分位点拟合曲线比较
```{r}
plot(engel$income,engel$foodexp,cex=0.25,type = "n",
     xlab = "Household Income",ylab = "Food Expenditure")
points(engel$income,engel$foodexp,cex=0.5,col="blue")
abline(rq(foodexp~income,tau = 0.5,data=engel),col="blue")
abline(lm(foodexp~income,data=engel),lty=2,col="red")
taus=c(0.1,0.25,0.75,0.9)
for(i in 1:length(taus)){
  abline(rq(foodexp~income,tau=taus[i],data = engel),col="gray")
}
```

###残差形态检验
```{r}
#位值漂移模型：不同分位点估计结果之间的斜率相同或相近，截距不同
KhmaladzeTest(foodexp ~ income, data = engel, 
              taus = seq(.05,.95,by = .01),nullH = "location")
KhmaladzeTest(foodexp ~ income, data = engel, 
              taus = seq(.05,.95,by = .01),nullH = "location",se="ker")
#位置-尺度漂移模型：不同分位点估计结果斜率和截距都不同
KhmaladzeTest(foodexp ~ income, data = engel, 
              taus = seq(.05,.95,by = .01),nullH = "location-scale")
KhmaladzeTest(foodexp ~ income, data = engel, 
              taus = seq(.05,.95,by = .01),nullH = "location-scale",se="ker")
```
Tn表示模型整体检验，THn表示每个自变量的检验。位值漂移模型的Tn值比位置-尺度漂移模型的Tn值大，拒绝位值漂移模型的概论较大，位值-尺度漂移模型更加合适。

###分位数回归的分解
分位数分解法对各个影响因素进行分解分析
```{r warning=F}
# MM2005分位数分解的函数
MM2005 = function(formu,taus, data, group, pic=F){
  # furmu 为方程，如foodexp~income
  # taus 为不同的分位数
  # data 总的数据集
  # group 分组指标，是一个向量，用于按行区分data
  # pic 是否画图，如果分位数比较多，建议不画图
  engel1 = data[group==1,]
  engel2 = data[group==2,]
  # 开始进行分解
  fita = summary( rq(formu, tau = taus, data = engel1 ) )
  fitb = summary( rq(formu, tau = taus, data = engel2 ) )
  tab = matrix(0,length(taus),4)
  colnames(tab) = c("分位数","总差异","回报影响","变量影响")
  rownames(tab) = rep("",dim(tab)[1])
  for( i in 1:length(taus) ){
    ya = cbind(1,engel1[,names(engel1)!=formu[[2]]] ) %*% fita[[i]]$coef[,1]
    yb = cbind(1,engel2[,names(engel2)!=formu[[2]]] ) %*% fitb[[i]]$coef[,1]
    # 这里以group==1为基准模型，用group==2的数据计算反常规模型拟合值
    ystar = cbind(1,engel2[,names(engel2)!=formu[[2]]] ) %*% fita[[i]]$coef[,1]
    ya = mean(ya)
    yb = mean(yb)
    ystar = mean(ystar)
    tab[i,1] = fita[[i]]$tau
    tab[i,2] = yb - ya
    tab[i,3] = yb - ystar # 回报影响，数据相同，模型不同：模型机制的不同所产生的差异
    tab[i,4] = ystar - ya # 变量影响，数据不同，模型相同：样本点不同产生的差异
  }
  # 画图
  if( pic ){
    attach(engel)
    windows(5,5)
    plot(income, foodexp, cex=0.5, type="n",main="两组分位数回归结果比较")
    points(engel1, cex=0.5, col=2)
    points(engel2, cex=0.5, col=3)
    for( i in 1:length(taus) ){
      abline( fita[[i]], col=2 )
      abline( fitb[[i]], col=3 )
    }
    detach(engel)
  }
  # 输出结果
  tab
}

data(engel,package = "quantreg")
group = c(rep(1,100),rep(2,135))  # 取前100个为第一组，后135个第二组
taus = c(0.05,0.25,0.5,0.75,0.95)  # 需要考察的不同分位点
MM2005(foodexp~income, taus, data = engel, group=group, pic=F)
```

```{r echo=F}
try(detach(package:pander))
try(detach(package:ggplot2))
try(detach(package:pspearman))
try(detach(package:gvlma))
try(detach(package:car))
try(detach(package:lmtest))
try(detach(package:leaps))
try(detach(package:plyr))
try(detach(package:bootstrap))
try(detach(package:rJava))
try(detach(package:quantreg))
```

#广义线性模型
```{r include=FALSE}
library(pander)
library(ggplot2)
library(plyr) 
library(elrm) 
library(epicalc)
library(car)
library(rms)
library(Deducer)
library(boot)
library(bestglm)
library(survival)
library(robust)
library(mlogit)
library(VGAM)
library(nnet)
library(ordinal)
library(robust)
library(qcc)
library(sandwich)
library(lmtest)
library(pscl)
library(mvtnorm)
library(MASS)
```
广义线性模型（GLM）是正态线性模型的直接推广，使用于连续数据和离散数据。广义线性模型通过链接函数，将因变量的期望与线性自变量相联系，通过误差函数描述误差的分布，使得许多线性模型的方法能被用于一般的问题。下表为广义线性模型中常见的链接函数和误差函数。

      连接函数                     典型误差函数
----  ---                          ---
恒等  $x^{T}\beta =E(y)$           正态分布
对数  $x^{T}\beta =lnE(y)$         Poisson分布
Logit $x^{T}\beta =logitE(y)$      二项分布
逆    $x^{T}\beta =\frac{1}{E(y)}$ Gamma分布

R中常用的分布族和连接函数见下表

分布族            连接函数                        默认连接函数
----              ----                            ---
binomial          logit,probit,cloglog            link="logit"
gaussian          identity                        link="identity"
Gamma             identity,inverse,log            link="inverse"
inverse.gaussian  1/mu^2                          link="1/mu^2""
poisson           identity,log,sqrt               link="log""
quasi             logit,probit,cloglog,identity,  link="identity",variance="constant"
                  inverse,log,1/mu^2,sqrt
                  
R中通过glm(formula, family=family.generator,data=data.frame) 函数用来做广义线性回归。正态分布族的使用方法：glm(formula, family = gaussian(link = identity),data = data.frame) , link指定了连接函数，正态分布族的连接函数缺省值是恒等的，link = identity可以不写。分布族缺省值是正态分布，family = gaussian也可以不写。glm(formula,data=data.frame)与lm(formula,data=data.frame)等价。本章重点关注常用的两种模型：Logistic回归和Poisson回归。

##Logistic回归

因变量为二分类或多分类时，Logistics回归是非常重要的模型。Logistics回归由于对资料的正态性和方差齐性不做要求、对自变量类型也不做要求等，使得Logistic回归模型在医学研究各个领域被广泛用，可探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，为两分类变量，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。通过logistic回归分析，就可以大致了解到底哪些因素是胃癌的危险因素。Logistics回归模型的表达形式为
$$logit(P)=ln(\frac{P}{1-P})=\beta_{0}+\beta_{1}X_{1}+\beta_{2}X_{2}+\cdots +\beta_{p}X_{p}$$
P为暴露于某种状态下的结局概率。$logit(P)$是一种变量变换方式，表示对P进行logit变换。$beta_{i}$为偏回归系数，表示在其他自变量不变的条件下，$X_{i}$每变化一个单位$logit(P)$的估计值。对P进行了$logit(P)$变换后，$ln(\frac{P}{1-P})$的值可以取任意值。Logistics回归是通过最大似然估计（maximum likelihood estimation,MLE）求解常数项和偏回归系数,基本思想时当从总体中随机抽取n个样本后，最合理的参数估计量应该使得这n个样本观测值的概率最大。最大似然法的基本思想是先建立似然函数与对数似然函数，再通过使对数似然函数最大求解相应的参数值，所得到的估计值称为参数的最大似然估计值。

在R语言中，进行logistic回归的命令是通过广义线性模型进行的：fm <- glm(formula, family = binomial(link = logit),data=data.frame) 。Logistic回归的基本方法是极大似然方法，其前提是样本较大。在样本量较小、数据结构较偏时，可以用精确Logistic回归（Exact logistic regression）来解决这一问题，该方法通过建立条件似然函数，进一步求出参数的充分统计量的分布函数。随着计算方法的发展和优化，也出现了使用马尔可夫链蒙特卡罗算法来模拟精确Logistic回归。R语言中的elrm包就可以实现这种算法。glm()拟合二项模型时对于因变量，如果是向量， 则假定操作二元（binary）数据，因此要求是0/1向量。 如果因变量是双列矩阵，则假定第一列为试验成功的次数第二列为试验失败的次数。如果因变量是因子，则第一水平作为失败 (0) 考虑而其他的作为`成功'(1) 考虑。

### 单因素Logistics回归
某项研究观察一种基因对于胃癌的诊断价值，选择了115名胃癌患者和115名非胃癌患者，检测他们的基因表达状态，欲分析该基因对胃癌是否有一定的诊断价值。

胃癌        基因+        基因-
----        ---          ---
是          50           65
否          4            111

本例研究的因变量为二分类变量，分析基因的影响可以用$\chi ^{2}$和Logistics回归。
```{r}
x<-c(50, 4, 65, 111)
dim(x)<-c(2,2)
chisq.test(x,correct = FALSE)
```
P值较小，可以认为该基因对胃癌的诊断具有统计学意义。
```{r}
#将表转化为扁平格式
table2flat <- function(mytable){
  df <- as.data.frame(mytable)
  rows <- dim(df)[1]
  cols <- dim(df)[2]
  x <- NULL
  for(i in 1:rows){
    for(j in 1:as.integer(as.character(df$Freq[i]))){
      row <- df[i,c(1:(cols-1))]
      x <- rbind(x,row)
    }
  }
  row.names(x) <- c(1:dim(x)[1])
  return(x)
}

gene <- rep(c(1,0),times=2)
cancer <- rep(c("0","1"),each=2)
Freq <- c(50,4,65,111)
mytable <- as.data.frame(cbind(gene,cancer,Freq))
mydata <- table2flat(mytable)

#绘制条件密度图，查看线性关系
cdplot(cancer~gene,data=mydata)
fit.glm<- glm(cancer~gene,family = binomial, data = mydata)
summary(fit.glm)
```

#### 回归诊断
##### 拟合优度（goodness of fit）
拟合优度度量的是预测值和观测值之间的总体一致性。但是在评价模型时，实际上测量的是预测值和观测值之间的差别，也就是实际上检测的是模型预测的“劣度”不是”优度“，即拟合不佳检验 （lack of fit test）常用的两个指标是 Hosmer-Lemeshow指标（HL）和信息测量指标（information measure）(IM). Hosmer Lemeshow拟合优度指标(通常简写为H-L),对应的统计假设$H_{0}$是预测值概率和观测值之间无显著差异，所以如果HL指标显示较大的P-value，说明统计结果不显著，因此，不能拒绝关于模型拟合数据很好的假设，换句话说，模型很好的拟合了数据。 IM指标中比较常用的是AIC，在其他条件不变的情况下，较小的AIC值表示拟合模型较好。

##### 模型卡方统计（model chi-square statistic）
模型卡方统计检测的是模型中所包含的统计量对因变量有显著的解释能力，也就是说所设模型比零假设模型（即只包含常数项的模型）要好，在多元线性回归和ANOVA中，常用F检验达到目的。在logistic中用似然比检验（likelihood ratio test）,相当于F检验。需要注意的是，模型卡方值和拟合优度是两个完全不同的概念：模型卡方值度量的是自变量是否与因变量的odds自然对数线性相关，而拟合优度度量的是预测值与观测值之间的一致性。所以按照理想情况，最好是模型的卡方检验统计性显著而拟合优度的统计性不显著。如果发生不一致，实践中更优先关注前者。

##### 预测准确性
模型卡方统计关注的只是对于零假设模型而言，所设模型显著不显著，它只是从总体上考虑了模型的显著性，但是所有X变量到底能解释多少Y变量的波动？这是预测准确性的问题，有两种方法：(1)类RSQUARE指标：在线性回归中，可以用RSQUARE来度量，显然RSQUARE越高说明预测越好，在logistic中，也有类似的指标。logistic中的RSQUARE也有许多重要的性质：与经典的RSQUARE定义一致，它可以被理解为Y变异中被解释的比例。(2)AUC值(C统计量)：拟合优度只是给出了观测值和预测概率直接的差别程度，然后给出了一个总体评价的指标，但是在实际应用中，往往更关心观测值和模型预测的条件事件概率的关联强度，这类指标被称为序列相关指标，指标值越高，表示预测概率与观测反应变量直接的关联越密切。通常用ROC图来和ROC图的曲线下面积（AUC）进行，AUC可以定量地评价模型的效果，AUC越大则模型效果越好。ROC曲线下的面积值在1.0和0.5之间。在AUC>0.5的情况下，AUC越接近于1，说明诊断效果越好。AUC在 0.5～0.7时有较低准确性，AUC在0.7～0.9时有一定准确性，AUC在0.9以上时有较高准确性。AUC=0.5时，说明诊断方法完全不起作用，无诊断价值。AUC<0.5不符合真实情况，在实际中极少出现。大于或等于0.75一般认为认为模型是可靠的。

ROC（receiver operating characteristic curve，受试者工作特征曲线）曲线，横轴是1-Specificity（特异度），纵轴是Sensitivity（灵敏度）。45度线是作为参照（baseline model）出现的，就是说，ROC的好坏，乃是跟45度线相比的。选择最佳的诊断界限值。ROC曲线越靠近左上角,试验的准确性就越高。最靠近左上角的ROC曲线的点是错误最少的最好阈值，其假阳性和假阴性的总数最少。两种或两种以上不同诊断试验对疾病识别能力的比较。在对同一种疾病的两种或两种以上诊断方法进行比较时，可将各试验的ROC曲线绘制到同一坐标中，以直观地鉴别优劣，靠近左上角的ROC曲线所代表的受试者工作最准确。亦可通过分别计算各个试验的ROC曲线下的面积(AUC)进行比较，哪一种试验的 AUC最大，则哪一种试验的诊断价值最佳。

对于0-1变量的二分类问题，分类的最终结果可以用表格表示为：

            预测值0     预测值1
----        ---         ---            
实际值0     a           b
实际值1     c           d

其中，d是“实际为1而预测为1”的样本个数，c是“实际为1而预测为0”的样本个数，其余依此类推。显然地，主对角线所占的比重越大，则预测效果越佳，这也是一个基本的评价指标——总体准确率(a+d)/(a+b+c+d)。TPR（真阳性率、灵敏度）：True Positive Rate，将实际的1正确地预测为1的概率，d/(c+d)。FPR：False Positive Rate（假阳性率，1-特异度），将实际的0错误地预测为1的概率，b/(a+b)。TPR与FPR相互影响的重要因素就是“阈值”。当阈值为0时，所有的样本都被预测为正例，因此TPR=1，而FPR=1。此时的FPR过大，无法实现分类的效果。随着阈值逐渐增大，被预测为正例的样本数逐渐减少，TPR和FPR各自减小，当阈值增大至1时，没有样本被预测为正例，此时TPR=0，FPR=0。

统计量最为关注的是AUC值，其次是似然卡方统计量，然后才是HL统计量，对AIC 和RSQUARE 极少关注，这一点和多元线性回归有很大的不同，根本原因是多元线性回归是一个预测模型，目标变量的值具有实际的数值意义；而logistic是一个分类模型，目标变量的值是一个分类标识，因此更关注观测值和预测值之间的相对一致性，而不是绝对一致性。

rms包lrm()函数可以计算相关统计量。
```{r}
model <- lrm(cancer~gene,data=mydata)

#Nagelkerke等其他拟合优度指标
goodfit <- function(glmFit)
{
  N    <- nobs(glmFit)
  glm0 <- update(glmFit, . ~ 1)
  LLf  <- logLik(glmFit)
  LL0  <- logLik(glm0)
  
  McFadden <- as.vector(1 - (LLf / LL0))
  CoxSnell <- as.vector(1 - exp((2/N) * (LL0 - LLf)))
  Nagelkerke <- as.vector((1 - exp((2/N) * (LL0 - LLf))) / (1 - exp(LL0)^(2/N)))
  
 result <- list(McFadden=McFadden, CoxSnell= CoxSnell,Nagelkerke=Nagelkerke)
 return (result)
}

model$stats
goodfit(fit.glm)
```
AUC值（C统计量）为0.778，可以认为模型比较可靠。似然比检验结果比较显著，观测值和预测值的一致性有差异。HL统计量,在多因素统计中予以计算。Deducer包rocplot可以绘制ROC曲线并计算AUC值。CoxSnell$R_{2}$系数与线性回归分析中的决定系数$R_{2}$有相似指出，也是回归方程对因变量变异解释程度的反应，由于CoxSnell$R_{2}$系数取值范围不易确定，不易直接判断拟合效果。Nagelkerke$R_{2}$系数是对CoxSnell$R_{2}$的修正，取值范围在0~1之间，越接近于1，说明模型的拟合优度越高。但对Logistic回归而言，伪决定系数不像线性回归中决定系数那么重要。

```{r}
rocplot(fit.glm)
```
#### 影响分析
对于异常值识别仍然可用influence.measures()函数获得。
```{r}
influencePlot(fit.glm)
influence.measures(fit.glm)
```

#### 多重共线性
可用vif（方差膨胀因子）进行判断，vif开平方是否大于2，若大于2，则存在多重共线性问题。

#### 过度离散
因变量的方差大于期望的二项分布的方差，过度离散会导致奇异标准误检验和不精确的的显著性检验。检验过度离散的一种方法是比较二项分布模型的残差偏差与残差自由度，如果比值比1大很多，可以认为存在过度离散。对过度离散的假设检验需要用family = "quasibinomial"再进行一次模型拟合。

```{r}
overdispersion <- function(fit.glm){
  Phi <- fit.glm$deviance/fit.glm$df.residual
  fit.od <- glm(fit.glm$formula,family = quasibinomial, data = fit.glm$data)
  p <- pchisq(summary(fit.od)$dispersion*fit.glm$df.residual,
              fit.glm$df.residual,lower=F)
  return (list(Phi=Phi,p.value=p))
  }
overdispersion(fit.glm)
```
比值在1附近，并且P值大于0.05，不能拒绝比值为1的假设，可以认为不存在过度离散。


#### 模型参数解释
```{r}
logistic.display(fit.glm)
```
exp(coef(fit.glm))即为OR值，表示自变量增加一个单位，因变量则乘以OR值。OR值具有风险的含义，在危险因素研究中具有重要意义。LR-test（likelihood ration test）为似然比检验,Wald's test为Wadld检验，P值小于0.05均说明回归系数具有统计学意义，自变量与因变量有统计学联系。OR值大于1，为危险因素。OR值小于1，为保护因素。

### 多因素Logistics回归
AER包中包含一个Affairs数据，记录了一组婚外情数据，其中包括参与者性别、年龄、婚龄、是否有小孩、宗教信仰程度（5分制，1表示反对，5表示非常信仰）、学历、职业和婚姻的自我评分（5分制，1表示非常不幸福，5表示非常幸福）。
```{r}
data(Affairs,package="AER")
Affairs$ynaffair[Affairs$affairs > 0] <- 1
Affairs$ynaffair[Affairs$affairs==0] <- 0
Affairs$ynaffair <- factor(Affairs$ynaffair,levels=c(0,1),labels=c("No","Yes"))
```
与线性回归相似，bestglm包中bestglm函数可以完成logistic回归的全子集的自变量筛选。
```{r}
Affairs <- Affairs[,c("gender","age","yearsmarried","children",
                      "religiousness","education","occupation","rating","ynaffair")]
best.logistic <-bestglm(Affairs,family = binomial,IC = "AIC",method = "exhaustive") 
best.logistic$BestModels
summary(best.logistic$BestModel)
```
也可用逐步法完成自变量的筛选。
```{r}
fit.full <- glm(ynaffair~gender+age+yearsmarried
                +children+religiousness+education+
                  occupation+rating,data=Affairs,family=binomial())
step(fit.full)
```

全自集和逐步法对自变量的筛选均应建立在对自变量专业考虑的基础上进行。本例中两种方法结果类似，对其结果进行诊断。
```{r}
fit <- glm(ynaffair ~ gender + age + yearsmarried + 
             religiousness + rating, family = binomial(), data = Affairs)

lrm(ynaffair ~ gender + age + yearsmarried + religiousness + rating,data=Affairs)
```
AUC=0.70,模型尚可。
```{r}
fit0 <- glm(formula = ynaffair ~ 1, family = binomial(), data = Affairs)
anova(fit0,fit,test="Chisq")
```
模型的likelihood-ratio检验，P值小于0.05，可以认为模型的自变量与因变量的odds自然对数线性相关。

Hosmer-Lemeshowz指标
```{r error=FALSE}
hosmerlem  <- function(y, yhat, g=10) {
  cutyhat = cut(yhat, breaks = quantile(yhat, probs=seq(0,1,1/g)), 
                include.lowest=TRUE)
  obs = xtabs(cbind(1 - y, y) ~ cutyhat)
  expect = xtabs(cbind(1 - yhat, yhat) ~ cutyhat)
  chisq = sum((obs - expect)^2/expect)
  P = 1 - pchisq(chisq, g - 2)
  return(list(chisq=chisq,p.value=P))
}

hosmerlem(y=Affairs$ynaffair, yhat=fitted(fit))
```
Hosmer Lemeshow拟合优度指标检验P值小于0.05，可以认为预测值和观测值之间差异显著。
过度离散诊断
```{r}
overdispersion(fit)
```
过度离散检验P值大于0.05，可以认为不存在过度离散。

多重共线性
```{r}
sqrt(vif(fit)) > 2
```
自变量之间不存在多重共线性。可用influence.measures()函数进行影响分析，logistic.display()对自变量进行解释。

### 稳健Logistic回归
robust包中的glmRob（）函数可用来拟合稳健的广义线性模型，包括稳健Logistic回归；当拟合回归模型数据出现离群点和强影响点时，便可应用稳健Logistic回归。对influence.measures(fit)进行影响分析后，发现存在强影响点，应用稳健Logistic回归。
```{r}
fit.rob <- glmRob(ynaffair ~ gender + age + 
                    yearsmarried + religiousness + rating, 
                  family = binomial(), data = Affairs)
summary(fit.rob)
```

### 条件logistic回归
条件logistic回归假设自变量在各配对组中对结果变量的作用是相同的，即自变量的回归系数与配对组无关。配对设计的Logistic回归模型不含常数项，参数估计是根据条件概率得到的。对病例和对照进行配比能控制影响实验效应的主要非处理因素，可以提高统计分析的效能，通常可分为1:1，1:n，m:n配对。epicalc包中的VC1to1来自于验证吸烟、酗酒和橡胶行业工作是否是食管癌的危险因素的病例对照研究。

```{r}
data(VC1to1,package = "epicalc")
pander(VC1to1)
use(VC1to1)
matchTab(case,smoking,strat=matset)
```
case变量1表示患病，0表示未患病。matset变量表示对子号。epicalc包中matchTab()函数用以计算条件优势比（McNemar's优势比），表示病例间不一致部分的计数比值，其95%置信区间如果包含1，则表示变量没有统计学意义。
```{r}
fit.c <- clogit(case~smoking+alcohol+rubber+strata(matset),
                data=VC1to1,method = "exact")
summary(fit.c)
fit.c$loglik
```
survival包中clogit()函数可以完成条件Logistic回归，结果显示模型与空模型比较，差异无显著性。自变量smoking和rubber均无显著性差异，自变量alcohol差异显著。条件Logistic回归模型不能得到对数似然比和AIC值，但能得到条件对数似然比，以表示模型的拟合水平。

### 无序多分类Logistic回归 
若因变量包含两个以上的无序类别（比如，已婚/寡居/离婚），便可使用mlogit包中的mlogit（）函数拟合多项Logistic回归。epicalc中Ectopic数据集，其中outc变量中Deci表示正常分娩，IA表示发生人工流产，EP表示发生宫外孕。hia变量表示以前是否有IA（人工流产史），gravi表示怀孕的次数。
```{r}
data(Ectopic,package = "epicalc")
pander(head(Ectopic))
```
```{r}
ep <- Ectopic$outc=="EP"
ia <- Ectopic$outc=="IA"
deli <- Ectopic$outc=="Deli"
mnFit <- multinom(cbind(deli,ep,ia)~hia+gravi, data=Ectopic)
summary(mnFit)
mlogit.display(mnFit)
```

```{r}
vglmFitMN <- vglm(outc~hia+gravi, family=multinomial(refLevel=3), data=Ectopic)
exp(VGAM::coef(vglmFitMN))
```

```{r}
dfMNL <- mlogit.data(Ectopic, choice="outc", shape="wide", varying=NULL)
mlogitFit <- mlogit(outc ~ 0 | hia+gravi,, reflevel="Deli", data=dfMNL)
summary(mlogitFit)
exp(mlogitFit$coefficients)
```
nnet包中multinom()函数、VGAM包中的vglm()函数、mlogit包中mlogit()函数均得到了相似的结果。mlogit()函数对数据格式于其他两个函数的要求有所不同，其中formula：mlogit提供了条件logit，多项logit，混合logit多种模型，对于多项logit的估计模型应写为：因变量~0|自变量,data：使用mlogit.data函数使得数据结构符合mlogit函数要求。Choice：确定分类变量是什么Shape：如果每一行是一个观测，选择wide，如果每一行是表示一个选择，那么选择long。alt.var：对于shape为long的数据，需要标明所有的选择名称。由于mlogit包可以做的logit模型更多。

本例中是以outc变量的Deli(分娩)做为参考水平的，有人工流产史的病例(hia ever IA)发生宫外孕（EP）的危险增加4.44，有人工流产史的病例(hia ever IA)发生人工流产（IA）的危险增加1.47(置信区间包括1，无显著性意义)。multinom()函数默认是第一水平，可通过levels(Ectopic$outc)方法查看。vglm()和mlogit()函数是可以指定参考水平。

#### 模型拟合评价
```{r}
PhatCateg <- VGAM::predict(vglmFitMN, type="response")
categHat <- levels(Ectopic$outc)[max.col(PhatCateg)]
facHat <- factor(categHat,levels=levels(Ectopic$outc))
cTab   <- xtabs(~ outc+ facHat, data=Ectopic)
addmargins(cTab)
CCR <- sum(diag(cTab)) / sum(cTab)
CCR
```
上述方法可获得模型的正确分类率，本例的正确分类率为`r CCR`，正确分类率偏低。

偏差、对数似然值和AIC值
```{r}
deviance <- VGAM::deviance(vglmFitMN)
logLik<- VGAM::logLik(vglmFitMN)
AIC <- VGAM::AIC(vglmFitMN)
deviance
logLik
AIC
```

McFadden, Cox & Snell and Nagelkerke $R^{2}$伪决定系数

vglm()函数拟合结果并没有直接给出伪决定系数，可通过如下方法计算相关统计量。
```{r}
vglm0 <- vglm(outc~ 1, family=multinomial(refLevel=3), data=Ectopic)
LLf   <- VGAM::logLik(vglmFitMN)
LL0   <- VGAM::logLik(vglm0)
N    <- nobs(vglmFitMN)
McFadden <- as.vector(1 - (LLf / LL0))
CoxSnell<- as.vector(1 - exp((2/N) * (LL0 - LLf)))
Nagelkerke<- as.vector((1 - exp((2/N) * (LL0 - LLf))) / (1 - exp(LL0)^(2/N)))
McFadden
CoxSnell
Nagelkerke
```
Nagelkerke伪决定系数为`r Nagelkerke`，表明自变量对因变量的解释程度不高。

####系数及模型的检验
vglm函数结果中并没有系数及模型的检验情况。对模型的系数及其95%置信区间可从如下方法获得。
```{r}
sumMN   <- VGAM::summary(vglmFitMN)
coefMN <- VGAM::coef(sumMN)
zCrit   <- qnorm(c(0.05/2, 1 - 0.05/2))
ciCoef <- t(apply(coefMN, 1, function(x) x["Estimate"] - zCrit*x["Std. Error"] ))
coefMN
ciCoef
```
似然比检验通过如下方法获得。
```{r}
vglm0 <- vglm(outc~ 1, family=multinomial(refLevel=3), data=Ectopic)
VGAM::lrtest(vglmFitMN, vglm0)
```
似然比检验结果表明含有两个自变量的模型和仅有截距项的模型相比有显著性差异。对系数的检验结果表明有人工流产史的病例(hia ever IA)是发生宫外孕(EP)危险因素。


#### 预测分类
vglm拟合结果可通过如下的方法得到每个分类的预测概率。
```{r}
PhatCateg <- VGAM::predict(vglmFitMN, type="response")
head(PhatCateg)
```
还可以通过如下两种方法分别得到针对multinom()、mlogit()每个分类的预测概率。
```{r eval=FALSE}
predict(mnFit, type="probs")
fitted(mlogitFit, outcome=FALSE)
```
对分类结果的预测有如下两种方法。
```{r}
PhatCateg <- VGAM::predict(vglmFitMN, type="response")
categHat <- levels(Ectopic$outc)[max.col(PhatCateg)]
head(categHat)
```
```{r eval=FALSE}
predCls <- predict(mnFit, type="class")
head(predCls)
```

### 有序多分类Logistic回归
若因变量是一有序的类别（比如，无效/有效/显效/控制），使用无序多分类Logistic回归处理因变量，不但会丧失变量间联系的功效，而且会曲解因变量和自变量之间的相关方式。程序包MASS提供polr()函数、ordinal提供clm()函数、rms提供orm()函数、VGAM提供vglm()函数可以进行ordered logit或probit回归。累积Logistic回归模型(cumulative logit model)如下，${logit}(p(Y \geq g)) = \ln \frac{P(Y \geq g)}{1 - P(Y \geq g)} = \beta_{0_{g}} + \beta_{1} X_{1} + \dots + \beta_{p} X_{p} \quad(g = 2, \ldots, k)$。成比例比数比累计Logistic模型(proportional-adds cumulative logit mode)简化上述模型，使自变量$X_{i}$所对应的回归系数$\beta_{i}$都是相等。在此假设条件下，不同累计Logistic的回归线相互平行，只是截距$\beta_{i}$不同。
例 epicalc中HW93数据集是1993年泰国南部钩虫感染的调查资料，其中intense变量表示感染的严重程度为有序多分类变量，shoes表示是否穿鞋，agegr是年龄分组。
```{r}
data(HW93,package = "epicalc")
intense.ord <- ordered(HW93$intense)
```

在自变量较多的时候，可以采用R中自动逐步变量筛选step()函数，仅MASS包中polr()函数能够支持自变量的筛选。
```{r}
polrFit <- polr(intense.ord~agegr+shoes,method="logistic",data=HW93)
exp(MASS:::confint.polr(polrFit))
ordinal.or.display(polrFit)
```
VGAM包
```{r}
vglmFit <- vglm(intense.ord~agegr+shoes, family=propodds, data=HW93)
```
VGAM包能进行所有类型的logistic回归的计算，并且能进行累计Logistic回归模型的平行性假设检验，其他包则不能。模型中family=cumulative(parallel=TRUE, reverse=TRUE)指定拟合累计Logistic回归模型，而且parallel=T指定模型按平行性假定进行拟合，该选项可简写为amily=propodds。
```{r,eval=FALSE}
vglm(intense.ord~agegr+shoes, family=cumulative(parallel=TRUE, 
                                                reverse=TRUE),data=HW93)
vglm(intense.ord~agegr+shoes, family=acat(parallel=TRUE), data=HW93)
vglm(intense.ord~agegr+shoes, family=sratio(parallel=TRUE), data=HW93)
```

rms包
```{r}
ormFit <- orm(intense~agegr+shoes, data=HW93)
```

ordinal包
```{r}
clmFit <- clm(intense~agegr+shoes, link="logit", data=HW93)
```
结果显示，上述有序多分类Logisitic回归模型有两个截距，每一个都是结果的一个切割点，这些截距项的值没有实际意义。年龄的系数通过两个切割点进行了分割，两个系数均为正数表示危险度随年龄的增加而增加，穿鞋的系数为负数表示穿鞋对两种感染水平均有保护作用。

#### 模型评价
```{r}
vglmFit <- vglm(intense.ord~agegr+shoes, family=propodds, data=HW93)
PhatCateg <- VGAM::predict(vglmFit, type="response")
categHat <- levels(HW93$intense)[max.col(PhatCateg)]
facHat <- factor(categHat, levels=levels(HW93$intense))
cTab   <- xtabs(~ intense + facHat, data=HW93)
addmargins(cTab)
(CCR <- sum(diag(cTab)) / sum(cTab))
```
上述方法可获得模型的正确分类率，本例的正确分类率为`r CCR`，正确分类率偏低。
偏差、对数似然值和AIC值
```{r}
deviance <- VGAM::deviance(vglmFit)
logLik<- VGAM::logLik(vglmFit)
AIC <- VGAM::AIC(vglmFit)
deviance
logLik
AIC
```

McFadden, Cox & Snell and Nagelkerke $R^{2}$伪决定系数
```{r}
vglm0 <- vglm(intense.ord~ 1, family=propodds, data=HW93)
LLf   <- VGAM::logLik(vglmFit)
LL0   <- VGAM::logLik(vglm0)
McFadden <- as.vector(1 - (LLf / LL0))
CoxSnell<- as.vector(1 - exp((2/N) * (LL0 - LLf)))
Nagelkerke<- as.vector((1 - exp((2/N) * (LL0 - LLf))) / (1 - exp(LL0)^(2/N)))
McFadden
CoxSnell
Nagelkerke
```

####系数及模型的检验
```{r}
sumOrd   <- summary(vglmFit)
coefOrd <- coef(sumOrd)
exp(coefOrd[,1])
zCrit   <- qnorm(c(0.05/2, 1 - 0.05/2))
ciCoef <- t(apply(coefOrd, 1, function(x) x["Estimate"] - zCrit*x["Std. Error"] ))
```

MASS包建立的模型可直接使用confint()函数计算OR值及其可信区间。
```{r}
summary(polrFit)
exp(cbind(OR=coef(polrFit),t(confint(polrFit))))
```

ordinal包建立的模型用summary()函数即可输出系数。
```{r}
summary(clmFit)
```

#### 模型比较
```{r}
vglmR <- vglm(intense.ord~ shoes, family=propodds, data=HW93)
VGAM::lrtest(vglmFit, vglmR)
VGAM::lrtest(vglmFit, vglm0)
```
vglmFit与其他两个模型比较均有显著性差异，选择LogLik值较大的，还有两个自变量的模型。选择更优模型还可以比较两个模型的信息统计量AIC和BIC，信息统计量小的模型更优。
```{r}
AIC(vglmR)
AIC(vglm0)
AIC(vglmFit)
```

#### 平行性假设检验
为了检验平行性假设，需要建立非平行的模型，将平行性模型与非平行性模型进行似然比检验，检验平行性假设
```{r}
vglmP  <- vglm(intense.ord~agegr+shoes, 
               family=cumulative(parallel=TRUE,  reverse=TRUE),data=HW93)
vglmNP <- vglm(intense.ord~agegr+shoes, 
               family=cumulative(parallel=FALSE, reverse=TRUE),data=HW93)
VGAM::lrtest(vglmP, vglmNP)
```

```{r}
clmP  <- clm(intense~agegr+shoes, link="logit", data=HW93)
clmNP <- clm(intense~shoes, nominal=~agegr, data=HW93)
anova(clmP, clmNP)
```
平行性假设检验结果表明，P值小于0.05，可以认为平行性假设不成立。检验结果可用is.parallel()函数获得。
### 精确Logistic回归
例 elrm包的drugDat数据集记录不同性别人群在某种药物治疗的结果，recovered表示恢复数量，n表示总人数。
```{r}
data(drugDat,package = "elrm")
pander(drugDat)
```

```{r,eval=FALSE}
data(drugDat)
drug.elrm=elrm(formula=recovered/n~sex+treatment,
               interest=~sex+treatment,iter=100000,burnIn=1000,dataset=drugDat)
summary(drug.elrm)
```

## Possion回归
Poisson回归的因变量是计数型的变量，自变量是连续性或类别型变量。Poisson回归因变量通常局限在一个固定长度时间段内进行测量（如过去一年交通事故数），整个观测集中时间长度都是不变的。Poisson回归主要有两个假设，首先，具有相同特征和同时的不同对象的人时风险是同质的，其次，当样本量越来越大时，频数的均数趋近于方差。

例 robust包中Breslow癫痫数据记录了治疗初期八周内，抗癫痫药物对癫痫发病数的影响，因变量sumY为随机后8周内癫痫发病数，自变量治疗Trt，年龄Age和治疗前8周的癫痫发病数Base。

```{r}
data(breslow.dat,package="robust")
opar <- par(no.readonly=T)
par(mfrow = c(1,2))
attach(breslow.dat)
hist(sumY,breaks = 20,xlab = "Seizure Count",main="Distribution of Seizure")
boxplot(sumY~Trt,xlab="Treatment",main="Group Coomparisons")
par(opar)
```

从图中可以清楚的看到因变量的偏移特性及可能的离群点。药物治疗下癫痫的发病数似乎变小，且方差也变小了。

```{r}
fit <- glm(sumY~Base+Age+Trt,data=breslow.dat,family = poisson())
summary(fit)
```

VGAM包vglm()方法获得类似结果
```{r,eval=FALSE}
vglmFit <- vglm(sumY~Base+Age+Trt, family=poissonff, data=breslow.dat)
summary(vglmFit)
```

结果输出了偏差、回归参数、标准误和参数为0的检验。

###拟合优度检验
检验建立Poisson模型的拟合优度
```{r}
poisgof(fit)
```
P值较小，表明模型的拟合优度较差。

###模型的系数及解释
```{r}
exp(coef(fit))
```
Base、Age、Trt和截距项检验均显示有意义，在保持其他变量不变，年龄增加1岁，癫痫发病数将乘以1.023。一单位的Trt变化（从安慰剂到治疗组），癫痫发病数将乘以0.86,也就是说治疗组想对于安慰剂组发病数下降了。危险比的95%置信区间可通过
```{r}
idr.display(fit)
```

###过度离散
与Logistic回归类似，如果残差的偏差和和残差的自由度之比大于1,那么表明存在过度离散。Poisson分布的方差和均数相等，当因变量的方差比预测方差大时，Poisson分布可能会发生过度离散。过度离散可能会对结果的解释造成影响，可能会得到很小的标准误和置信区间，并且显著性检验也比较宽松。发生过度离散可能是遗漏了某个重要变量或者是计数事件并不独立。过度离散检验可用qcc包的qcc.overdispersion.test()方法。

```{r}
qcc.overdispersion.test(breslow.dat$sumY,type = "poisson")
```
P值小于0.05,表明确实存在过度离散。通过用family="quasipoisson" 替换family="poisson",以完成对过度离散数据的拟合。

```{r}
fit.od <- glm(sumY~Base+Age+Trt,data=breslow.dat,family = quasipoisson())
summary(fit.od)
```

VGAM包vglm()方法获得类似结果
```{r,eval=FALSE}
vglm <- vglm(sumY~Base+Age+Trt, family=quasipoissonff, data=breslow.dat)
summary(vglm)
```

使用类Poisson方法估计的参数与Poisson相同，但标准误变大。当考虑过度离散，Base、Trt和Age均没有显著意义。

###异方差一致的标准误差 
可通过如下方法获得
```{r}
hcSE <- vcovHC(fit, type="HC0")
coeftest(fit, vcov=hcSE)
```

###时间段变化的Poisson回归
当观测时间长度不同时，可以拟合时间段变化的Poisson回归模型，次住假设结果变量是比率。为分析比率，数据中需包含一个记录每个观测时间长度的变量(如time)。然后模型将从$ln(\lambda )=\beta _{0}+\sum_{j=1}^{p}\beta _{j}X_{j}$修改为$ln\begin{pmatrix}\frac{\lambda}{time} \end{pmatrix}=\beta _{0}+\sum_{j=1}^{p}\beta _{j}X_{j}$。为拟合新模型，需要使用glm()函数中的offset选项。假设Breslow中有一个time变量，记录了病人随机分组后监测时间长度的变化，拟合模型如下

```{r,eval=FALSE}
fit <- glm(sumY~Base+Age+Trt,data=breslow.dat,offset=log(time),
           family = poisson())
vglmFit <- vglm(sumY~Base+Age+Trt,offset=log(time), 
                family=poissonff, data=breslow.dat)
```

###零膨胀的Poisson回归
当因变量中，0计数的数目比Poisson回归预测的数据多时，即总体的一个子群体无任何被计数的行为时，就可能发生这种问题。

```{r}
set.seed(123)
N     <- 200
sigma <- matrix(c(4,2,-3, 2,16,-1, -3,-1,8), byrow=TRUE, ncol=3)
mu    <- c(-3, 2, 4)
XY    <- rmvnorm(N, mean=mu, sigma=sigma)
Y     <- round(XY[ , 3] - 1.5)
Y[Y < 0] <- 0
dfCount <- data.frame(X1=XY[ , 1], X2=XY[ , 2], Y)

ziFitP <- zeroinfl(Y ~ X1 + X2 | 1, dist="poisson", data=dfCount)
vglm(Y ~ X1 + X2, family=zipoissonff, data=dfCount)
```

###稳健Poisson回归
influence.measures()对拟合的模型完成影响分析后，如存在离群点和强影响点，可用robust包中glmRob()方法拟合稳健广义线性模型。
```{r}
fit.rob <- glmRob(sumY~Base+Age+Trt, family = poisson(), data=breslow.dat)
summary(fit.rob)
```

### 负二项回归(Negative binomial regression)
Poisson回归假定因变量是均数和方差相等，如果出现方差比均数大，就会形成过度离散，Poisson回归会低估预测变量的标准误。当过度离散比较明显时，指定误差项服从负二项分布，得到的负二项回归系数与Poisson回归相同，但标准误更大，结果的解释与Poisson回归相同。

例 epicalc包DHF99数据集是一实地调查的滋生蚊子幼虫的水容器的数据，因变量containers是有蚊子幼虫滋生的容器的频数，education 和viltype是可能对因变量有影响的自变量。

```{r}
data(DHF99,package="epicalc")
opar <- par(no.readonly=T)
par(mfrow = c(1,2))
attach(DHF99)
hist(containers,breaks = 20)
boxplot(containers~viltype)
par(opar)
qcc.overdispersion.test(DHF99$containers,type = "poisson")
```
因变量的偏移特性比较明显,因变量有缺失值，Poisson回归的过度离散情况不能够检验。

负二项回归拟合用MASS包中glm.nb()方法
```{r}
glmFitNB <- glm.nb(containers ~ education + viltype, data=DHF99)
summary(glmFitNB)
```
VGAM包中vglm()方法如下
```{r,eval=FALSE}
vglmFitNB <- vglm(containers ~ education + viltype, 
                  family=negbinomial, data=DHF99)
summary(vglmFitNB)
```

### 拟合优度检验
检验建立负二项回归模型的拟合优度
```{r}
poisgof(glmFitNB)
```
P值较大，表明模型的拟合优度较好。

###模型的系数及解释
```{r}
exp(coef(glmFitNB))
```
viltype的P值小于0.05,意义比较显著，结果解释与Poisson回归类似。对于自变量的选择可以采用step()和AIC值。

###零膨胀的负二项回归回归
与Poisson回归类似，因变量中0计数的频数较多时，应采用零膨胀的负二项回归回归
```{r}
ziFitNB <- zeroinfl(containers ~ education + viltype | 1, 
                    dist="negbin", data=DHF99)
summary(ziFitNB)
```
VGAM包中vglm()方法如下，此方法的自变量不能为分类变量。
```{r,eval=FALSE}
vglm(containers ~ village, family=zinegbinomial, data=DHF99)
```

出用AIC比较模型外，Quang Vuong提出如果一个模型比另一个模型更接近真实的函数，那么从这个模型得到的每个个体的对数似然值也应该显著的大于从另一个模型得到的每个个体的对数似然值。pscl包vuong() 方法实现了Vuong检验。
```{r}
vuong(ziFitNB, glmFitNB)
```

Vuong 检验的统计量则成标准的N(0, 1)正态分布。Vuong 值大于1.96，则模型1好于模型2，小于-1.96，则结论相反。Vuong Test = -0.15表明两个模型同样地接近真实函数。

```{r echo=F}
try(detach(package:Deducer))
try(detach(package:rms))
try(detach(package:pander))
try(detach(package:ggplot2))
try(detach(package:plyr))
try(detach(package:elrm))
try(detach(package:epicalc))
try(detach(package:car))
try(detach(package:boot))
try(detach(package:bestglm))
try(detach(package:Hmisc))
try(detach(package:survival))
try(detach(package:robust))
try(detach(package:mlogit))
try(detach(package:VGAM))
try(detach(package:nnet))
try(detach(package:ordinal))
try(detach(package:robust))
try(detach(package:qcc))
try(detach(package:sandwich))
try(detach(package:lmtest))
try(detach(package:pscl))
try(detach(package:mvtnorm))
try(detach(package:MASS))
```
